# Hidden Markov Models in PoS Tagging

A partire dagli anni '70, il **PoS tagging** ha iniziato a essere affrontato anche con **metodi probabilistici**, cioÃ¨ **stocastici**.

L'idea alla base Ã¨ semplice: usare i **modelli di Markov nascosti (HMM)** per selezionare la **sequenza di etichette grammaticale piÃ¹ probabile** data una sequenza di parole.

Formalmente, il problema puÃ² essere formulato come segue:

$$
\hat{t}_1^n = \underset{t_1^n \in \text{Tagset}^n}{\arg\max} \ P(t_1^n \mid w_1^n)
$$

In altre parole, cerchiamo la sequenza di tag $t_1^n$ che **massimizza la probabilitÃ  condizionata** dato l'input $w_1^n$, ovvero la sequenza di parole osservate.

## Teorema di Bayes

Per calcolare questa probabilitÃ , possiamo ricorrere al **teorema di Bayes**:

$$
P(x \mid y) = \frac{P(y \mid x) \cdot P(x)}{P(y)}
$$

Applicandolo al nostro problema:

$$
P(t_1^n \mid w_1^n) = \frac{P(w_1^n \mid t_1^n) \cdot P(t_1^n)}{P(w_1^n)}
$$

PoichÃ© $P(w_1^n)$ Ã¨ costante rispetto ai tag $t_1^n$, possiamo ignorarlo nel calcolo dell'$\arg\max$. Otteniamo quindi:

$$
\hat{t}_1^n = \underset{t_1^n \in \text{Tagset}^n}{\arg\max} \ \frac{P(w_1^n \mid t_1^n) \cdot P(t_1^n)}{P(w_1^n)} \approx \underset{t_1^n \in \text{Tagset}^n}{\arg\max} P(w_1^n \mid t_1^n) \cdot P(t_1^n)
$$

Dove:
- $P(w_1^n \mid t_1^n)$ Ã¨ la **verosimiglianza** (*likelihood*): probabilitÃ  di osservare le parole date le etichette.
- $P(t_1^n)$ Ã¨ la **probabilitÃ  a priori** (*prior*) delle etichette grammaticali.

In pratica, cerchiamo la sequenza di PoS tag che **spiega meglio le parole osservate**, tenendo anche conto di quanto sia **probabile a priori** quella sequenza di tag. Ma come calcolare queste probabilitÃ ?

## Assunzione 1: La parola dipende solo dal suo PoS tag

Per semplificare il calcolo della **verosimiglianza** $P(w_1^n \mid t_1^n)$, si fa la seguente assunzione:

> Ogni parola $w_i$ dipende solo dal suo corrispondente tag $t_i$.

Formalmente:

$$
P(w_1^n \mid t_1^n) = \prod_{i=1}^{n} P(w_i \mid t_i)
$$

Questa Ã¨ unâ€™**assunzione di indipendenza condizionata**: ci permette di calcolare la probabilitÃ  delle parole in modo **locale**, tag per tag, invece che sull'intera sequenza.

## Assunzione 2: Ogni tag dipende solo dal tag precedente

Per semplificare il calcolo della **prior** $P(t_1^n)$, si assume che ogni tag dipenda **solo dal tag precedente**:

> Questo Ã¨ noto come **bigram model** o **Markov assumption di primo ordine**.

Formalmente:

$$
P(t_1^n) = \prod_{i=1}^{n} P(t_i \mid t_{i-1})
$$

Questo significa che la sequenza dei tag viene modellata come una **catena di Markov**: non consideriamo tutta la storia passata dei tag, ma solo quello immediatamente precedente.

## Combinazione delle due assunzioni

Applicando insieme le due assunzioni precedenti otteniamo:

$$
P(w_1^n \mid t_1^n) \cdot P(t_1^n) = \prod_{i=1}^{n} P(w_i \mid t_i) \cdot P(t_i \mid t_{i-1})
$$

Questo prodotto Ã¨ il cuore del PoS tagging stocastico: stimiamo la **probabilitÃ  congiunta** della sequenza parole-tag usando stime locali.

## Stima delle probabilitÃ  dai corpora

Grazie a **corpora annotati** (es. Penn Treebank, Universal Dependencies), possiamo stimare le due componenti:

- **ProbabilitÃ  di emissione** (likelihood):  
  $$
  P(w_i \mid t_i) = \frac{\text{conteggio}(t_i, w_i)}{\text{conteggio}(t_i)}
  $$

- **ProbabilitÃ  di transizione** (prior):  
  $$
  P(t_i \mid t_{i-1}) = \frac{\text{conteggio}(t_{i-1}, t_i)}{\text{conteggio}(t_{i-1})}
  $$

Queste stime si basano sulla **frequenza relativa** osservata nei corpus PoS-annotati.

## Come trovare la sequenza di tag ottimale?

Ora abbiamo:
- le probabilitÃ  $P(w_i \mid t_i)$ â†’ emissione
- le probabilitÃ  $P(t_i \mid t_{i-1})$ â†’ transizione

Ma dobbiamo trovare la **sequenza di tag $\hat{t}_1^n$** che **massimizza il prodotto** di questi termini.

Questo Ã¨ un problema classico di **decodifica in modelli di Markov nascosti**.

## Utilizzo degli Hidden Markov Models

Per risolvere il problema del PoS tagging â€” ovvero associare la sequenza di parole a una sequenza di tag grammaticale â€” si puÃ² modellare il processo come un **Hidden Markov Model (HMM)**.

Un HMM Ã¨ un modello statistico in cui:
- Esiste una **sequenza nascosta di stati** (nel nostro caso, i **tag** grammaticali).
- Ogni stato emette un'**osservazione** (nel nostro caso, una **parola** del testo).
- Le transizioni tra stati e le emissioni sono regolate da **probabilitÃ **.

**Formalmente**:

- $Q = q_1 q_2 \dots q_N$  **un insieme di $N$ stati**

- $A = a_{11} \dots a_{ij} \dots a_{NN}$ **una matrice di probabilitÃ  di transizione** $A$, dove ogni $a_{ij}$ rappresenta la probabilitÃ   
  di passare dallo stato $i$ allo stato $j$, tale che $\sum_{j=1}^N a_{ij} = 1 \quad \forall i$

- $O = o_1 o_2 \dots o_T$ **una sequenza di $T$ osservazioni**, ciascuna presa da un vocabolario $V = v_1, v_2, \dots, v_V$

- $B = b_i(o_t)$ **una sequenza di probabilitÃ  di osservazione**, dette anche **probabilitÃ  di emissione**, ognuna delle quali esprime la probabilitÃ  che un'osservazione $o_t$ venga generata dallo stato $q_i$

- $\pi = \pi_1, \pi_2, \dots, \pi_N$ **una distribuzione di probabilitÃ  iniziale** sugli stati. $\pi_i$ Ã¨ la probabilitÃ  che la catena di Markov inizi nello stato $i$. Alcuni stati $j$ possono avere $\pi_j = 0$,  
  cioÃ¨ non possono essere stati iniziali. Inoltre, $\sum_{i=1}^n \pi_i = 1$

### Due assunzioni fondamentali di un HMM di primo ordine

1. **Assunzione di Markov**:  
   Ogni stato (tag) dipende solo dallo **stato precedente**:
   $$
   P(t_i \mid t_1^{i-1}) \approx P(t_i \mid t_{i-1})
   $$

2. **Assunzione di emissione indipendente**:  
   Ogni parola dipende solo dal **tag corrente**, non dagli altri tag o parole:
   $$
   P(w_i \mid t_1^n, w_1^{i-1}) \approx P(w_i \mid t_i)
   $$

Applicando queste due assunzioni otteniamo la formula:
$$
\hat{t}_1^n = \arg\max_{t_1^n \in Tagset^n} \prod_{i=1}^n P(w_i \mid t_i) \cdot P(t_i \mid t_{i-1})
$$

[[Hidden Markov Models|Qui]] Ã¨ diposnibile una descrizione dettagliata degli HMM.

### Esempio: Jason Eisner task (2002)

Un esempio classico per spiegare gli HMM Ã¨ il **"Jason Eisner task"**:

> Jason tiene un diario con il numero di gelati mangiati ogni giorno dell'estate.
> Il suo obiettivo Ã¨ ricostruire, a partire da questi numeri, se ogni giorno era caldo (**H**) o freddo (**C**).

Formalmente:
- La sequenza **osservata** $O$ Ã¨ il numero di gelati mangiati ogni giorno.
- La sequenza **nascosta** $Q$ Ã¨ la condizione meteorologica (**H**ot o **C**old).
- Ogni giorno Jason sceglie quanti gelati mangiare **in base al meteo**.
- Lâ€™obiettivo Ã¨ **inferire la sequenza di stati** che ha prodotto le osservazioni.

Questo Ã¨ del tutto analogo al PoS tagging:
- Le **osservazioni** sono le parole del testo.
- Gli **stati nascosti** sono i tag grammaticali.
- Lâ€™obiettivo Ã¨ inferire la **sequenza di tag piÃ¹ probabile** dato il testo osservato.

### Riassunto dei componenti di un HMM per il PoS tagging

| Componente | Significato NLP | Simbolo | Come si calcola |
|------------|------------------|---------|------------------|
| Stati $Q$ | Tag PoS | $t_i$ | Predefiniti nel tagset |
| Osservazioni $O$ | Parole del testo | $w_i$ | Input della frase |
| Transizione | $P(t_i \mid t_{i-1})$ | Tag â†’ Tag | Frequenze nei corpora |
| Emissione | $P(w_i \mid t_i)$ | Tag â†’ Parola | Frequenze nei corpora |
| Iniziale $\pi(t_1)$ | ProbabilitÃ  iniziale di ogni tag | $P(t_1)$ | Conta quanti tag iniziali in corpus |

### Obiettivo finale

Data una frase (sequenza di parole), vogliamo trovare:

$$
\hat{t}_1^n = \arg\max_{t_1^n} P(w_1^n \mid t_1^n) \cdot P(t_1^n)
$$

Dove $P(w_1^n \mid t_1^n)$ e $P(t_1^n)$ sono le **verosimiglianze** e **probabilitÃ  a priori**.


### Esempio pratico


Supponiamo di avere il seguente **corpus annotato** (PoS-tagged):

```
the/DT dog/NN barks/VBZ
the/DT can/NN falls/VBZ
we/PRP can/MD win/VB
book/NN the/DT book/VB
dogs/NNS bark/VBP
cats/NNS sleep/VBP
the/DT can/MD run/VB
can/MD you/PRP run/VB
some/DT dogs/NNS bark/VBP
```

#### 1. Insieme dei tag e parole

- **Tag (Q)** = { `DT`, `PRP`, `NN`, `NNS`, `MD`, `VBZ`, `VBP`, `VB` }  
- **Parole (O)** = { the, some, we, you, dog, dogs, cat(s), can, book, bark, barks, falls, sleep, run, win }

#### 2. ProbabilitÃ  di transizione

| Transizione           | Conteggio | ProbabilitÃ  |
|-----------------------|-----------|-------------|
| âŸ¨sâŸ© â†’ DT              | 4         | 4/9 â‰ƒ 0.44  |
| âŸ¨sâŸ© â†’ PRP             | 1         | 1/9 â‰ƒ 0.11  |
| âŸ¨sâŸ© â†’ NN              | 1         | 1/9 â‰ƒ 0.11  |
| âŸ¨sâŸ© â†’ NNS             | 2         | 2/9 â‰ƒ 0.22  |
| âŸ¨sâŸ© â†’ MD              | 1         | 1/9 â‰ƒ 0.11  |
| DT â†’ NN               | 2         | 2/5 = 0.40  |
| DT â†’ MD               | 1         | 1/5 = 0.20  |
| DT â†’ NNS              | 1         | 1/5 = 0.20  |
| DT â†’ VB               | 1         | 1/5 = 0.20  |
| PRP â†’ MD              | 1         | 1/2 = 0.50  |
| PRP â†’ VB              | 1         | 1/2 = 0.50  |
| NN â†’ VBZ              | 2         | 2/3 â‰ƒ 0.67  |
| NN â†’ DT               | 1         | 1/3 â‰ƒ 0.33  |
| NNS â†’ VBP             | 2         | 3/3 = 1.00  |
| MD â†’ VB               | 2         | 2/3 â‰ƒ 0.67  |
| MD â†’ PRP              | 1         | 1/3 â‰ƒ 0.33  |

#### 3. ProbabilitÃ  di emissione

**DT** (5 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| the    | 4         | 4/5 = 0.80  |
| some   | 1         | 1/5 = 0.20  |

**PRP** (2 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| we     | 1         | 1/2 = 0.50  |
| you    | 1         | 1/2 = 0.50  |

**NN** (4 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| dog    | 1         | 1/3 â‰ˆ 0.333 |
| can    | 1         | 1/3 â‰ˆ 0.333 |
| book   | 1         | 1/3 â‰ˆ 0.333 |

**NNS** (3 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| dogs   | 2         | 2/3 â‰ƒ 0.67  |
| cats   | 1         | 1/3 â‰ƒ 0.33  |

**MD** (3 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| can    | 3         | 3/3 = 1.00  |

**VBZ** (2 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| barks  | 1         | 1/2 = 0.50  |
| falls  | 1         | 1/2 = 0.50  |

**VBP** (2 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| bark   | 2         | 2/3 â‰ˆ 0.667 |
| sleep  | 1         | 1/3 â‰ˆ 0.333 |

**VB** (4 occorrenze)

| Parola | Conteggio | ProbabilitÃ  |
|--------|-----------|-------------|
| win    | 1         | 1/4 = 0.25  |
| book   | 1         | 1/4 = 0.25  |
| run    | 2         | 2/4 = 0.50  |

#### 4. Rappresentazione TikZ del modello HMM

<img src="/images/tikz/3bfdc9c4c841833e4ad94f4100c0c1d9.svg" style="display: block; width: 100%; height: auto; max-height: 600px;" class="tikz-svg" />

#### Conclusione

Questo Ã¨ un semplice esempio pratico che mostra come costruire un HMM da un corpus annotato, calcolare tutte le probabilitÃ , e disegnare il grafo corrispondente. Nella realtÃ  si lavora su tagset e vocabolari molto piÃ¹ grandi, ma il concetto Ã¨ lo stesso.

## PoS Decoding

Nel contesto dei modelli **HMM**, il **decoding** Ã¨ il processo per determinare la sequenza piÃ¹ probabile di stati nascosti (in questo caso, i PoS tag) dati una sequenza osservata di parole.

<br>

> **Decoding**: Dato in input un HMM $\lambda = (A, B)$ e una sequenza di osservazioni $O = o_1, o_2, \dots, o_T$, il compito Ã¨ trovare la sequenza di stati $Q = q_1 q_2 q_3 \dots q_T$ piÃ¹ probabile.

Nel caso del **PoS tagging**, le **osservazioni** corrispondono alle parole, mentre gli **stati** rappresentano i corrispondenti PoS tag. L'obiettivo Ã¨ quindi assegnare ad ogni parola il PoS tag piÃ¹ plausibile secondo il modello HMM.

### Algoritmo di Viterbi

Il **decoding** viene eseguito tramite l'**algoritmo di Viterbi**, che trova il percorso di stati piÃ¹ probabile (la sequenza di tag PoS piÃ¹ plausibile) che ha generato la sequenza osservata.

L'algoritmo lavora in tre fasi:

- **Inizializzazione**: calcola la probabilitÃ  iniziale per ciascuno stato, moltiplicando la probabilitÃ  iniziale $\pi_s$ per la probabilitÃ  di emissione della prima osservazione.
  
- **Ricorsione**: per ogni parola nella sequenza (dalla seconda in poi), si aggiorna la matrice delle probabilitÃ  di percorso considerando il massimo tra tutti i possibili stati precedenti.

- **Terminazione**: si seleziona il percorso con la probabilitÃ  totale piÃ¹ alta.

> Output: `bestpath`, la sequenza piÃ¹ probabile di stati (PoS tag), e `bestpathprob`, la sua probabilitÃ .

$$
\begin{aligned}
\textbf{VITERBI}(O = o_1, o_2, \dots, o_T; \lambda = (A, B)) &\Rightarrow \text{best-path}, \text{path-prob} \\
\\
\textbf{Inizializzazione:} \quad &\text{crea una matrice } \textit{viterbi}[N, T]\\
\quad &\text{per ogni stato } s = 1 \dots N \\
&\quad \textit{viterbi}[s, 1] \leftarrow \pi_s \cdot b_s(o_1) \\
&\quad \textit{backpointer}[s, 1] \leftarrow 0 \\
\\
\textbf{Ricorsione:} \quad &\text{per ogni } t = 2 \dots T \\
&\quad \text{per ogni stato } s = 1 \dots N \\
&\quad \quad \textit{viterbi}[s, t] \leftarrow \max_{s'} \left( \textit{viterbi}[s', t-1] \cdot a_{s', s} \cdot b_s(o_t) \right) \\
&\quad \quad \textit{backpointer}[s, t] \leftarrow \mathop{\arg\max}\limits_{s'} \left( \textit{viterbi}[s', t-1] \cdot a_{s', s} \cdot b_s(o_t) \right) \\
\\
\textbf{Terminazione:} \quad &\text{bestpathprob} \leftarrow \max_{s=1}^N \left( \textit{viterbi}[s, T] \right) \\
&\text{bestpathpointer} \leftarrow \mathop{\arg\max}\limits_{s=1}^{N} \left( \textit{viterbi}[s, T] \right) \\
&\text{Ricostruzione del percorso usando } \textit{backpointer} \\
\end{aligned}
$$

**Spiegazione Intuitiva**

L'algoritmo di Viterbi si basa su un principio semplice ma potente: invece di considerare **tutti** i possibili percorsi attraverso la rete di stati (cosa computazionalmente proibitiva), calcola **ricorsivamente** il percorso piÃ¹ probabile che porta a ciascuno stato in ogni istante di tempo. CosÃ¬ facendo, sfrutta il principio di **ottimalitÃ ** della programmazione dinamica.

Ecco l'idea chiave:

- Se vogliamo sapere qual Ã¨ la sequenza di stati piÃ¹ probabile che ha generato una sequenza di osservazioni, possiamo costruirla passo dopo passo, **tenendo traccia solo dei percorsi migliori** verso ciascuno stato.
- In ogni momento, per uno stato corrente $s$, si calcola la **probabilitÃ  massima di arrivare lÃ¬** da uno qualsiasi degli stati precedenti $s'$, **moltiplicando**:
  1. la probabilitÃ  del miglior percorso fino a $s'$ al tempo $t-1$
  2. la probabilitÃ  di transizione da $s'$ a $s$ ($a_{s', s}$)
  3. la probabilitÃ  di emissione dell'osservazione corrente da $s$ ($b_s(o_t)$)

Questo approccio si basa su un'importante assunzione del modello di Markov (HMM):

- La **probabilitÃ  di uno stato** dipende **solo** dallo stato precedente (Markoviano)
- L'**osservazione** dipende **solo** dallo stato attuale

**PerchÃ© funziona?**  
PerchÃ© grazie alla struttura a stati e alle probabilitÃ  condizionate dellâ€™HMM, possiamo decomporre un problema complesso (trovare il percorso globale ottimo) in tanti sottoproblemi piÃ¹ semplici (trovare il miglior percorso fino a un certo stato in un certo istante), e riutilizzare le soluzioni ai sottoproblemi precedenti. Questo Ã¨ esattamente ciÃ² che fa la programmazione dinamica.

Infine, una volta costruita la matrice `viterbi`, usiamo `backpointer` per ricostruire **allâ€™indietro** la sequenza ottimale degli stati, partendo dallo stato finale con la massima probabilitÃ .

In sintesi:

- Non esplora tutti i percorsi possibili.
- Sfrutta solo i percorsi migliori a ogni passo.
- Ãˆ efficiente (tempo lineare nella lunghezza della sequenza).
- Ãˆ esatto (garantisce il percorso piÃ¹ probabile).

### Applicazione dell'Algoritmo di Viterbi per la sequenza "we can run"

Questo documento illustra passo dopo passo l'applicazione dell'algoritmo di Viterbi per trovare la sequenza di tag POS (Part-Of-Speech) piÃ¹ probabile per la frase "we can run". 

**Parametri di Input**
- **Sequenza di osservazioni**:  
  $$O = (o_1, o_2, o_3) = (\text{we},\, \text{can},\, \text{run})$$  
  Dove $T = 3$ Ã¨ la lunghezza della sequenza.

- **Insieme degli stati (tag POS)**:  
  $$Q = \{\text{DT}, \text{PRP}, \text{NN}, \text{NNS}, \text{MD}, \text{VBZ}, \text{VBP}, \text{VB}\}$$  
  Alcuni stati (VBZ, VBP, VB) hanno probabilitÃ  iniziale $\pi_s = 0$.

- **Parametri**:
  - $\pi_s$: ProbabilitÃ  iniziali degli stati.
  - $A = [a]_{i,j}$: Matrice di transizione tra stati.
  - $B = b_i(o_t)$: Matrice di emissione (probabilitÃ  che uno stato $i$ emetta una parola $o_t$).

**1. Inizializzazione ($t=1$)**

Calcoliamo le probabilitÃ  $v[s,1]$ per tutti gli stati al primo passo temporale ($t=1$), usando la formula:  
$$v[s,1] = \pi_s \cdot b_s(\text{we})$$

**Spiegazione**:
- $v[s,1]$: ProbabilitÃ  del percorso piÃ¹ probabile che termina nello stato $s$ al tempo $t=1$.
- Solo gli stati con $\pi_s > 0$ **e** $b_s(\text{we}) > 0$ contribuiscono.  

| Stato $s$ | $\pi_s$      | $b_s(\text{we})$ | $v[s,1]$          | Note                                  |
|-------------|----------------|---------------------|---------------------|---------------------------------------|
| DT          | $4/9 \approx 0.444$ | 0                  | $0$              | Emissione nulla per "we"              |
| PRP     | $1/9 \approx 0.111$ | $0.50$            | $\frac{1}{18} \approx 0.0556$ | Unico stato con probabilitÃ  non nulla |
| NN          | $1/9$        | 0                  | $0$              | Emissione nulla                      |
| NNS         | $2/9$        | 0                  | $0$              | Emissione nulla                      |
| MD          | $1/9$        | 0                  | $0$              | Emissione nulla                      |
| VBZ         | $0$              | $0$                  | $0$              | ProbabilitÃ  iniziale nulla           |
| VBP         | $0$              | $0$                  | $0$              | ProbabilitÃ  iniziale nulla           |
| VB          | $0$              | $0$                  | $0$              | ProbabilitÃ  iniziale nulla           |

**Chiarimenti**:
- Lo stato PRP Ã¨ l'unico attivo a $t=1$ perchÃ© ha sia $\pi_s > 0$ che $b_s(\text{we}) > 0$.
- I valori di $\pi_s$ per VBZ, VBP, VB sono zero (non presenti nel training data iniziale).

### 2. Fase Ricorsiva

#### Passo $t=2$ (osservazione: "can")

**Emissioni rilevanti**:  
- $b_{\text{NN}}(\text{can}) = 0.25$  
- $b_{\text{MD}}(\text{can}) = 1.00$  

Calcoliamo $v[s,2]$ solo per NN e MD (unici stati con emissione non nulla):

1. **Per lo stato NN**:  
   $$v[\text{NN},2] = \max_{s'} \left( v[s',1] \cdot a_{s',\text{NN}} \cdot 0.25 \right)$$  
   - $s'$ puÃ² essere solo PRP (unico stato con $v[s',1] > 0$).  
   - $a_{\text{PRP},\text{NN}} = 0$ (transizione PRPâ†’NN non consentita).  
   - Risultato: $v[\text{NN},2] = 0.0556 \cdot 0 \cdot 0.25 = 0$.

2. **Per lo stato MD**:  
   $$v[\text{MD},2] = \max_{s'} \left( v[s',1] \cdot a_{s',\text{MD}} \cdot 1.00 \right)$$  
   - $a_{\text{PRP},\text{MD}} = 0.5$ (transizione PRPâ†’MD consentita).  
   - Risultato: $v[\text{MD},2] = 0.0556 \cdot 0.5 \cdot 1 = 0.0278$.  
   - Backpointer: $bp[\text{MD},2] = \text{PRP}$ (stato precedente ottimale).

| Stato $s$ | $v[s,2]$       | $bp[s, 2]$   | Note                          |
|-------------|------------------|------|-------------------------------|
| MD          | $\frac{1}{36} \approx 0.0278$ | PRP  | Unico stato attivo a $t=2$ |
| NN          | $0$            | â€”    | ProbabilitÃ  nulla            |
| Altri       | $0$            | â€”    | Emissione nulla              |

#### Passo $t=3$ (osservazione: "run")

**Emissioni rilevanti**:  
- $b_{\text{VB}}(\text{run}) = 0.50$ (solo VB emette "run").  

Calcoliamo $v[\text{VB},3]$:  
$$v[\text{VB},3] = \max_{s'} \left( v[s',2] \cdot a_{s',\text{VB}} \cdot 0.50 \right)$$  

- $s'$ puÃ² essere solo MD (unico stato con $v[s',2] > 0$).  
- $a_{\text{MD},\text{VB}} = \frac{2}{3}$ (transizione MDâ†’VB consentita).  
- Risultato:  
  $$v[\text{VB},3] = 0.0278 \cdot \frac{2}{3} \cdot 0.5 = \frac{1}{108} \approx 0.00926$$  
- Backpointer: $bp[\text{VB},3] = \text{MD}$.

| Stato $s$ | $v[s,3]$         | $bp[s, 3]$   | Note                          |
|-------------|--------------------|------|-------------------------------|
| VB          | $\frac{1}{108} \approx 0.00926$ | MD  | Unico stato attivo a $t=3$ |
| Altri       | $0$              | â€”    | Emissione nulla              |

Alla fine, abbiamo la tabella di valori ottimali:

| Stato   | $o_1$="we" (t=1)      | $o_2$="can" (t=2)       | $o_3$="run" (t=3)        |
|---------|-----------------------|-------------------------|---------------------------|
| DT      | $0$                   | $0$                     | $0$                       |
| PRP     | $\frac{1}{18} \approx 0.0556$ | $0$                     | $0$                       |
| NN      | $0$                   | $0$                     | $0$                       |
| NNS     | $0$                   | $0$                     | $0$                       |
| MD      | $0$                   | $\frac{1}{36} \approx 0.0278$ | $0$                       |
| VBZ     | $0$                   | $0$                     | $0$                       |
| VBP     | $0$                   | $0$                     | $0$                       |
| VB      | $0$                   | $0$                     | $\frac{1}{108} \approx 0.00926$ |


e la tabella di backpointers:

| Stato   | $o_1$="we" (t=1) | $o_2$="can" (t=2) | $o_3$="run" (t=3) |
|---------|-------------------|-------------------|-------------------|
| DT      | $0$              | â€”                 | â€”                 |
| PRP     | $0$              | â€”                 | â€”                 |
| NN      | $0$              | â€”                 | â€”                 |
| NNS     | $0$              | â€”                 | â€”                 |
| MD      | $0$              | **PRP**           | â€”                 |
| VBZ     | $0$              | â€”                 | â€”                 |
| VBP     | $0$              | â€”                 | â€”                 |
| VB      | $0$              | â€”                 | **MD**            |

#### 3. Terminazione e Ricostruzione del Percorso

1. **Terminazione**:  
   - Troviamo lo stato finale ottimale:  
     $$\text{bestpathprob} = \max_{s} v[s,T] = \max_{s} v[s,3] = v[\text{VB},3] \approx 0.00926$$  
   - Stato finale: $s^* = \text{VB}$.

2. **Ricostruzione all'indietro** (backtracking):  
   - $\hat{s}_3 = \text{VB}$  
   - $\hat{s}_2 = bp[\text{VB},3] = \text{MD}$  
   - $\hat{s}_1 = bp[\text{MD},2] = \text{PRP}$  

**Sequenza ottimale**:  
$$(\text{PRP},\, \text{MD},\, \text{VB}) \quad \text{con probabilitÃ  } \approx 0.926\%$$  

**Interpretazione linguistica**:  
- **PRP**: Pronome personale ("we").  
- **MD**: Verbo modale ("can").  
- **VB**: Verbo base ("run").

## Conclusione: HMM e Viterbi nel PoS Tagging

### ðŸ” Punti Chiave
1. **Modellazione Contestuale**: Gli HMM catturano le dipendenze sequenziali tra i tag attraverso le probabilitÃ  di transizione  
2. **Efficienza Computazionale**: L'algoritmo di Viterbi riduce la complessitÃ  da esponenziale a lineare grazie alla programmazione dinamica  
3. **Addestramento Data-Driven**: Le probabilitÃ  sono stimate direttamente da corpora annotati, garantendo adattabilitÃ  a diversi domini linguistici  

### ðŸ›‘ Limiti Pratici
- **SparsitÃ  dei Dati**: Transizioni/emissioni non osservate nei dati di training ricevono probabilitÃ  zero (problema dello smoothing)  
- **Contesto Limitato**: L'assunzione markoviana di primo ordine ignora dipendenze a lungo raggio  
- **Ambiguity Resolution**: DifficoltÃ  con parole polisemiche che richiederebbero contesto semantico  

#### ðŸ’¡ Soluzioni Ibride Moderne
1. **Integrazione con Reti Neurali**  
   - Usare HMM per la struttura sequenziale + Embedding neurali per rappresentazioni contestuali  
   - Esempio: **BiLSTM-CRF** combinano la potenza delle reti ricorrenti con modelli grafici  

2. **Transformer-Based Taggers**  
   - Modelli come BERT sfruttano l'attenzione globale per catturare dipendenze complesse  
   - Accuracy >98% sul Penn Treebank contro il 95-97% degli HMM classici  

3. **Active Learning**  
   - Ridurre la dipendenza da grandi corpora annotati attraverso annotazioni mirate  
   - Particolarmente utile per lingue low-resource o domini specialistici  

#### ðŸ“š Riferimenti

- [Penn Treebank](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)
- [Jurafsky and Martin - Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)
