# ðŸ§  Word Sense Disambiguation (WSD)

## ðŸ“– Definizione

La **Word Sense Disambiguation (WSD)** Ã¨ il compito di **determinare il significato corretto** di una parola in un determinato contesto, **data una lista di possibili sensi (o synset)**, come quelli definiti in risorse come **WordNet**.

> Esempio:  
> Frase: *"I like planes and aeronautics in general."*  
> Obiettivo: Disambiguare la parola *planes* â†’ potrebbe significare â€œaereiâ€ ($planeÂ¹_n$) oppure â€œsuperfici pianeâ€ ($planeÂ²_n$)  
> Risultato corretto: $planeÂ¹_n$ (aerei) grazie al contesto semantico (â€œaeronauticsâ€).

ðŸ“Œ Inventario di sensi: tipicamente tratto da **WordNet** o risorse simili.

## ðŸ§ª Varianti del task

La WSD si divide in due principali sottotipi di task:

### ðŸŽ¯ Lexical Sample Task

- Viene fornito un **insieme limitato di parole target**.
- Ogni parola ha un proprio inventario di sensi.
- Obiettivo: disambiguare solo queste parole in diversi contesti.
- âœ… Semplice da valutare e confrontare.

### ðŸ“š All-Words Task

- Obiettivo: disambiguare **tutte le parole** in un testo.
- Si utilizza un **lessico completo** con sensi per ogni lemma.
- Simile al *part-of-speech tagging*, ma ogni lemma ha un proprio tagset.
- âœ… PiÃ¹ realistico e sfidante.

## ðŸ§  Metodi per la WSD

### ðŸ” 1. Supervised Learning

- Richiede **corpora annotati manualmente** (es. SemCor).
- Utilizza tecniche di machine learning (es. SVM, Decision Tree, ecc.).
- âœ… Alta accuratezza
- âŒ Costi alti per lâ€™annotazione

### ðŸ§© 2. Unsupervised Learning

- Non richiede etichette.
- Utilizza **similaritÃ  distribuzionale**, clustering, o co-occorrenze.
- âŒ Tipicamente meno accurato
- âœ… Scalabile a nuove lingue

### âš–ï¸ 3. Minimally Supervised

- Si basa su **annotazioni parziali** o **weak supervision**.
- Esempio: sfruttare glossari, parallel corpora o dizionari bilingue.

### ðŸ¤– 4. Neural WSD

- Modelli basati su **reti neurali profonde**, spesso con **word embeddings contestuali** (es. BERT, ELMo).
- Alcuni modelli famosi:
  - **GlossBERT** (legge gloss e contesto con BERT)
  - **Knowledge-based BERT**
- ðŸ“Ž Paper: [IJCAI 2021 â€” Neural Word Sense Disambiguation](https://www.ijcai.org/proceedings/2021/593)

## ðŸ” Tecniche correlate

La WSD Ã¨ strettamente legata ad altri compiti semantici:

- ðŸ”— **[[Entity Linking]]**  
  â†’ associa una menzione in testo a un'entitÃ  in una knowledge base (es. Wikidata, DBpedia).  
  â†’ simile alla WSD ma lavora su entitÃ  enciclopediche anzichÃ© parole comuni.

- ðŸ§  **[[Ontology Learning]]**  
  â†’ processo automatico di costruzione di **ontologie semantiche** a partire da testo.  
  â†’ le disambiguazioni accurate sono fondamentali per costruire classi e relazioni corrette.

## ðŸ§  Esempio visivo (placeholder)

ðŸ“Œ *Inserisci qui uno schema che mostri il processo WSD: parola â†’ contesto â†’ selezione tra sensi possibili da WordNet.*

## ðŸ“Œ Considerazioni finali

La WSD Ã¨ un **compito centrale nella comprensione semantica del linguaggio naturale**.  
Nonostante sia studiata da decenni, **rimane un problema aperto** in molte lingue e domini, specialmente in contesti rumorosi o low-resource.

> âœ¨ Una WSD accurata Ã¨ cruciale per applicazioni NLP avanzate come:  
> â†’ *machine translation*, *question answering*, *text summarization*, *semantic search*, *information extraction* e molto altro.
