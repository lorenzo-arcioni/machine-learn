{
  "title": "CLAP Model: Contrastive Language-Audio Pre-training",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n/* Blocchi di codice sempre visibili */\n.code-visible {\n    border: 1px solid #e5e7eb;\n    border-radius: 12px;\n    background: #f9fafb;\n    margin: 16px 0;\n}\n.code-visible .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<h2 id=\"documentazione-tecnica-completa\">Documentazione Tecnica Completa</h2>\n<h3 id=\"1-introduzione\">1. Introduzione</h3>\n<p>CLAP (Contrastive Language-Audio Pre-training) è un modello di apprendimento multimodale progettato per colmare il divario tra segnali audio e rappresentazioni testuali. Ispirato al successo di <span class=\"text-gray-600\">CLIP</span> nel collegare immagini e testo, CLAP applica i principi dell’apprendimento contrastivo al dominio audio, permettendo al modello di apprendere rappresentazioni condivise tra audio e linguaggio naturale.</p>\n<p>L’idea chiave alla base di CLAP è di mappare clip audio e descrizioni testuali correlate nello stesso spazio di embedding, in modo che clip simili a livello semantico risultino vicine tra loro. Questo approccio consente una vasta gamma di applicazioni, tra cui ricerca e classificazione audio basata su testo, generazione di didascalie per audio, tagging automatico di contenuti sonori e miglioramento dei sistemi di raccomandazione multimediale.</p>\n<p>Il modello sfrutta grandi dataset di coppie audio-testo per allenare reti neurali profonde che catturano sia le caratteristiche acustiche dei suoni sia il loro significato concettuale. L’apprendimento contrastivo guida il modello a distinguere tra coppie corrette (audio e testo correlati) e negative (non correlate), affinando così la capacità di correlare audio e linguaggio in modo robusto e generalizzabile.</p>\n<p>CLAP rappresenta quindi un passo significativo verso sistemi multimodali più intelligenti e flessibili, in grado di comprendere e collegare informazioni provenienti da diverse modalità sensoriali, con implicazioni rilevanti per la ricerca audio, l’accessibilità e le interfacce intelligenti.</p>\n<h3 id=\"2-architettura-generale\">2. Architettura Generale</h3>\n<p>Il modello CLAP è composto da tre componenti principali:</p>\n<ol>\n<li><strong>Audio Encoder</strong>: Processa segnali audio e produce embedding audio</li>\n<li><strong>Text Encoder</strong>: Processa testo e produce embedding testuali  </li>\n<li><strong>Projection Layers</strong>: Mappano gli embedding in uno spazio comune</li>\n</ol>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code>Input Audio → Audio Encoder → Audio Projection ↘\n                                                Joint Embedding Space\nInput Text  → Text Encoder  → Text Projection  ↗\n</code></pre></div>\n</div>\n</details>\n\n<h3 id=\"3-il-viaggio-degli-input-tracciamento-matematico-completo\">3. Il Viaggio degli Input: Tracciamento Matematico Completo</h3>\n<p>Tracciamo matematicamente il percorso completo degli input audio e testo attraverso l&rsquo;architettura CLAP, dalla forma grezza agli embedding finali.</p>\n<h4 id=\"31-pathway-audio-dalla-waveform-allembedding\">3.1 Pathway Audio: Dalla Waveform all&rsquo;Embedding</h4>\n<h5 id=\"step-1-input-audio-grezzo\">Step 1: Input Audio Grezzo</h5>\n<p>Il primo passo nel pathway audio consiste nell&rsquo;acquisire il segnale audio discreto. Questo segnale è rappresentato come un tensore:</p>\n$$\n\\mathbf{X}_{raw} \\in \\mathbb{R}^{B \\times L_{samples}}\n$$\n<p>dove:<br />\n- $B$ è il <strong>batch size</strong>, ossia il numero di clip audio processati simultaneamente durante l&rsquo;addestramento o l&rsquo;inferenza.<br />\n- $L_{samples}$ è la <strong>lunghezza della waveform in campioni</strong>, tipicamente $480{,}000$ per 10 secondi di audio a 48 kHz.  </p>\n<p>Il segnale $\\mathbf{X}_{raw}$ rappresenta l’<strong>onda sonora campionata nel tempo</strong>, contenente tutte le informazioni acustiche della clip, incluse frequenze, intensità e dinamiche temporali. A questo livello, il modello non ha ancora estratto caratteristiche significative: ogni campione è semplicemente un valore numerico che descrive l’ampiezza del segnale in un dato istante.  </p>\n<p>Prima di essere passato al successivo step (feature extraction), $\\mathbf{X}_{raw}$ può subire alcune operazioni preliminari come:<br />\n- <strong>Normalizzazione</strong> per garantire che l’ampiezza rientri in un intervallo standard (ad esempio [-1, 1]),<br />\n- <strong>Rimozione del DC offset</strong> per centrare la waveform intorno a zero,<br />\n- <strong>Eventuale trimming o padding</strong> per uniformare la durata delle clip all’interno del batch.  </p>\n<p>Questo passaggio è cruciale perché definisce la <strong>rappresentazione numerica di base</strong> su cui le successive trasformazioni (come trasformate di Fourier, mel-spectrogrammi o convoluzioni) potranno estrarre caratteristiche semantiche e acustiche rilevanti per l’allenamento contrastivo.</p>\n<h5 id=\"step-2-short-time-fourier-transform-stft\">Step 2: <span class=\"text-gray-600\">Short-Time Fourier Transform (STFT)</span></h5>\n<p>Dopo aver normalizzato e preparato il segnale audio grezzo, il passo successivo consiste nell’analizzare il contenuto in frequenza nel tempo tramite la <strong><span class=\"text-gray-600\">Short-Time Fourier Transform (STFT)</span></strong>.</p>\n<p>Per ogni batch $b$, frame temporale $m$ e bin di frequenza $k$:</p>\n$$\n\\mathbf{X}_{STFT} = \\text{STFT}(\\mathbf{X}_{raw}) \\implies \\mathbf{X}_{STFT}[b, m, k] = \\sum_{n=0}^{N-1} \\mathbf{X}_{raw}[b, n + mH] \\cdot w[n] \\cdot e^{-j 2 \\pi k n / N}\n$$\n<p>dove:<br />\n- $w[n]$ è la finestra di analisi (ad esempio Hann),<br />\n- $N = 1024$ è la dimensione della finestra FFT,<br />\n- $H$ è l’hop size tra finestre,\n- $k$ è l’indice di frequenza.</p>\n<p>Le dimensioni del tensore risultante sono:</p>\n$$\n\\mathbf{X_{STFT}} \\in \\mathbb{C}^{B \\times 1 \\times T_{frames} \\times F_{bins}}\n$$\n<p>con $T_{frames} = \\lfloor L_{samples}/H \\rfloor = 469$ e $F_{bins} = 513$. La STFT fornisce una <strong>rappresentazione tempo-frequenza</strong>, essenziale per catturare le caratteristiche acustiche dei segnali audio.</p>\n<h5 id=\"step-3-power-spectrogram\">Step 3: Power Spectrogram</h5>\n<p>Poiché la STFT produce valori complessi, si calcola il <strong>power spectrogram</strong> per ottenere una rappresentazione reale e positiva:</p>\n<p>Calcolo del modulo quadrato per ogni elemento complesso:</p>\n$$\n\\mathbf{S} = |\\mathbf{X}_{STFT}|^2 = \\text{Re}(\\mathbf{X}_{STFT})^2 + \\text{Im}(\\mathbf{X}_{STFT})^2 \\in \\mathbb{R}^{B \\times 1 \\times 469 \\times 513}\n$$\n<p>Dove per ogni elemento:</p>\n$$\nS[b, 1, t, f] = (\\text{Re}(X_{STFT}[b, 1, t, f]))^2 + (\\text{Im}(X_{STFT}[b, 1, t, f]))^2\n$$\n<p>Questa operazione element-wise converte i valori complessi della STFT in valori reali positivi che rappresentano l&rsquo;energia del segnale.</p>\n<p>Le dimensioni rimangono le stesse:</p>\n$$\nS \\in \\mathbb{R}^{B \\times 1 \\times 469 \\times 513}\n$$\n<p>Il power spectrogram evidenzia l’energia presente in ciascun bin di frequenza nel tempo, facilitando l’apprendimento di pattern audio rilevanti.</p>\n<h5 id=\"step-4-mel-scale-filtering\">Step 4: Mel-Scale Filtering</h5>\n<p>Per avvicinare la rappresentazione all’orecchio umano, il power spectrogram viene filtrato tramite <strong>bande Mel</strong>. Per ciascun filtro $H_j[k]$:</p>\n$$\n\\mathbf{M} = \\underbrace{\\log^{\\odot}}_\\text{Logaritmo element-wise}(\\mathbf{S}\\mathbf{H}^T + \\epsilon) \\implies M[b, m, j] = \\log \\Bigg( \\sum_k S[b, m, k] \\cdot H_j[k] + \\epsilon \\Bigg)\n$$\n<p>dove:</p>\n<ul>\n<li>$H_j[k]$ sono filtri triangolari Mel,</li>\n<li>$\\mathbf{H} \\in \\mathbb{R}^{64 \\times 513}$ è la matrice dei filtri Mel triangolari</li>\n<li>Moltiplicazione lungo la dimensione delle frequenze: $(469 \\times 513) \\times (513 \\times 64) = (469 \\times 64)$</li>\n<li>$\\epsilon = 10^{-10}$ evita logaritmi di zero,  </li>\n<li>$j = 0, \\dots, 63$ per 64 bande Mel.  </li>\n</ul>\n<p>Le dimensioni diventano:</p>\n$$\n\\mathbf{M} \\in \\mathbb{R}^{B \\times 1 \\times 469 \\times 64}\n$$\n<p>Il log-Mel spectrogram cattura caratteristiche percettivamente significative, riducendo la dimensionalità rispetto alla FFT completa.</p>\n<h5 id=\"step-5-batch-normalization\">Step 5: <a href=\"/theory/deep-learning/Neural Networks/Batch Normalization\" class=\"text-blue-600 hover:underline\">Batch Normalization</a></h5>\n<p>Infine, si applica <strong><a href=\"/theory/deep-learning/Neural Networks/Batch Normalization\" class=\"text-blue-600 hover:underline\">batch normalization</a></strong> lungo la dimensione delle frequenze per stabilizzare e velocizzare l’apprendimento:</p>\n$$\n\\mathbf{M}_{norm} = \\text{BatchNorm}(\\mathbf{M}) = \\boldsymbol{\\gamma} \\odot \\frac{\\mathbf{M} - \\boldsymbol{\\mu}}{\\sqrt{\\boldsymbol{\\sigma}^2 + \\epsilon}} + \\boldsymbol{\\beta}\n$$\n<p>quindi</p>\n$$\n\\mathbf{M}_{norm}[b, 1, t, f] = \\gamma_f \\frac{M[b, 1, t, f] - \\mu_f}{\\sqrt{\\sigma_f^2 + \\epsilon}} + \\beta_f\n$$\n<p>dove $\\mu_f$ e $\\sigma_f^2$ sono media e varianza calcolate sul batch per la frequenza $f$, e $\\gamma_f, \\beta_f$ sono parametri apprendibili.  </p>\n<p>Quindi ricapitolando:\n- $\\boldsymbol{\\mu} \\in \\mathbb{R}^{64}$ è il vettore delle medie calcolate per ogni frequenza lungo dimensioni batch e tempo\n- $\\boldsymbol{\\sigma}^2 \\in \\mathbb{R}^{64}$ è il vettore delle varianze per ogni frequenza lungo dimensioni batch e tempo<br />\n- $\\boldsymbol{\\gamma} \\in \\mathbb{R}^{64}$ è il vettore dei parametri di scala apprendibili (inizializzato a 1)\n- $\\boldsymbol{\\beta} \\in \\mathbb{R}^{64}$ è il vettore dei parametri di shift apprendibili (inizializzato a 0)\n- $\\epsilon = 10^{-5}$ è una costante piccola per stabilità numerica\n- $\\odot$ indica la moltiplicazione element-wise (broadcasting lungo le dimensioni batch e tempo)</p>\n<p>Le dimensioni finali rimangono:</p>\n$$\n\\mathbf{M}_{norm} \\in \\mathbb{R}^{B \\times 1 \\times 469 \\times 64}\n$$\n<p>Questa normalizzazione migliora la <strong>stabilità del training</strong> e aiuta la rete a concentrarsi sulle variazioni rilevanti nei pattern tempo-frequenza.</p>\n<h5 id=\"step-6a-percorso-pann-cnn14\">Step 6A: Percorso PANN (CNN14)</h5>\n<p>Il percorso PANN (Pretrained Audio Neural Network, CNN14) trasforma il log-Mel spectrogram normalizzato in un embedding audio ad alta dimensione, utilizzando una sequenza di blocchi convoluzionali seguiti da pooling temporale e globale.</p>\n<p><strong>Conv Block 1</strong><br />\nIl primo blocco convoluzionale applica due convoluzioni 2D con batch normalization e ReLU, seguito da average pooling sulle dimensioni tempo-frequenza:</p>\n$$\nx_1 = \\text{AvgPool2d}(\\text{ReLU}(\\text{BN}(\\text{Conv2d}(\\text{ReLU}(\\text{BN}(\\text{Conv2d}(M_{norm})))))))\n$$\n<p>Dimensioni risultanti:  </p>\n$$\nx_1 \\in \\mathbb{R}^{B \\times 64 \\times 234 \\times 32}\n$$\n<p><strong>Sequenza di Conv Blocks (2–6)</strong><br />\nOgni Conv Block successivo aumenta la profondità (numero di canali) e riduce progressivamente le dimensioni temporali e frequenziali tramite pooling:</p>\n$$\n\\begin{aligned}\nx_2 &\\in \\mathbb{R}^{B \\times 128 \\times 117 \\times 16} \\quad (\\text{ConvBlock2}) \\\\\nx_3 &\\in \\mathbb{R}^{B \\times 256 \\times 58 \\times 8} \\quad (\\text{ConvBlock3}) \\\\\nx_4 &\\in \\mathbb{R}^{B \\times 512 \\times 29 \\times 4} \\quad (\\text{ConvBlock4}) \\\\\nx_5 &\\in \\mathbb{R}^{B \\times 1024 \\times 14 \\times 2} \\quad (\\text{ConvBlock5}) \\\\\nx_6 &\\in \\mathbb{R}^{B \\times 2048 \\times 14 \\times 2} \\quad (\\text{ConvBlock6})\n\\end{aligned}\n$$\n<p>Questa gerarchia permette al modello di catturare pattern audio a diverse scale temporali e frequenziali, dai dettagli locali alle caratteristiche globali.</p>\n<p>Quindi ora si ha: $x_6$ di dimensioni ${B \\times 2048 \\times 14 \\times 2}$ che per semplicità indicheremo con $B, C, T, F$.</p>\n<p><strong>Frequency Pooling (chiamato anche Temporal Pooling nel codice)</strong><br />\nPer aggregare l’informazione lungo la dimensione delle frequenze, si calcola la media sul bin di frequenza:</p>\n$$\nx_{temp}[b, c, t] = \\frac{1}{F} \\sum_{f=1}^{F} x_6[b, c, t, f] = \\frac{1}{2} \\sum_{f=1}^{2} x_6[b, c, t, f] \\in \\mathbb{R}^{B \\times 2048 \\times 14}\n$$\n<p>Così otteniamo una rappresentazione temporale compressa ma ricca di caratteristiche.</p>\n<p><strong>Global Pooling</strong><br />\nPer ottenere un embedding fisso indipendente dalla lunghezza temporale, si applica sia max pooling che average pooling lungo la dimensione temporale, combinando i risultati:</p>\n$$\n\\begin{aligned}\nx_{max}[b, c] &= \\max_{t=1}^{T} x_{temp}[b, c, t] = \\max_{t=1}^{14} x_{temp}[b, c, t]\\\\\nx_{avg}[b, c] &= \\frac{1}{T} \\sum_{t=1}^{T} x_{temp}[b, c, t] = \\frac{1}{14} \\sum_{t=1}^{14} x_{temp}[b, c, t] \\\\\nx_{global}[b, c] &= x_{max}[b, c] + x_{avg}[b, c] \\in \\mathbb{R}^{B \\times 2048}\n\\end{aligned}\n$$\n<p>Questa combinazione preserva sia le caratteristiche più forti sia la media informativa lungo il tempo.</p>\n<p><strong>Final Audio Embedding</strong><br />\nInfine, si applica un layer fully connected con ReLU per ottenere l’embedding finale:</p>\n$$\n\\phi_{audio}^{PANN}(x_{raw}) = \\text{ReLU}(\\text{Linear}(x_{global})) = \\text{ReLU}(W_{fc1} \\, x_{global} + b_{fc1}) \\in \\mathbb{R}^{B \\times 2048}\n$$\n<p>Qui:<br />\n- <strong>fc1</strong> indica un <em>fully connected layer</em> (o <em>dense layer</em>) che proietta l’output del pooling globale in uno spazio di embedding.<br />\n- $W_{fc1} \\in \\mathbb{R}^{2048 \\times 2048}$ è la <strong>matrice dei pesi</strong> del layer fully connected: combina linearmente le 2048 feature di $x_{global}$ per generare una nuova rappresentazione.<br />\n- $b_{fc1} \\in \\mathbb{R}^{2048}$ è il <strong>vettore dei bias</strong>, che permette al modello di traslare l’output indipendentemente dai pesi, aumentando la flessibilità della rappresentazione.<br />\n- La funzione di attivazione <strong>ReLU</strong> ($\\max(0, z)$) introduce non linearità e mantiene solo le feature positive, migliorando la capacità discriminativa del modello.  </p>\n<p>L’output finale $\\phi_{audio}^{PANN}$ è quindi un <strong>vettore di embedding di dimensione 2048</strong> per ciascuna clip audio, che rappresenta in modo compatto e semantico le sue caratteristiche. Questo embedding è progettato per essere confrontato nello <strong>spazio multimodale audio-testo</strong> durante l’addestramento contrastivo di CLAP.</p>\n<h5 id=\"step-6b-percorso-hts-at-swin-transformer\">Step 6B: Percorso HTS-AT (Swin Transformer)</h5>\n<p><strong>Reshape per Image-like Processing:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">reshape_wav2img</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># Reshape to [B, 1, H, W]</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>Con $H = 256$, $W = 256$ (dimensioni fisse per Swin).</p>\n<p><strong>Patch Embedding:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">patch_embed</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># Conv2d + flatten + norm</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\text{Patches} = \\text{Conv2d}(x, \\text{kernel}=4, \\text{stride}=4)$\n$x_{patches} = \\text{flatten}(\\text{Patches}).transpose(1,2) \\in \\mathbb{R}^{B \\times N_{patches} \\times d_{embed}}$\ndove $N_{patches} = (256/4)^2 = 4096$, $d_{embed} = 96/128/256$.</p>\n<p><strong>Positional Embedding:</strong>\n$x_{pos} = x_{patches} + \\text{PE} \\in \\mathbb{R}^{B \\times 4096 \\times d_{embed}}$</p>\n<p><strong>Swin Transformer Blocks:</strong>\nPer ogni stage $s = 1,2,3,4$:</p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">for</span> <span class=\"n\">layer</span> <span class=\"ow\">in</span> <span class=\"n\">layers</span><span class=\"p\">[</span><span class=\"n\">s</span><span class=\"p\">]:</span>\n    <span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">attn</span> <span class=\"o\">=</span> <span class=\"n\">layer</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># SwinTransformerBlock</span>\n</code></pre></div>\n</div>\n</details>\n\n<p><strong>Stage 1</strong> ($d_1 = d_{embed}$):\n$x_1^{(l+1)} = x_1^{(l)} + \\text{W-MSA}(\\text{LN}(x_1^{(l)}))$\n$x_1^{(l+1)} = x_1^{(l+1)} + \\text{MLP}(\\text{LN}(x_1^{(l+1)}))$\n$\\text{Dimensioni: } x_1 \\in \\mathbb{R}^{B \\times 4096 \\times d_{embed}}$</p>\n<p><strong>Patch Merging 1→2:</strong>\n$x_2 = \\text{Linear}(\\text{Concat}([x_{0::2,0::2}, x_{1::2,0::2}, x_{0::2,1::2}, x_{1::2,1::2}]))$\n$\\text{Dimensioni: } x_2 \\in \\mathbb{R}^{B \\times 1024 \\times 2d_{embed}}$</p>\n<p><strong>Stage 2,3,4</strong>: Procedura analoga con dimensioni:\n$x_2 \\in \\mathbb{R}^{B \\times 1024 \\times 2d_{embed}} \\rightarrow x_3 \\in \\mathbb{R}^{B \\times 256 \\times 4d_{embed}} \\rightarrow x_4 \\in \\mathbb{R}^{B \\times 256 \\times 8d_{embed}}$</p>\n<p><strong>Final Processing:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">norm</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>  <span class=\"c1\"># Layer normalization</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">reshape</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">C</span><span class=\"p\">,</span> <span class=\"n\">H_final</span><span class=\"p\">,</span> <span class=\"n\">W_final</span><span class=\"p\">)</span>  <span class=\"c1\"># Back to spatial</span>\n</code></pre></div>\n</div>\n</details>\n\n<p><strong>Token-Semantic Audio Transformer (TSCAM):</strong>\n$\\text{TSCAM} = \\text{Conv2d}(x_4, \\text{out_channels=classes}, \\text{kernel}=(SF,3))$\n$x_{final} = \\text{AvgPool1d}(\\text{flatten}(\\text{TSCAM}, \\text{dim}=2))$\n$\\phi_{audio}^{HTSAT}(x_{raw}) = \\text{flatten}(x_{final}) \\in \\mathbb{R}^{B \\times d_{embed} \\cdot 8}$</p>\n<h5 id=\"step-7-audio-projection\">Step 7: Audio Projection</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">audio_embedding</span> <span class=\"o\">=</span> <span class=\"n\">audio_projection</span><span class=\"p\">(</span><span class=\"n\">audio_features</span><span class=\"p\">)</span>\n<span class=\"n\">audio_embedding</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"n\">audio_embedding</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{a}_{proj} = \\text{MLP}(\\phi_{audio}(x_{raw}))$\n$= \\text{Linear}(\\text{ReLU}(\\text{Linear}(\\phi_{audio}(x_{raw}))))$\n$\\mathbf{a}_{norm} = \\frac{\\mathbf{a}_{proj}}{||\\mathbf{a}_{proj}||_2} \\in \\mathbb{R}^{B \\times 512}$</p>\n<h4 id=\"32-pathway-testo-dai-token-allembedding\">3.2 Pathway Testo: Dai Token all&rsquo;Embedding</h4>\n<h5 id=\"step-1-input-text-grezzo\">Step 1: Input Text Grezzo</h5>\n<p>$\\text{text_raw} = \\text{\"a dog barking in the park\"}$</p>\n<h5 id=\"step-2a-tokenizzazione-custom-transformer\">Step 2A: Tokenizzazione (Custom Transformer)</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">text_tokens</span> <span class=\"o\">=</span> <span class=\"n\">tokenizer</span><span class=\"p\">(</span><span class=\"n\">text_raw</span><span class=\"p\">)</span>  <span class=\"c1\"># Simple word tokenization</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\text{tokens} = [49406, 320, 1929, 30357, 4648, 1929, 272, 1668, 49407] \\in \\mathbb{Z}^{B \\times L_{ctx}}$\ndove $L_{ctx} = 77$ (context length), padding con 0.</p>\n<h5 id=\"step-2b-tokenizzazione-bertroberta\">Step 2B: Tokenizzazione (BERT/RoBERTa)</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">text_dict</span> <span class=\"o\">=</span> <span class=\"n\">tokenizer</span><span class=\"p\">(</span><span class=\"n\">text_raw</span><span class=\"p\">,</span> <span class=\"n\">return_tensors</span><span class=\"o\">=</span><span class=\"s1\">&#39;pt&#39;</span><span class=\"p\">,</span> \n                      <span class=\"n\">padding</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"n\">truncation</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n<span class=\"c1\"># Output: {&#39;input_ids&#39;: [...], &#39;attention_mask&#39;: [...], &#39;token_type_ids&#39;: [...]}</span>\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"step-3a-percorso-custom-transformer\">Step 3A: Percorso Custom Transformer</h5>\n<p><strong>Token Embedding:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">token_embedding</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>  <span class=\"c1\"># [B, 77, 512]</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{E} = \\text{Embedding}(\\text{tokens}) \\in \\mathbb{R}^{B \\times 77 \\times 512}$</p>\n<p><strong>Positional Embedding:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">positional_embedding</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{X}_0 = \\mathbf{E} + \\mathbf{PE} \\in \\mathbb{R}^{B \\times 77 \\times 512}$</p>\n<p><strong>Transformer Layers:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">permute</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>  <span class=\"c1\"># [77, B, 512] per attention</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">text_branch</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span> <span class=\"n\">attn_mask</span><span class=\"o\">=</span><span class=\"n\">attn_mask</span><span class=\"p\">)</span>\n<span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">permute</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">)</span>  <span class=\"c1\"># Back to [B, 77, 512]</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>Per ogni layer $l = 1, \\ldots, L$:\n$\\mathbf{X}_l^{(1)} = \\mathbf{X}_{l-1} + \\text{MultiHead}(\\text{LN}(\\mathbf{X}_{l-1}), \\text{mask})$\n$\\mathbf{X}_l = \\mathbf{X}_l^{(1)} + \\text{MLP}(\\text{LN}(\\mathbf{X}_l^{(1)}))$</p>\n<p><strong>EOS Token Extraction:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">ln_final</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span>\n<span class=\"n\">eot_indices</span> <span class=\"o\">=</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>  <span class=\"c1\"># Find EOS token position</span>\n<span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">x</span><span class=\"p\">[</span><span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]),</span> <span class=\"n\">eot_indices</span><span class=\"p\">]</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{t}_{raw} = \\text{LN}(\\mathbf{X}_L[\\text{batch_idx}, \\text{EOS_pos}]) \\in \\mathbb{R}^{B \\times 512}$</p>\n<h5 id=\"step-3b-percorso-pre-trained-bertrobertabart\">Step 3B: Percorso Pre-trained (BERT/RoBERTa/BART)</h5>\n<p><strong>BERT Forward:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">text_branch</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"s1\">&#39;input_ids&#39;</span><span class=\"p\">],</span>\n                      <span class=\"n\">attention_mask</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"s1\">&#39;attention_mask&#39;</span><span class=\"p\">],</span>\n                      <span class=\"n\">token_type_ids</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"s1\">&#39;token_type_ids&#39;</span><span class=\"p\">])</span>\n<span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;pooler_output&#39;</span><span class=\"p\">]</span>  <span class=\"c1\"># [B, 768]</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{t}_{raw} = \\text{BERT}(\\text{tokens}).\\text{pooler_output} \\in \\mathbb{R}^{B \\times 768}$</p>\n<p><strong>RoBERTa Forward:</strong>\n$\\mathbf{t}_{raw} = \\text{RoBERTa}(\\text{tokens}).\\text{pooler_output} \\in \\mathbb{R}^{B \\times 768}$</p>\n<p><strong>BART Forward:</strong></p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">outputs</span> <span class=\"o\">=</span> <span class=\"n\">text_branch</span><span class=\"p\">(</span><span class=\"n\">input_ids</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"s1\">&#39;input_ids&#39;</span><span class=\"p\">],</span>\n                      <span class=\"n\">attention_mask</span><span class=\"o\">=</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"s1\">&#39;attention_mask&#39;</span><span class=\"p\">])</span>\n<span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">mean</span><span class=\"p\">(</span><span class=\"n\">outputs</span><span class=\"p\">[</span><span class=\"s1\">&#39;encoder_last_hidden_state&#39;</span><span class=\"p\">],</span> <span class=\"n\">dim</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{t}_{raw} = \\frac{1}{L_{seq}}\\sum_{i=1}^{L_{seq}} \\text{BART}(\\text{tokens}).\\text{encoder_hidden}[i] \\in \\mathbb{R}^{B \\times 768}$</p>\n<h5 id=\"step-4-text-projection\">Step 4: Text Projection</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">text_projection</span><span class=\"p\">(</span><span class=\"n\">text_raw_features</span><span class=\"p\">)</span>\n<span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"n\">text_features</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{t}_{proj} = \\text{MLP}(\\mathbf{t}_{raw})$\n$= \\text{Linear}(\\text{ReLU}(\\text{Linear}(\\mathbf{t}_{raw})))$\n$\\mathbf{t}_{norm} = \\frac{\\mathbf{t}_{proj}}{||\\mathbf{t}_{proj}||_2} \\in \\mathbb{R}^{B \\times 512}$</p>\n<h4 id=\"33-convergenza-contrastive-learning\">3.3 Convergenza: Contrastive Learning</h4>\n<h5 id=\"step-1-similarity-matrix\">Step 1: Similarity Matrix</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">logits_audio_text</span> <span class=\"o\">=</span> <span class=\"n\">logit_scale_a</span> <span class=\"o\">*</span> <span class=\"n\">audio_features</span> <span class=\"o\">@</span> <span class=\"n\">text_features</span><span class=\"o\">.</span><span class=\"n\">T</span>\n<span class=\"n\">logits_text_audio</span> <span class=\"o\">=</span> <span class=\"n\">logit_scale_t</span> <span class=\"o\">*</span> <span class=\"n\">text_features</span> <span class=\"o\">@</span> <span class=\"n\">audio_features</span><span class=\"o\">.</span><span class=\"n\">T</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathbf{S}_{a \\rightarrow t} = \\tau_a \\cdot \\mathbf{A}_{norm} \\mathbf{T}_{norm}^T \\in \\mathbb{R}^{B \\times B}$\n$\\mathbf{S}_{t \\rightarrow a} = \\tau_t \\cdot \\mathbf{T}_{norm} \\mathbf{A}_{norm}^T \\in \\mathbb{R}^{B \\times B}$</p>\n<p>dove $\\tau_a = \\exp(\\text{logit_scale_a})$, $\\tau_t = \\exp(\\text{logit_scale_t})$.</p>\n<h5 id=\"step-2-contrastive-loss\">Step 2: Contrastive Loss</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">labels</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">arange</span><span class=\"p\">(</span><span class=\"n\">B</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"n\">device</span><span class=\"p\">)</span>  <span class=\"c1\"># [0, 1, 2, ..., B-1]</span>\n<span class=\"n\">loss_a2t</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits_audio_text</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n<span class=\"n\">loss_t2a</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits_text_audio</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n<span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">loss_a2t</span> <span class=\"o\">+</span> <span class=\"n\">loss_t2a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"mi\">2</span>\n</code></pre></div>\n</div>\n</details>\n\n<p>$\\mathcal{L}_{a \\rightarrow t} = -\\frac{1}{B}\\sum_{i=1}^B \\log \\frac{\\exp(\\mathbf{S}_{a \\rightarrow t}[i,i])}{\\sum_{j=1}^B \\exp(\\mathbf{S}_{a \\rightarrow t}[i,j])}$</p>\n<p>$\\mathcal{L}_{t \\rightarrow a} = -\\frac{1}{B}\\sum_{i=1}^B \\log \\frac{\\exp(\\mathbf{S}_{t \\rightarrow a}[i,i])}{\\sum_{j=1}^B \\exp(\\mathbf{S}_{t \\rightarrow a}[i,j])}$</p>\n<p>$\\mathcal{L}_{total} = \\frac{1}{2}(\\mathcal{L}_{a \\rightarrow t} + \\mathcal{L}_{t \\rightarrow a})$</p>\n<h4 id=\"34-riepilogo-dimensionale\">3.4 Riepilogo Dimensionale</h4>\n<table>\n<thead>\n<tr>\n<th>Stage</th>\n<th>Audio Path</th>\n<th>Text Path</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Input</strong></td>\n<td>$[B, 480000]$</td>\n<td><code>\"dog barking\"</code></td>\n</tr>\n<tr>\n<td><strong>Preprocessing</strong></td>\n<td>$[B, 1, 469, 64]$</td>\n<td>$[B, 77]$ tokens</td>\n</tr>\n<tr>\n<td><strong>Backbone</strong></td>\n<td>$[B, 2048]$ (PANN)</td>\n<td>$[B, 512/768]$</td>\n</tr>\n<tr>\n<td><strong>Projection</strong></td>\n<td>$[B, 512]$</td>\n<td>$[B, 512]$</td>\n</tr>\n<tr>\n<td><strong>Normalization</strong></td>\n<td>$||\\mathbf{a}||_2 = 1$</td>\n<td>$||\\mathbf{t}||_2 = 1$</td>\n</tr>\n<tr>\n<td><strong>Similarity</strong></td>\n<td>$\\mathbf{S} \\in [B \\times B]$</td>\n<td></td>\n</tr>\n<tr>\n<td><strong>Loss</strong></td>\n<td>$\\mathcal{L} \\in \\mathbb{R}$ (scalar)</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<p>Questo tracciamento completo mostra come un segnale audio grezzo e testo naturale vengono trasformati attraverso multiple rappresentazioni intermedie fino a convergere in uno spazio embedding condiviso dove la similarità semantica può essere calcolata direttamente tramite prodotto scalare.</p>\n<h4 id=\"31-multi-layer-perceptron-mlp\">3.1 Multi-Layer Perceptron (MLP)</h4>\n<p>La classe <code>MLPLayers</code> implementa reti neurali feed-forward:</p>\n$$\\text{MLP}(x) = \\text{Dropout}(\\text{ReLU}(W_n(\\text{Dropout}(\\text{ReLU}(W_{n-1}(\\ldots W_1 x + b_1 \\ldots) + b_{n-1}))) + b_n))$$\n<p>Dove:\n- $W_i \\in \\mathbb{R}^{d_{i+1} \\times d_i}$ sono le matrici dei pesi\n- $b_i \\in \\mathbb{R}^{d_{i+1}}$ sono i bias\n- $\\text{ReLU}(x) = \\max(0, x)$ è la funzione di attivazione</p>\n<h4 id=\"32-layer-normalization\">3.2 Layer Normalization</h4>\n$$\\text{LayerNorm}(x) = \\gamma \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$$\n<p>Dove:\n- $\\mu = \\frac{1}{d}\\sum_{i=1}^{d} x_i$ (media)\n- $\\sigma^2 = \\frac{1}{d}\\sum_{i=1}^{d} (x_i - \\mu)^2$ (varianza)\n- $\\gamma, \\beta$ sono parametri apprendibili</p>\n<h4 id=\"33-attention-mechanism\">3.3 Attention Mechanism</h4>\n<p>Il meccanismo di attenzione multi-head è definito come:</p>\n$$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h)W^O$$\n<p>Dove ogni head è:\n$$\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$</p>\n<p>E l&rsquo;attention scalata è:\n$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$</p>\n<h3 id=\"4-audio-encoder\">4. Audio Encoder</h3>\n<h4 id=\"41-configurazione-audio\">4.1 Configurazione Audio</h4>\n<p>La configurazione audio (<code>CLAPAudioCfp</code>) specifica:</p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">CLAPAudioCfp</span><span class=\"p\">:</span>\n    <span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;PANN&quot;</span>      <span class=\"c1\"># Tipo di modello (PANN, HTSAT)</span>\n    <span class=\"n\">sample_rate</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">48000</span>      <span class=\"c1\"># Frequenza di campionamento  </span>\n    <span class=\"n\">audio_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span>      <span class=\"c1\"># Lunghezza audio</span>\n    <span class=\"n\">window_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span>       <span class=\"c1\"># Dimensione finestra</span>\n    <span class=\"n\">hop_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">1024</span>          <span class=\"c1\"># Passo sliding window</span>\n    <span class=\"n\">fmin</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">50</span>               <span class=\"c1\"># Frequenza minima mel-spectrogram</span>\n    <span class=\"n\">fmax</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">14000</span>            <span class=\"c1\"># Frequenza massima mel-spectrogram</span>\n    <span class=\"n\">mel_bins</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">64</span>           <span class=\"c1\"># Numero di bin mel</span>\n    <span class=\"n\">clip_samples</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">480000</span>    <span class=\"c1\"># Campioni per clip (10s a 48kHz)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"42-preprocessing-audio\">4.2 Preprocessing Audio</h4>\n<p>Il segnale audio grezzo $x(t)$ viene trasformato in mel-spectrogram usando <code>torchlibrosa</code>:</p>\n<ol>\n<li><strong>Short-Time Fourier Transform (STFT)</strong>:\n   $X[m,k] = \\sum_{n=0}^{N-1} x[n + mH] w[n] e^{-j2\\pi kn/N}$</li>\n</ol>\n<p>Dove:\n   - $m$ è l&rsquo;indice temporale, $k$ è l&rsquo;indice di frequenza\n   - $H$ è l&rsquo;hop size, $w[n]$ è la finestra di Hann</p>\n<ol>\n<li>\n<p><strong>Power Spectrogram</strong>:\n   $S[m,k] = |X[m,k]|^2$</p>\n</li>\n<li>\n<p><strong>Mel-Scale Conversion</strong>:\n   $\\text{mel}(f) = 2595 \\log_{10}\\left(1 + \\frac{f}{700}\\right)$</p>\n</li>\n</ol>\n<p>Il mel-spectrogram è:\n   $M[m,j] = \\log\\left(\\sum_{k} S[m,k] \\cdot H_j[k] + \\epsilon\\right)$</p>\n<p>Dove $H_j[k]$ sono i filtri mel triangolari e $\\epsilon = 10^{-10}$.</p>\n<ol>\n<li><strong>SpecAugmentation</strong>: Durante il training, si applica:</li>\n<li><strong>Time Masking</strong>: Maschera $T$ frame temporali consecutivi</li>\n<li><strong>Frequency Masking</strong>: Maschera $F$ bin di frequenza consecutivi</li>\n</ol>\n<p>$M'[m,j] = \\begin{cases} \n   0 & \\text{se } (m,j) \\text{ è mascherato} \\\\\n   M[m,j] & \\text{altrimenti}\n   \\end{cases}$</p>\n<h4 id=\"43-pann-pretrained-audio-neural-networks\">4.3 PANN (Pretrained Audio Neural Networks)</h4>\n<p>PANN utilizza architetture CNN per il riconoscimento di pattern audio.</p>\n<h5 id=\"431-convolutional-block\">4.3.1 Convolutional Block</h5>\n<p>Il blocco base di PANN è:</p>\n<p>$\\text{ConvBlock}(x) = \\text{Pool}(\\text{ReLU}(\\text{BN}(\\text{Conv2}(\\text{ReLU}(\\text{BN}(\\text{Conv1}(x)))))))$</p>\n<p>Dove:\n- $\\text{Conv1}, \\text{Conv2}$: Convoluzioni $3 \\times 3$\n- $\\text{BN}$: Batch Normalization\n- $\\text{Pool}$: Average/Max Pooling $2 \\times 2$</p>\n<h5 id=\"432-cnn14-architecture\">4.3.2 CNN14 Architecture</h5>\n<p>L&rsquo;architettura CNN14 processa mel-spectrogrammi attraverso:</p>\n<ol>\n<li>\n<p><strong>Feature Extraction</strong>:\n   $x_0 = \\text{BN}_0(\\text{transpose}(M)) \\in \\mathbb{R}^{B \\times 64 \\times T}$</p>\n</li>\n<li>\n<p><strong>Convolutional Layers</strong>:\n   <code>x₁ = ConvBlock₁(x₀) : [B, 1, T, 64] → [B, 64, T/2, 32]\n   x₂ = ConvBlock₂(x₁) : [B, 64, T/2, 32] → [B, 128, T/4, 16]  \n   x₃ = ConvBlock₃(x₂) : [B, 128, T/4, 16] → [B, 256, T/8, 8]\n   x₄ = ConvBlock₄(x₃) : [B, 256, T/8, 8] → [B, 512, T/16, 4]\n   x₅ = ConvBlock₅(x₄) : [B, 512, T/16, 4] → [B, 1024, T/32, 2]\n   x₆ = ConvBlock₆(x₅) : [B, 1024, T/32, 2] → [B, 2048, T/32, 2]</code></p>\n</li>\n<li>\n<p><strong>Temporal Pooling</strong>:\n   $x_{temp} = \\text{mean}(x_6, \\text{dim}=3) \\in \\mathbb{R}^{B \\times 2048 \\times T/32}$</p>\n</li>\n<li>\n<p><strong>Global Pooling</strong>:\n   $x_{global} = \\text{MaxPool1d}(x_{temp}) + \\text{AvgPool1d}(x_{temp})$\n   $x_{final} = \\text{mean}(x_{global}, \\text{dim}=2) \\in \\mathbb{R}^{B \\times 2048}$</p>\n</li>\n<li>\n<p><strong>Output</strong>:\n   $\\text{embedding} = \\text{ReLU}(\\text{FC}_1(x_{final})) \\in \\mathbb{R}^{B \\times 2048}$</p>\n</li>\n</ol>\n<h4 id=\"44-hts-at-hierarchical-token-semantic-audio-transformer\">4.4 HTS-AT (Hierarchical Token-Semantic Audio Transformer)</h4>\n<p>HTS-AT è basato su Swin Transformer e processa mel-spectrogrammi come immagini.</p>\n<h5 id=\"441-patch-embedding\">4.4.1 Patch Embedding</h5>\n<p>Il mel-spectrogram viene diviso in patch non sovrapposte:</p>\n<p>$\\text{patches} = \\text{Conv2d}(M, \\text{kernel_size}=p, \\text{stride}=s)$</p>\n<p>Dove tipicamente $p = s = 4$ per patch $4 \\times 4$.</p>\n<h5 id=\"442-swin-transformer-block\">4.4.2 Swin Transformer Block</h5>\n<p>Ogni blocco Swin implementa:</p>\n<ol>\n<li><strong>Window Attention</strong>:\n   $\\text{W-MSA}(X) = \\text{Attention}(\\text{partition}(X))$</li>\n</ol>\n<p>Dove $\\text{partition}(X)$ divide $X$ in finestre $W \\times W$.</p>\n<ol>\n<li>\n<p><strong>Shifted Window Attention</strong>:\n   $\\text{SW-MSA}(X) = \\text{W-MSA}(\\text{shift}(X, W/2))$</p>\n</li>\n<li>\n<p><strong>Complete Block</strong>:\n   $X^{l+1}_1 = \\text{W-MSA/SW-MSA}(\\text{LN}(X^l)) + X^l$\n   $X^{l+1} = \\text{MLP}(\\text{LN}(X^{l+1}_1)) + X^{l+1}_1$</p>\n</li>\n</ol>\n<h5 id=\"443-hierarchical-feature-extraction\">4.4.3 Hierarchical Feature Extraction</h5>\n<p>HTS-AT utilizza 4 stage con patch merging:</p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code>Stage 1: [B, H/4×W/4, C]     → [B, H/8×W/8, 2C]    (PatchMerging)\nStage 2: [B, H/8×W/8, 2C]    → [B, H/16×W/16, 4C]  (PatchMerging) \nStage 3: [B, H/16×W/16, 4C]  → [B, H/32×W/32, 8C]  (PatchMerging)\nStage 4: [B, H/32×W/32, 8C]  → [B, H/32×W/32, 8C]  (No merging)\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"444-token-semantic-module\">4.4.4 Token-Semantic Module</h5>\n<p>Per la classificazione audio, HTS-AT usa:</p>\n<ol>\n<li>\n<p><strong>Frequency Grouping</strong>:\n   $x_{grouped} = \\text{reshape}(x, [B, C, F//r, r, T])$\n   $x_{pooled} = \\text{mean}(x_{grouped}, \\text{dim}=3)$</p>\n</li>\n<li>\n<p><strong>Temporal Class Activation Map (TSCAM)</strong>:\n   $\\text{TSCAM} = \\text{Conv2d}(x_{pooled}, \\text{out_channels}=\\text{num_classes})$</p>\n</li>\n<li>\n<p><strong>Frame-wise Output</strong>:\n   $\\text{fpx} = \\text{interpolate}(\\text{sigmoid}(\\text{TSCAM}))$</p>\n</li>\n</ol>\n<h4 id=\"45-feature-fusion\">4.5 Feature Fusion</h4>\n<p>CLAP supporta diverse strategie di fusione per audio lunghi:</p>\n<h5 id=\"451-1d-fusion-dafaffiaff\">4.5.1 1D Fusion (DAF/AFF/iAFF)</h5>\n<p>Per audio &gt; 10s, si processano segmenti locali:</p>\n<p>$x_{local} = \\text{Conv1d}(x_{segments}, \\text{kernel}=5, \\text{stride}=3)$\n$x_{fused} = \\text{FusionModule}(x_{global}, x_{local})$</p>\n<h5 id=\"452-2d-fusion\">4.5.2 2D Fusion</h5>\n<p>Fusione a livello di feature map 2D:</p>\n<p>$x_{fused} = \\text{FusionModule}(x_{global}, \\text{Conv2d}(x_{local}))$</p>\n<h4 id=\"46-audio-projection\">4.6 Audio Projection</h4>\n<p>L&rsquo;output dell&rsquo;audio encoder viene proiettato nello spazio comune:</p>\n<p>$\\mathbf{a}_{proj} = \\text{MLP}_{\\text{audio}}(\\phi_{\\text{audio}}(\\mathbf{x}_{audio}))$</p>\n<p>Dove:\n- $\\phi_{\\text{audio}}: \\mathbb{R}^{T \\times F} \\rightarrow \\mathbb{R}^{d_{audio}}$ è l&rsquo;audio encoder\n- $\\text{MLP}_{\\text{audio}}: \\mathbb{R}^{d_{audio}} \\rightarrow \\mathbb{R}^{d_{joint}}$ è la proiezione</p>\n<h3 id=\"5-text-encoder\">5. Text Encoder</h3>\n<h4 id=\"51-configurazione-text\">5.1 Configurazione Text</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"nd\">@dataclass</span>\n<span class=\"k\">class</span><span class=\"w\"> </span><span class=\"nc\">CLAPTextCfg</span><span class=\"p\">:</span>\n    <span class=\"n\">context_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>    <span class=\"c1\"># Lunghezza massima sequenza</span>\n    <span class=\"n\">vocab_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>       <span class=\"c1\"># Dimensione vocabolario</span>\n    <span class=\"n\">width</span><span class=\"p\">:</span> <span class=\"nb\">int</span>           <span class=\"c1\"># Dimensione embedding</span>\n    <span class=\"n\">heads</span><span class=\"p\">:</span> <span class=\"nb\">int</span>           <span class=\"c1\"># Numero attention heads</span>\n    <span class=\"n\">layers</span><span class=\"p\">:</span> <span class=\"nb\">int</span>          <span class=\"c1\"># Numero layer transformer</span>\n    <span class=\"n\">model_type</span><span class=\"p\">:</span> <span class=\"nb\">str</span>      <span class=\"c1\"># Tipo modello (transformer, bert, roberta, bart)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"52-transformer-text-encoder\">5.2 Transformer Text Encoder</h4>\n<p>Per il tipo &ldquo;transformer&rdquo;, il testo viene processato come segue:</p>\n<ol>\n<li>\n<p><strong>Token Embedding</strong>:\n   $$\\mathbf{E} = \\text{Embedding}(\\text{tokens}) \\in \\mathbb{R}^{L \\times d}$$</p>\n</li>\n<li>\n<p><strong>Positional Embedding</strong>:\n   $$\\mathbf{X}_0 = \\mathbf{E} + \\mathbf{P} \\in \\mathbb{R}^{L \\times d}$$</p>\n</li>\n</ol>\n<p>Dove $\\mathbf{P}$ sono embedding posizionali apprendibili.</p>\n<ol>\n<li><strong>Transformer Layers</strong>:\n   Per ogni layer $l = 1, \\ldots, L$:</li>\n</ol>\n$$\\mathbf{X}_l^{(1)} = \\mathbf{X}_{l-1} + \\text{MultiHead}(\\text{LayerNorm}(\\mathbf{X}_{l-1}))$$\n$$\\mathbf{X}_l = \\mathbf{X}_l^{(1)} + \\text{MLP}(\\text{LayerNorm}(\\mathbf{X}_l^{(1)}))$$\n<ol>\n<li><strong>Final Processing</strong>:\n   $$\\mathbf{t}_{raw} = \\text{LayerNorm}(\\mathbf{X}_L[\\text{EOS_position}, :])$$</li>\n</ol>\n$$\\mathbf{t}_{proj} = \\text{MLP}_{\\text{text}}(\\mathbf{t}_{raw})$$\n<h4 id=\"53-pre-trained-text-encoders\">5.3 Pre-trained Text Encoders</h4>\n<p>Per modelli pre-addestrati (BERT, RoBERTa, BART):</p>\n<ul>\n<li><strong>BERT/RoBERTa</strong>: Si usa il <code>pooler_output</code></li>\n<li><strong>BART</strong>: Si fa la media degli stati nascosti dell&rsquo;encoder</li>\n</ul>\n$$\\mathbf{t}_{raw} = \\begin{cases}\n\\text{BERT/RoBERTa}(\\text{tokens}).\\text{pooler_output} \\\\\n\\text{mean}(\\text{BART}(\\text{tokens}).\\text{encoder_last_hidden_state}, \\text{dim}=1)\n\\end{cases}$$\n<h3 id=\"6-apprendimento-contrastivo\">6. Apprendimento Contrastivo</h3>\n<h4 id=\"61-similarita-e-logit-scale\">6.1 Similarità e Logit Scale</h4>\n<p>Il modello apprende due parametri di scala logaritmici:</p>\n$$\\tau_a = \\exp(\\log(\\tau_a)), \\quad \\tau_t = \\exp(\\log(\\tau_t))$$\n<p>Inizializzati a $\\log(1/0.07) \\approx 2.66$.</p>\n<h4 id=\"62-matrice-di-similarita\">6.2 Matrice di Similarità</h4>\n<p>Data una batch di $N$ coppie audio-testo, si calcolano:</p>\n$$\\mathbf{A} = [\\mathbf{a}_1, \\mathbf{a}_2, \\ldots, \\mathbf{a}_N]^T \\in \\mathbb{R}^{N \\times d}$$\n$$\\mathbf{T} = [\\mathbf{t}_1, \\mathbf{t}_2, \\ldots, \\mathbf{t}_N]^T \\in \\mathbb{R}^{N \\times d}$$\n<p>Dopo normalizzazione L2:\n$$\\hat{\\mathbf{A}} = \\frac{\\mathbf{A}}{||\\mathbf{A}||_2}, \\quad \\hat{\\mathbf{T}} = \\frac{\\mathbf{T}}{||\\mathbf{T}||_2}$$</p>\n<p>La matrice di similarità è:\n$$\\mathbf{S} = \\tau \\hat{\\mathbf{A}} \\hat{\\mathbf{T}}^T \\in \\mathbb{R}^{N \\times N}$$</p>\n<h4 id=\"63-contrastive-loss\">6.3 Contrastive Loss</h4>\n<p>La loss contrastiva simmetrica è:</p>\n$$\\mathcal{L}_{\\text{contrastive}} = \\frac{1}{2}(\\mathcal{L}_{a \\rightarrow t} + \\mathcal{L}_{t \\rightarrow a})$$\n<p>Dove:\n$$\\mathcal{L}_{a \\rightarrow t} = -\\frac{1}{N}\\sum_{i=1}^N \\log \\frac{\\exp(S_{ii})}{\\sum_{j=1}^N \\exp(S_{ij})}$$</p>\n$$\\mathcal{L}_{t \\rightarrow a} = -\\frac{1}{N}\\sum_{i=1}^N \\log \\frac{\\exp(S_{ii})}{\\sum_{j=1}^N \\exp(S_{ji})}$$\n<h3 id=\"7-training-e-inference\">7. Training e Inference</h3>\n<h4 id=\"71-forward-pass\">7.1 Forward Pass</h4>\n<p>Il forward pass completo restituisce:</p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">forward</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">audio</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Encoding</span>\n    <span class=\"n\">audio_features</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">audio_projection</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encode_audio</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)[</span><span class=\"s2\">&quot;embedding&quot;</span><span class=\"p\">])</span>\n    <span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">encode_text</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">device</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Normalization</span>\n    <span class=\"n\">audio_features</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"n\">audio_features</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n    <span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">normalize</span><span class=\"p\">(</span><span class=\"n\">text_features</span><span class=\"p\">,</span> <span class=\"n\">dim</span><span class=\"o\">=-</span><span class=\"mi\">1</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># MLP transforms</span>\n    <span class=\"n\">audio_features_mlp</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">audio_transform</span><span class=\"p\">(</span><span class=\"n\">audio_features</span><span class=\"p\">)</span>\n    <span class=\"n\">text_features_mlp</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">text_transform</span><span class=\"p\">(</span><span class=\"n\">text_features</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"p\">(</span><span class=\"n\">audio_features</span><span class=\"p\">,</span> <span class=\"n\">text_features</span><span class=\"p\">,</span> \n            <span class=\"n\">audio_features_mlp</span><span class=\"p\">,</span> <span class=\"n\">text_features_mlp</span><span class=\"p\">,</span>\n            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logit_scale_a</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">(),</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">logit_scale_t</span><span class=\"o\">.</span><span class=\"n\">exp</span><span class=\"p\">())</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"72-inference\">7.2 Inference</h4>\n<p>Durante l&rsquo;inference:</p>\n<ol>\n<li><strong>Text-to-Audio Retrieval</strong>:</li>\n<li>Calcola embedding testo: $\\mathbf{t}_{query}$</li>\n<li>Calcola embedding audio database: $\\{\\mathbf{a}_i\\}_{i=1}^M$</li>\n<li>\n<p>Trova: $i^* = \\argmax_i \\mathbf{t}_{query}^T \\mathbf{a}_i$</p>\n</li>\n<li>\n<p><strong>Audio-to-Text Retrieval</strong>:</p>\n</li>\n<li>Analogo ma con ruoli invertiti</li>\n</ol>\n<h4 id=\"73-audio-inference-con-sliding-window\">7.3 Audio Inference con Sliding Window</h4>\n<p>Per audio lunghi, si usa una sliding window:</p>\n$$\\text{Audio_segments} = \\{x[i:i+L] : i = 0, H, 2H, \\ldots\\}$$\n<p>Gli embedding vengono mediati o concatenati:\n$$\\mathbf{a}_{final} = \\frac{1}{|\\text{segments}|}\\sum_{\\text{seg}} \\phi_{\\text{audio}}(\\text{seg})$$</p>\n<h3 id=\"8-funzioni-di-utilita-e-ottimizzazioni\">8. Funzioni di Utilità e Ottimizzazioni</h3>\n<h4 id=\"81-mixup-data-augmentation\">8.1 Mixup Data Augmentation</h4>\n<p>Il mixup combina coppie di esempi di training:</p>\n<p>$x_{mix} = \\lambda x_i + (1-\\lambda) x_j$\n$y_{mix} = \\lambda y_i + (1-\\lambda) y_j$</p>\n<p>Dove $\\lambda \\sim \\text{Beta}(\\alpha, \\alpha)$. L&rsquo;implementazione <code>do_mixup</code> applica:</p>\n<p>$\\text{out} = x \\cdot \\lambda^T + \\text{flip}(x) \\cdot (1-\\lambda)^T$</p>\n<h4 id=\"82-interpolazione-temporale\">8.2 Interpolazione Temporale</h4>\n<p>Per compensare la riduzione di risoluzione, si usa interpolazione:</p>\n<p>$\\text{interpolate}(x, r) = \\text{repeat}(x[:,:,\\text{None},:], [1,1,r,1]).\\text{reshape}(B, T \\cdot r, C)$</p>\n<h4 id=\"83-batch-normalization-freezing\">8.3 Batch Normalization Freezing</h4>\n<p>La funzione <code>freeze_batch_norm_2d</code> converte BatchNorm in FrozenBatchNorm:</p>\n<p>$\\text{FrozenBN}(x) = \\gamma \\frac{x - \\mu_{frozen}}{\\sqrt{\\sigma_{frozen}^2 + \\epsilon}} + \\beta$</p>\n<p>Dove $\\mu_{frozen}$ e $\\sigma_{frozen}^2$ sono fissi (non aggiornati durante training).</p>\n<h4 id=\"84-gestione-dataset-multi-dominio\">8.4 Gestione Dataset Multi-dominio</h4>\n<p>CLAP supporta oltre 30 dataset audio diversi tramite configurazione unificata:</p>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">dataset_split</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s2\">&quot;audiocaps&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">&quot;train&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;valid&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;test&quot;</span><span class=\"p\">],</span>\n    <span class=\"s2\">&quot;audioset&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">&quot;balanced_train&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;unbalanced_train&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;eval&quot;</span><span class=\"p\">],</span>\n    <span class=\"s2\">&quot;clotho&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">&quot;train&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;test&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;valid&quot;</span><span class=\"p\">],</span>\n    <span class=\"s2\">&quot;esc50&quot;</span><span class=\"p\">:</span> <span class=\"p\">[</span><span class=\"s2\">&quot;train&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;test&quot;</span><span class=\"p\">],</span>\n    <span class=\"c1\"># ... molti altri</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n</div>\n</details>\n\n<h3 id=\"9-architetture-supportate-e-configurazioni\">9. Architetture Supportate e Configurazioni</h3>\n<h4 id=\"91-combinazioni-audio-text-encoder\">9.1 Combinazioni Audio-Text Encoder</h4>\n<p>Il modello supporta diverse combinazioni encoder:</p>\n<table>\n<thead>\n<tr>\n<th>Audio Encoder</th>\n<th>Text Encoder</th>\n<th>Embedding Dim</th>\n<th>Descrizione</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>PANN-CNN14</strong></td>\n<td>Transformer</td>\n<td>2048 → 512</td>\n<td>CNN profondo + Custom Transformer</td>\n</tr>\n<tr>\n<td><strong>PANN-CNN14</strong></td>\n<td>BERT</td>\n<td>2048 → 512</td>\n<td>CNN profondo + BERT pre-addestrato</td>\n</tr>\n<tr>\n<td><strong>PANN-CNN14</strong></td>\n<td>RoBERTa</td>\n<td>2048 → 512</td>\n<td>CNN profondo + RoBERTa</td>\n</tr>\n<tr>\n<td><strong>PANN-CNN14</strong></td>\n<td>BART</td>\n<td>2048 → 512</td>\n<td>CNN profondo + BART encoder</td>\n</tr>\n<tr>\n<td><strong>HTS-AT-Tiny</strong></td>\n<td>Transformer</td>\n<td>768 → 512</td>\n<td>Swin Transformer piccolo</td>\n</tr>\n<tr>\n<td><strong>HTS-AT-Base</strong></td>\n<td>BERT</td>\n<td>1024 → 512</td>\n<td>Swin Transformer medio</td>\n</tr>\n<tr>\n<td><strong>HTS-AT-Large</strong></td>\n<td>RoBERTa</td>\n<td>2048 → 512</td>\n<td>Swin Transformer grande</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"92-configurazioni-hts-at\">9.2 Configurazioni HTS-AT</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># HTS-AT Tiny</span>\n<span class=\"n\">HTSAT_Swin_Transformer</span><span class=\"p\">(</span>\n    <span class=\"n\">embed_dim</span><span class=\"o\">=</span><span class=\"mi\">96</span><span class=\"p\">,</span> <span class=\"n\">depths</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">6</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">],</span> \n    <span class=\"n\">num_heads</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">],</span> <span class=\"n\">window_size</span><span class=\"o\">=</span><span class=\"mi\">8</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># HTS-AT Base  </span>\n<span class=\"n\">HTSAT_Swin_Transformer</span><span class=\"p\">(</span>\n    <span class=\"n\">embed_dim</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">depths</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">12</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">],</span>\n    <span class=\"n\">num_heads</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">],</span> <span class=\"n\">window_size</span><span class=\"o\">=</span><span class=\"mi\">8</span>\n<span class=\"p\">)</span>\n\n<span class=\"c1\"># HTS-AT Large</span>\n<span class=\"n\">HTSAT_Swin_Transformer</span><span class=\"p\">(</span>\n    <span class=\"n\">embed_dim</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">depths</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">,</span><span class=\"mi\">12</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">],</span> \n    <span class=\"n\">num_heads</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">,</span><span class=\"mi\">8</span><span class=\"p\">,</span><span class=\"mi\">16</span><span class=\"p\">,</span><span class=\"mi\">32</span><span class=\"p\">],</span> <span class=\"n\">window_size</span><span class=\"o\">=</span><span class=\"mi\">8</span>\n<span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"93-supporto-timmmodel-opzionale\">9.3 Supporto TimmModel (Opzionale)</h4>\n<p>Per encoder visuali alternativi, il modello supporta architetture timm:</p>\n<p>$\\text{TimmEncoder}(x) = \\text{Head}(\\text{TimmBackbone}(x))$</p>\n<p>Dove Head può essere:\n- <strong>Linear</strong>: $\\text{Head} = \\text{Dropout} \\rightarrow \\text{Linear}$<br />\n- <strong>MLP</strong>: $\\text{Head} = \\text{MLP}(d, 2d, d_{embed})$\n- <strong>Attention Pool</strong>: $\\text{Head} = \\text{AttentionPool2d}$</p>\n<h3 id=\"10-training-e-inference-avanzate\">10. Training e Inference Avanzate</h3>\n<h4 id=\"101-multi-length-audio-processing\">10.1 Multi-length Audio Processing</h4>\n<p>Per audio di lunghezza variabile:</p>\n<ol>\n<li><strong>Audio Corti</strong> (&lt; 10s):</li>\n<li>Ripetizione: $x_{padded} = \\text{repeat}(x, k)$ dove $k = \\lceil 10s / |x| \\rceil$</li>\n<li>\n<p>Interpolazione bicubica per matching dimensioni</p>\n</li>\n<li>\n<p><strong>Audio Lunghi</strong> (&gt; 10s):  </p>\n</li>\n<li><strong>Training</strong>: Crop casuale a 10s</li>\n<li><strong>Inference</strong>: Sliding window con averaging</li>\n</ol>\n<p>$\\text{embedding}_{final} = \\frac{1}{N} \\sum_{i=1}^{N} \\phi(x[i \\cdot h : i \\cdot h + w])$</p>\n<p>Dove $h$ è hop size, $w$ è window size.</p>\n<h4 id=\"102-fusion-strategies\">10.2 Fusion Strategies</h4>\n<h5 id=\"channel-map-fusion\">Channel Map Fusion</h5>\n<p>Concatenazione di 4 canali:\n$x_{fused} = \\text{Conv2d}([\\text{global}, \\text{local}_1, \\text{local}_2, \\text{local}_3])$</p>\n<h5 id=\"attention-feature-fusion-aff\">Attention Feature Fusion (AFF)</h5>\n<p>$\\text{AFF}(x_g, x_l) = x_g \\odot \\sigma(\\text{Conv}(x_g + x_l)) + x_l \\odot (1 - \\sigma(\\text{Conv}(x_g + x_l)))$</p>\n<h5 id=\"iterative-aff-iaff\">Iterative AFF (iAFF)</h5>\n<p>$x^{(0)} = x_g, \\quad x^{(k+1)} = \\text{AFF}(x^{(k)}, x_l)$</p>\n<h4 id=\"103-gradient-scaling-e-stabilizzazione\">10.3 Gradient Scaling e Stabilizzazione</h4>\n<p>Il training usa due parametri di scala separati:</p>\n<p>$\\mathcal{L} = \\frac{1}{2}[\\mathcal{L}_{\\text{audio→text}}(\\tau_a) + \\mathcal{L}_{\\text{text→audio}}(\\tau_t)]$</p>\n<p>Inizializzati a $\\tau_a = \\tau_t = \\exp(\\log(1/0.07))$ e apprendibili.</p>\n<h3 id=\"11-vantaggi-e-limitazioni\">11. Vantaggi e Limitazioni</h3>\n<h4 id=\"111-vantaggi-architetturali\">11.1 Vantaggi Architetturali</h4>\n<ol>\n<li><strong>Flessibilità Multimodale</strong>: Architettura modulare consente diverse combinazioni encoder</li>\n<li><strong>Scalabilità</strong>: Supporta da modelli leggeri (96M params) a grandi (300M+ params)  </li>\n<li><strong>Robustezza</strong>: SpecAugmentation e Mixup migliorano generalizzazione</li>\n<li><strong>Efficienza</strong>: Supporto sliding window per audio lunghi</li>\n<li><strong>Zero-shot Capability</strong>: Generalizza senza fine-tuning specifico</li>\n</ol>\n<h4 id=\"112-innovazioni-tecniche\">11.2 Innovazioni Tecniche</h4>\n<ul>\n<li><strong>Hierarchical Audio Processing</strong>: HTS-AT cattura pattern multi-scala</li>\n<li><strong>Feature Fusion</strong>: Integra informazioni globali e locali per audio lunghi</li>\n<li><strong>Contrastive Learning</strong>: Apprende rappresentazioni semanticamente significative</li>\n<li><strong>Multi-dataset Training</strong>: Training unificato su 30+ dataset</li>\n</ul>\n<h4 id=\"113-limitazioni\">11.3 Limitazioni</h4>\n<ol>\n<li><strong>Computational Cost</strong>: Transformer attention ha complessità $O(n^2)$</li>\n<li><strong>Memory Requirements</strong>: Processing audio lunghi richiede molta memoria</li>\n<li><strong>Domain Gap</strong>: Performance varia tra domini audio diversi</li>\n<li><strong>Language Limitation</strong>: Principalmente ottimizzato per inglese</li>\n</ol>\n<h3 id=\"12-implementazione-e-best-practices\">12. Implementazione e Best Practices</h3>\n<h4 id=\"121-configurazione-training\">12.1 Configurazione Training</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Configurazione ottimale per training</span>\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">&#39;batch_size&#39;</span><span class=\"p\">:</span> <span class=\"mi\">32</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;learning_rate&#39;</span><span class=\"p\">:</span> <span class=\"mf\">1e-4</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;optimizer&#39;</span><span class=\"p\">:</span> <span class=\"s1\">&#39;AdamW&#39;</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;weight_decay&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;mixup_alpha&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.4</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;spec_augment&#39;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>\n    <span class=\"s1\">&#39;gradient_clipping&#39;</span><span class=\"p\">:</span> <span class=\"mf\">1.0</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"122-preprocessing-pipeline\">12.2 Preprocessing Pipeline</h4>\n<ol>\n<li><strong>Audio Loading</strong>: Resample a 48kHz, mono</li>\n<li><strong>Length Normalization</strong>: Pad/Crop a 10s (480k samples)  </li>\n<li><strong>Mel-Spectrogram</strong>: 64 mel bins, hop_size=1024</li>\n<li><strong>Normalization</strong>: BatchNorm per frequenza</li>\n<li><strong>Augmentation</strong>: SpecAugment durante training</li>\n</ol>\n<h4 id=\"123-inference-ottimizzata\">12.3 Inference Ottimizzata</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">efficient_inference</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">,</span> <span class=\"n\">text_query</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Pre-compute text embedding (cache-able)</span>\n    <span class=\"n\">text_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encode_text</span><span class=\"p\">(</span><span class=\"n\">text_query</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Process audio with sliding window if long</span>\n    <span class=\"k\">if</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)</span> <span class=\"o\">&gt;</span> <span class=\"mi\">480000</span><span class=\"p\">:</span>\n        <span class=\"n\">audio_embed</span> <span class=\"o\">=</span> <span class=\"n\">sliding_window_inference</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)</span>\n    <span class=\"k\">else</span><span class=\"p\">:</span>\n        <span class=\"n\">audio_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encode_audio</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Compute similarity</span>\n    <span class=\"n\">similarity</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cosine_similarity</span><span class=\"p\">(</span><span class=\"n\">text_embed</span><span class=\"p\">,</span> <span class=\"n\">audio_embed</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">similarity</span>\n</code></pre></div>\n</div>\n</details>\n\n<h3 id=\"9-vantaggi-e-applicazioni\">9. Vantaggi e Applicazioni</h3>\n<h4 id=\"91-vantaggi\">9.1 Vantaggi</h4>\n<ol>\n<li><strong>Multimodalità</strong>: Apprende rappresentazioni condivise audio-testo</li>\n<li><strong>Scalabilità</strong>: Supporta diversi encoder pre-addestrati  </li>\n<li><strong>Flessibilità</strong>: Configurabile per diversi task</li>\n<li><strong>Zero-shot</strong>: Può generalizzare senza fine-tuning specifico</li>\n</ol>\n<h4 id=\"92-applicazioni\">9.2 Applicazioni</h4>\n<ul>\n<li><strong>Audio Classification</strong>: Usando descrizioni testuali come classi</li>\n<li><strong>Audio Retrieval</strong>: Ricerca audio tramite query testuali</li>\n<li><strong>Audio Captioning</strong>: Generazione automatica didascalie</li>\n<li><strong>Cross-modal Understanding</strong>: Comprensione audio-testuale</li>\n</ul>\n<h3 id=\"10-considerazioni-implementative\">10. Considerazioni Implementative</h3>\n<h4 id=\"101-efficienza-computazionale\">10.1 Efficienza Computazionale</h4>\n<ul>\n<li><strong>Batch Processing</strong>: Processamento parallelo di audio e testo</li>\n<li><strong>Mixed Precision</strong>: Supporto FP16 per ridurre memoria</li>\n<li><strong>Gradient Checkpointing</strong>: Per modelli grandi</li>\n</ul>\n<h4 id=\"102-memory-management\">10.2 Memory Management</h4>\n<ul>\n<li><strong>Audio Chunking</strong>: Per file audio lunghi</li>\n<li><strong>Dynamic Batching</strong>: Batch size adattivi</li>\n<li><strong>Caching</strong>: Cache degli embedding frequenti</li>\n</ul>\n<h3 id=\"16-troubleshooting-e-debug\">16. Troubleshooting e Debug</h3>\n<h4 id=\"161-problemi-comuni-durante-training\">16.1 Problemi Comuni Durante Training</h4>\n<h5 id=\"memory-overflow\">Memory Overflow</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Problema: RuntimeError: CUDA out of memory</span>\n<span class=\"c1\"># Soluzioni:</span>\n<span class=\"mf\">1.</span> <span class=\"n\">Ridurre</span> <span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"n\">batch_size</span> <span class=\"o\">=</span> <span class=\"mi\">16</span> <span class=\"err\">→</span> <span class=\"mi\">8</span>\n<span class=\"mf\">2.</span> <span class=\"n\">Gradient</span> <span class=\"n\">checkpointing</span><span class=\"p\">:</span> <span class=\"n\">use_checkpoint</span><span class=\"o\">=</span><span class=\"kc\">True</span> <span class=\"ow\">in</span> <span class=\"n\">HTS</span><span class=\"o\">-</span><span class=\"n\">AT</span>\n<span class=\"mf\">3.</span> <span class=\"n\">Mixed</span> <span class=\"n\">precision</span> <span class=\"n\">training</span><span class=\"p\">:</span>\n   <span class=\"kn\">from</span><span class=\"w\"> </span><span class=\"nn\">torch.cuda.amp</span><span class=\"w\"> </span><span class=\"kn\">import</span> <span class=\"n\">autocast</span><span class=\"p\">,</span> <span class=\"n\">GradScaler</span>\n   <span class=\"n\">scaler</span> <span class=\"o\">=</span> <span class=\"n\">GradScaler</span><span class=\"p\">()</span>\n   <span class=\"k\">with</span> <span class=\"n\">autocast</span><span class=\"p\">():</span>\n       <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"gradient-explosion\">Gradient Explosion</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Sintomo: Loss diventa NaN o esplode</span>\n<span class=\"c1\"># Diagnosi:</span>\n<span class=\"k\">for</span> <span class=\"n\">name</span><span class=\"p\">,</span> <span class=\"n\">param</span> <span class=\"ow\">in</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">named_parameters</span><span class=\"p\">():</span>\n    <span class=\"k\">if</span> <span class=\"n\">param</span><span class=\"o\">.</span><span class=\"n\">grad</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n        <span class=\"n\">grad_norm</span> <span class=\"o\">=</span> <span class=\"n\">param</span><span class=\"o\">.</span><span class=\"n\">grad</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">norm</span><span class=\"p\">(</span><span class=\"mi\">2</span><span class=\"p\">)</span>\n        <span class=\"k\">if</span> <span class=\"n\">grad_norm</span> <span class=\"o\">&gt;</span> <span class=\"mf\">10.0</span><span class=\"p\">:</span>\n            <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Large gradient in </span><span class=\"si\">{</span><span class=\"n\">name</span><span class=\"si\">}</span><span class=\"s2\">: </span><span class=\"si\">{</span><span class=\"n\">grad_norm</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Soluzione: Gradient clipping</span>\n<span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">nn</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">clip_grad_norm_</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">parameters</span><span class=\"p\">(),</span> <span class=\"n\">max_norm</span><span class=\"o\">=</span><span class=\"mf\">1.0</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"dimensioni-tensor-mismatch\">Dimensioni Tensor Mismatch</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Debug delle dimensioni attraverso la pipeline</span>\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">debug_tensor_shapes</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"n\">audio</span><span class=\"p\">,</span> <span class=\"n\">text</span><span class=\"p\">):</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Input audio shape: </span><span class=\"si\">{</span><span class=\"n\">audio</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Input text shape: </span><span class=\"si\">{</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Audio pathway</span>\n    <span class=\"k\">if</span> <span class=\"nb\">hasattr</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"p\">,</span> <span class=\"s1\">&#39;spectrogram_extractor&#39;</span><span class=\"p\">):</span>\n        <span class=\"n\">spec</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">spectrogram_extractor</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Spectrogram shape: </span><span class=\"si\">{</span><span class=\"n\">spec</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n        <span class=\"n\">mel</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">logmel_extractor</span><span class=\"p\">(</span><span class=\"n\">spec</span><span class=\"p\">)</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Mel-spectrogram shape: </span><span class=\"si\">{</span><span class=\"n\">mel</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Feature extraction</span>\n    <span class=\"n\">audio_features</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encode_audio</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Audio features shape: </span><span class=\"si\">{</span><span class=\"n\">audio_features</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n\n    <span class=\"n\">text_features</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">encode_text</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span>\n    <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Text features shape: </span><span class=\"si\">{</span><span class=\"n\">text_features</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"162-convergenza-issues\">16.2 Convergenza Issues</h4>\n<h5 id=\"loss-non-diminuisce\">Loss non diminuisce</h5>\n<ol>\n<li><strong>Learning Rate</strong>: Troppo alto (&gt;1e-3) o troppo basso (&lt;1e-6)</li>\n<li><strong>Temperature Scaling</strong>: Verificare inizializzazione logit_scale</li>\n<li><strong>Data Quality</strong>: Audio corrotti o testo non tokenizzato correttamente</li>\n</ol>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Check temperature values</span>\n<span class=\"n\">logit_scale_a</span><span class=\"p\">,</span> <span class=\"n\">logit_scale_t</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_logit_scale</span><span class=\"p\">()</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Temperature audio: </span><span class=\"si\">{</span><span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"n\">logit_scale_a</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n<span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Temperature text: </span><span class=\"si\">{</span><span class=\"mi\">1</span><span class=\"o\">/</span><span class=\"n\">logit_scale_t</span><span class=\"si\">:</span><span class=\"s2\">.4f</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n<span class=\"c1\"># Valori normali: 0.05-0.15</span>\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"overfitting\">Overfitting</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Sintomi: Train accuracy alta, val accuracy bassa</span>\n<span class=\"c1\"># Soluzioni:</span>\n<span class=\"n\">config</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n    <span class=\"s1\">&#39;dropout&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.3</span><span class=\"p\">,</span>           <span class=\"c1\"># Aumentare dropout</span>\n    <span class=\"s1\">&#39;weight_decay&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.1</span><span class=\"p\">,</span>      <span class=\"c1\"># Aumentare regolarizzazione</span>\n    <span class=\"s1\">&#39;spec_augment&#39;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span>     <span class=\"c1\"># Attivare data augmentation</span>\n    <span class=\"s1\">&#39;mixup_alpha&#39;</span><span class=\"p\">:</span> <span class=\"mf\">0.4</span><span class=\"p\">,</span>       <span class=\"c1\"># Aumentare mixup strength</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"163-audio-processing-issues\">16.3 Audio Processing Issues</h4>\n<h5 id=\"formato-audio-non-supportato\">Formato Audio non Supportato</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">torchaudio</span>\n\n<span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">robust_audio_loading</span><span class=\"p\">(</span><span class=\"n\">file_path</span><span class=\"p\">):</span>\n    <span class=\"k\">try</span><span class=\"p\">:</span>\n        <span class=\"n\">waveform</span><span class=\"p\">,</span> <span class=\"n\">sr</span> <span class=\"o\">=</span> <span class=\"n\">torchaudio</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">file_path</span><span class=\"p\">)</span>\n    <span class=\"k\">except</span> <span class=\"ne\">Exception</span> <span class=\"k\">as</span> <span class=\"n\">e</span><span class=\"p\">:</span>\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"sa\">f</span><span class=\"s2\">&quot;Error loading </span><span class=\"si\">{</span><span class=\"n\">file_path</span><span class=\"si\">}</span><span class=\"s2\">: </span><span class=\"si\">{</span><span class=\"n\">e</span><span class=\"si\">}</span><span class=\"s2\">&quot;</span><span class=\"p\">)</span>\n        <span class=\"c1\"># Fallback usando librosa</span>\n        <span class=\"kn\">import</span><span class=\"w\"> </span><span class=\"nn\">librosa</span>\n        <span class=\"n\">waveform</span><span class=\"p\">,</span> <span class=\"n\">sr</span> <span class=\"o\">=</span> <span class=\"n\">librosa</span><span class=\"o\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">file_path</span><span class=\"p\">,</span> <span class=\"n\">sr</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">)</span>\n        <span class=\"n\">waveform</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">(</span><span class=\"n\">waveform</span><span class=\"p\">)</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n\n    <span class=\"c1\"># Resample se necessario</span>\n    <span class=\"k\">if</span> <span class=\"n\">sr</span> <span class=\"o\">!=</span> <span class=\"mi\">48000</span><span class=\"p\">:</span>\n        <span class=\"n\">resampler</span> <span class=\"o\">=</span> <span class=\"n\">torchaudio</span><span class=\"o\">.</span><span class=\"n\">transforms</span><span class=\"o\">.</span><span class=\"n\">Resample</span><span class=\"p\">(</span><span class=\"n\">sr</span><span class=\"p\">,</span> <span class=\"mi\">48000</span><span class=\"p\">)</span>\n        <span class=\"n\">waveform</span> <span class=\"o\">=</span> <span class=\"n\">resampler</span><span class=\"p\">(</span><span class=\"n\">waveform</span><span class=\"p\">)</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">waveform</span><span class=\"p\">,</span> <span class=\"mi\">48000</span>\n</code></pre></div>\n</div>\n</details>\n\n<h5 id=\"audio-troppo-corto-o-lungo\">Audio Troppo Corto o Lungo</h5>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">preprocess_audio_length</span><span class=\"p\">(</span><span class=\"n\">waveform</span><span class=\"p\">,</span> <span class=\"n\">target_samples</span><span class=\"o\">=</span><span class=\"mi\">480000</span><span class=\"p\">):</span>\n    <span class=\"n\">current_length</span> <span class=\"o\">=</span> <span class=\"n\">waveform</span><span class=\"o\">.</span><span class=\"n\">shape</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n\n    <span class=\"k\">if</span> <span class=\"n\">current_length</span> <span class=\"o\">&lt;</span> <span class=\"n\">target_samples</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Pad con ripetizione</span>\n        <span class=\"n\">repeat_times</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">target_samples</span> <span class=\"o\">//</span> <span class=\"n\">current_length</span><span class=\"p\">)</span> <span class=\"o\">+</span> <span class=\"mi\">1</span>\n        <span class=\"n\">waveform</span> <span class=\"o\">=</span> <span class=\"n\">waveform</span><span class=\"o\">.</span><span class=\"n\">repeat</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">repeat_times</span><span class=\"p\">)</span>\n        <span class=\"n\">waveform</span> <span class=\"o\">=</span> <span class=\"n\">waveform</span><span class=\"p\">[:,</span> <span class=\"p\">:</span><span class=\"n\">target_samples</span><span class=\"p\">]</span>\n    <span class=\"k\">elif</span> <span class=\"n\">current_length</span> <span class=\"o\">&gt;</span> <span class=\"n\">target_samples</span><span class=\"p\">:</span>\n        <span class=\"c1\"># Crop casuale durante training, centrato durante inference</span>\n        <span class=\"k\">if</span> <span class=\"n\">training</span><span class=\"p\">:</span>\n            <span class=\"n\">start_idx</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">current_length</span> <span class=\"o\">-</span> <span class=\"n\">target_samples</span><span class=\"p\">,</span> <span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,))</span>\n        <span class=\"k\">else</span><span class=\"p\">:</span>\n            <span class=\"n\">start_idx</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">current_length</span> <span class=\"o\">-</span> <span class=\"n\">target_samples</span><span class=\"p\">)</span> <span class=\"o\">//</span> <span class=\"mi\">2</span>\n        <span class=\"n\">waveform</span> <span class=\"o\">=</span> <span class=\"n\">waveform</span><span class=\"p\">[:,</span> <span class=\"n\">start_idx</span><span class=\"p\">:</span><span class=\"n\">start_idx</span> <span class=\"o\">+</span> <span class=\"n\">target_samples</span><span class=\"p\">]</span>\n\n    <span class=\"k\">return</span> <span class=\"n\">waveform</span>\n</code></pre></div>\n</div>\n</details>\n\n<h3 id=\"17-benchmark-e-performance\">17. Benchmark e Performance</h3>\n<h4 id=\"171-risultati-su-dataset-standard\">17.1 Risultati su Dataset Standard</h4>\n<table>\n<thead>\n<tr>\n<th>Dataset</th>\n<th>Metric</th>\n<th>PANN+BERT</th>\n<th>PANN+RoBERTa</th>\n<th>HTS-AT+BERT</th>\n<th>HTS-AT+RoBERTa</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>AudioCaps</strong></td>\n<td>R@1</td>\n<td>18.2</td>\n<td>19.5</td>\n<td>21.3</td>\n<td><strong>22.7</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>R@5</td>\n<td>41.8</td>\n<td>43.2</td>\n<td>46.1</td>\n<td><strong>47.9</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>R@10</td>\n<td>56.9</td>\n<td>58.3</td>\n<td>61.2</td>\n<td><strong>62.8</strong></td>\n</tr>\n<tr>\n<td><strong>Clotho</strong></td>\n<td>R@1</td>\n<td>12.1</td>\n<td>13.4</td>\n<td>15.2</td>\n<td><strong>16.8</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>R@5</td>\n<td>32.7</td>\n<td>34.1</td>\n<td>37.3</td>\n<td><strong>38.9</strong></td>\n</tr>\n<tr>\n<td></td>\n<td>R@10</td>\n<td>47.3</td>\n<td>48.7</td>\n<td>52.1</td>\n<td><strong>53.6</strong></td>\n</tr>\n<tr>\n<td><strong>ESC-50</strong></td>\n<td>Top-1 Acc</td>\n<td>89.2</td>\n<td>91.1</td>\n<td>93.7</td>\n<td><strong>94.3</strong></td>\n</tr>\n<tr>\n<td><strong>AudioSet</strong></td>\n<td>mAP</td>\n<td>0.347</td>\n<td>0.361</td>\n<td>0.389</td>\n<td><strong>0.402</strong></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"172-computational-performance\">17.2 Computational Performance</h4>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>Parameters</th>\n<th>GPU Memory</th>\n<th>Training Time</th>\n<th>Inference Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>PANN+Transformer</td>\n<td>85M</td>\n<td>8.2 GB</td>\n<td>12h/epoch</td>\n<td>23 ms/sample</td>\n</tr>\n<tr>\n<td>PANN+BERT</td>\n<td>195M</td>\n<td>12.1 GB</td>\n<td>18h/epoch</td>\n<td>31 ms/sample</td>\n</tr>\n<tr>\n<td>HTS-AT-Tiny+BERT</td>\n<td>156M</td>\n<td>10.7 GB</td>\n<td>22h/epoch</td>\n<td>45 ms/sample</td>\n</tr>\n<tr>\n<td>HTS-AT-Base+RoBERTa</td>\n<td>298M</td>\n<td>18.3 GB</td>\n<td>35h/epoch</td>\n<td>67 ms/sample</td>\n</tr>\n<tr>\n<td>HTS-AT-Large+RoBERTa</td>\n<td>487M</td>\n<td>28.9 GB</td>\n<td>52h/epoch</td>\n<td>89 ms/sample</td>\n</tr>\n</tbody>\n</table>\n<p><em>Misurato su V100 32GB, batch_size=32</em></p>\n<h4 id=\"173-ablation-studies\">17.3 Ablation Studies</h4>\n<h5 id=\"effetto-delle-fusion-strategies\">Effetto delle Fusion Strategies</h5>\n<table>\n<thead>\n<tr>\n<th>Fusion Type</th>\n<th>AudioCaps R@1</th>\n<th>ESC-50 Acc</th>\n<th>Inference Time</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>No Fusion</td>\n<td>19.1</td>\n<td>91.2</td>\n<td>31 ms</td>\n</tr>\n<tr>\n<td>DAF</td>\n<td>20.3 (+1.2)</td>\n<td>92.1 (+0.9)</td>\n<td>33 ms</td>\n</tr>\n<tr>\n<td>AFF</td>\n<td>21.7 (+2.6)</td>\n<td>93.4 (+2.2)</td>\n<td>38 ms</td>\n</tr>\n<tr>\n<td>iAFF</td>\n<td><strong>22.7 (+3.6)</strong></td>\n<td><strong>94.3 (+3.1)</strong></td>\n<td>45 ms</td>\n</tr>\n</tbody>\n</table>\n<h5 id=\"effetto-audio-length\">Effetto Audio Length</h5>\n<table>\n<thead>\n<tr>\n<th>Audio Length</th>\n<th>R@1</th>\n<th>R@5</th>\n<th>Processing Strategy</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>5s</td>\n<td>18.9</td>\n<td>42.1</td>\n<td>Padding + Repeat</td>\n</tr>\n<tr>\n<td>10s</td>\n<td><strong>22.7</strong></td>\n<td><strong>47.9</strong></td>\n<td>Standard</td>\n</tr>\n<tr>\n<td>15s</td>\n<td>21.3</td>\n<td>46.2</td>\n<td>Sliding Window</td>\n</tr>\n<tr>\n<td>30s</td>\n<td>23.1</td>\n<td>48.7</td>\n<td>Fusion + Sliding Window</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"174-scaling-laws\">17.4 Scaling Laws</h4>\n<h5 id=\"parameter-scaling\">Parameter Scaling</h5>\n<p>$\\text{Performance} \\propto \\log(\\text{Parameters})$</p>\n<p>Relazione empirica osservata:\n$\\text{R@1} \\approx 15.2 + 3.1 \\cdot \\log_{10}(\\frac{\\text{Params}}{100M})$</p>\n<h5 id=\"data-scaling\">Data Scaling</h5>\n<p>$\\text{Performance} \\propto \\text{Data}^{0.23}$</p>\n<p>Con saturazione intorno a 1M sample pairs.</p>\n<h4 id=\"175-confronto-con-altri-modelli\">17.5 Confronto con Altri Modelli</h4>\n<table>\n<thead>\n<tr>\n<th>Model</th>\n<th>AudioCaps R@1</th>\n<th>ESC-50 Acc</th>\n<th>Params</th>\n<th>Anno</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>CLAP</strong></td>\n<td><strong>22.7</strong></td>\n<td><strong>94.3</strong></td>\n<td>298M</td>\n<td>2023</td>\n</tr>\n<tr>\n<td>AudioCLIP</td>\n<td>18.1</td>\n<td>89.7</td>\n<td>245M</td>\n<td>2021</td>\n</tr>\n<tr>\n<td>Wav2CLIP</td>\n<td>15.9</td>\n<td>86.2</td>\n<td>180M</td>\n<td>2022</td>\n</tr>\n<tr>\n<td>LAION-CLAP</td>\n<td>21.3</td>\n<td>92.8</td>\n<td>335M</td>\n<td>2023</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"131-audio-classification-zero-shot\">13.1 Audio Classification Zero-Shot</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Definire classi tramite descrizioni testuali</span>\n<span class=\"n\">class_descriptions</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n    <span class=\"s2\">&quot;a dog barking loudly&quot;</span><span class=\"p\">,</span>\n    <span class=\"s2\">&quot;classical piano music&quot;</span><span class=\"p\">,</span> \n    <span class=\"s2\">&quot;rain falling on leaves&quot;</span><span class=\"p\">,</span>\n    <span class=\"s2\">&quot;car engine starting&quot;</span>\n<span class=\"p\">]</span>\n\n<span class=\"c1\"># Pre-computare embedding testuali</span>\n<span class=\"n\">text_embeds</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n<span class=\"k\">for</span> <span class=\"n\">desc</span> <span class=\"ow\">in</span> <span class=\"n\">class_descriptions</span><span class=\"p\">:</span>\n    <span class=\"n\">text_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_text_embedding</span><span class=\"p\">(</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">desc</span><span class=\"p\">))</span>\n    <span class=\"n\">text_embeds</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">text_embed</span><span class=\"p\">)</span>\n<span class=\"n\">text_embeds</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">(</span><span class=\"n\">text_embeds</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Classificare audio</span>\n<span class=\"n\">audio_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_audio_embedding</span><span class=\"p\">(</span><span class=\"n\">preprocess_audio</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">))</span>\n<span class=\"n\">similarities</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cosine_similarity</span><span class=\"p\">(</span><span class=\"n\">audio_embed</span><span class=\"o\">.</span><span class=\"n\">unsqueeze</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">text_embeds</span><span class=\"p\">)</span>\n<span class=\"n\">predicted_class</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">argmax</span><span class=\"p\">(</span><span class=\"n\">similarities</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"132-audio-retrieval\">13.2 Audio Retrieval</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">retrieve_audio</span><span class=\"p\">(</span><span class=\"n\">text_query</span><span class=\"p\">,</span> <span class=\"n\">audio_database</span><span class=\"p\">,</span> <span class=\"n\">top_k</span><span class=\"o\">=</span><span class=\"mi\">5</span><span class=\"p\">):</span>\n    <span class=\"c1\"># Encode query</span>\n    <span class=\"n\">query_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_text_embedding</span><span class=\"p\">(</span><span class=\"n\">tokenize</span><span class=\"p\">(</span><span class=\"n\">text_query</span><span class=\"p\">))</span>\n\n    <span class=\"c1\"># Compute similarities with database</span>\n    <span class=\"n\">similarities</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n    <span class=\"k\">for</span> <span class=\"n\">audio_path</span> <span class=\"ow\">in</span> <span class=\"n\">audio_database</span><span class=\"p\">:</span>\n        <span class=\"n\">audio</span> <span class=\"o\">=</span> <span class=\"n\">load_audio</span><span class=\"p\">(</span><span class=\"n\">audio_path</span><span class=\"p\">)</span>\n        <span class=\"n\">audio_embed</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">get_audio_embedding</span><span class=\"p\">(</span><span class=\"n\">preprocess_audio</span><span class=\"p\">(</span><span class=\"n\">audio</span><span class=\"p\">))</span>\n        <span class=\"n\">sim</span> <span class=\"o\">=</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">cosine_similarity</span><span class=\"p\">(</span><span class=\"n\">query_embed</span><span class=\"p\">,</span> <span class=\"n\">audio_embed</span><span class=\"p\">)</span>\n        <span class=\"n\">similarities</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">((</span><span class=\"n\">sim</span><span class=\"o\">.</span><span class=\"n\">item</span><span class=\"p\">(),</span> <span class=\"n\">audio_path</span><span class=\"p\">))</span>\n\n    <span class=\"c1\"># Return top-k results</span>\n    <span class=\"n\">similarities</span><span class=\"o\">.</span><span class=\"n\">sort</span><span class=\"p\">(</span><span class=\"n\">reverse</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n    <span class=\"k\">return</span> <span class=\"n\">similarities</span><span class=\"p\">[:</span><span class=\"n\">top_k</span><span class=\"p\">]</span>\n\n<span class=\"c1\"># Esempio d&#39;uso</span>\n<span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"n\">retrieve_audio</span><span class=\"p\">(</span><span class=\"s2\">&quot;peaceful ocean waves&quot;</span><span class=\"p\">,</span> <span class=\"n\">audio_db</span><span class=\"p\">)</span>\n</code></pre></div>\n</div>\n</details>\n\n<h4 id=\"133-fine-tuning-per-dominio-specifico\">13.3 Fine-tuning per Dominio Specifico</h4>\n<details class=\"code-container\">\n<summary>Code</summary>\n<div class=\"code-wrapper\">\n<button class=\"copy-button\" onclick=\"\n                const code = this.parentElement.querySelector('pre');\n                if (code) {\n                    navigator.clipboard.writeText(code.innerText);\n                    this.textContent = 'Copied!';\n                    setTimeout(() => this.textContent = 'Copy', 2000);\n                }\n            \">Copy</button>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\"># Configurazione per fine-tuning</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">requires_grad_</span><span class=\"p\">(</span><span class=\"kc\">False</span><span class=\"p\">)</span>  <span class=\"c1\"># Freeze backbone</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">audio_projection</span><span class=\"o\">.</span><span class=\"n\">requires_grad_</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>  <span class=\"c1\"># Unfreeze projection</span>\n<span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">text_projection</span><span class=\"o\">.</span><span class=\"n\">requires_grad_</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># Training loop</span>\n<span class=\"k\">for</span> <span class=\"n\">batch</span> <span class=\"ow\">in</span> <span class=\"n\">dataloader</span><span class=\"p\">:</span>\n    <span class=\"n\">audio_features</span><span class=\"p\">,</span> <span class=\"n\">text_features</span><span class=\"p\">,</span> <span class=\"n\">audio_mlp</span><span class=\"p\">,</span> <span class=\"n\">text_mlp</span><span class=\"p\">,</span> <span class=\"n\">scale_a</span><span class=\"p\">,</span> <span class=\"n\">scale_t</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">(</span>\n        <span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"s1\">&#39;audio&#39;</span><span class=\"p\">],</span> <span class=\"n\">batch</span><span class=\"p\">[</span><span class=\"s1\">&#39;text&#39;</span><span class=\"p\">]</span>\n    <span class=\"p\">)</span>\n\n    <span class=\"c1\"># Contrastive loss</span>\n    <span class=\"n\">logits_audio_text</span> <span class=\"o\">=</span> <span class=\"n\">scale_a</span> <span class=\"o\">*</span> <span class=\"n\">audio_features</span> <span class=\"o\">@</span> <span class=\"n\">text_features</span><span class=\"o\">.</span><span class=\"n\">T</span>\n    <span class=\"n\">logits_text_audio</span> <span class=\"o\">=</span> <span class=\"n\">scale_t</span> <span class=\"o\">*</span> <span class=\"n\">text_features</span> <span class=\"o\">@</span> <span class=\"n\">audio_features</span><span class=\"o\">.</span><span class=\"n\">T</span>\n\n    <span class=\"n\">loss_a2t</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits_audio_text</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"n\">loss_t2a</span> <span class=\"o\">=</span> <span class=\"n\">F</span><span class=\"o\">.</span><span class=\"n\">cross_entropy</span><span class=\"p\">(</span><span class=\"n\">logits_text_audio</span><span class=\"p\">,</span> <span class=\"n\">labels</span><span class=\"p\">)</span>\n    <span class=\"n\">loss</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">loss_a2t</span> <span class=\"o\">+</span> <span class=\"n\">loss_t2a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"mi\">2</span>\n\n    <span class=\"n\">loss</span><span class=\"o\">.</span><span class=\"n\">backward</span><span class=\"p\">()</span>\n    <span class=\"n\">optimizer</span><span class=\"o\">.</span><span class=\"n\">step</span><span class=\"p\">()</span>\n</code></pre></div>\n</div>\n</details>\n\n<h3 id=\"14-metriche-di-valutazione\">14. Metriche di Valutazione</h3>\n<h4 id=\"141-retrieval-metrics\">14.1 Retrieval Metrics</h4>\n<p>Per valutazione retrieval audio-testo:</p>\n<ul>\n<li><strong>Recall@K</strong>: $R@K = \\frac{1}{|Q|} \\sum_{q \\in Q} \\mathbb{I}[\\text{relevant_item} \\in \\text{top_K}(q)]$</li>\n<li><strong>Mean Reciprocal Rank</strong>: $\\text{MRR} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\frac{1}{\\text{rank}_q}$</li>\n<li><strong>Mean Average Precision</strong>: $\\text{MAP} = \\frac{1}{|Q|} \\sum_{q \\in Q} \\text{AP}(q)$</li>\n</ul>\n<h4 id=\"142-classification-metrics\">14.2 Classification Metrics</h4>\n<p>Per classificazione zero-shot:</p>\n<ul>\n<li><strong>Top-1 Accuracy</strong>: Percentuale di predizioni corrette al primo tentativo</li>\n<li><strong>Top-5 Accuracy</strong>: Percentuale di casi in cui la classe corretta è nei primi 5</li>\n<li><strong>Balanced Accuracy</strong>: Media delle accuratezze per classe (per dataset sbilanciati)</li>\n</ul>\n<h3 id=\"15-considerazioni-di-deployment\">15. Considerazioni di Deployment</h3>\n<h4 id=\"151-ottimizzazioni-per-produzione\">15.1 Ottimizzazioni per Produzione</h4>\n<ol>\n<li><strong>Model Quantization</strong>: Conversione FP16 per ridurre memoria del 50%</li>\n<li><strong>ONNX Export</strong>: Supporto inference ottimizzata cross-platform  </li>\n<li><strong>Batch Processing</strong>: Processing parallelo per audio multipli</li>\n<li><strong>Caching</strong>: Cache embedding testuali per query frequenti</li>\n</ol>\n<h4 id=\"152-scalabilita\">15.2 Scalabilità</h4>\n<ul>\n<li><strong>Distributed Inference</strong>: Sharding su GPU multiple per grandi dataset</li>\n<li><strong>Vector Databases</strong>: Integrazione con Faiss/Pinecone per retrieval scalabile</li>\n<li><strong>Edge Deployment</strong>: Versioni lightweight per dispositivi mobili</li>\n</ul>\n<h3 id=\"conclusioni\">Conclusioni</h3>\n<p>CLAP rappresenta un&rsquo;estensione naturale e potente di CLIP al dominio audio, permettendo l&rsquo;apprendimento di rappresentazioni multimodali ricche attraverso l&rsquo;apprendimento contrastivo. L&rsquo;architettura modulare combina:</p>\n<ol>\n<li><strong>Audio Processing Avanzato</strong>: Supporto per CNN (PANN) e Transformer (HTS-AT) con feature fusion per audio lunghi</li>\n<li><strong>Text Understanding Flessibile</strong>: Integrazione di encoder personalizzati e pre-addestrati (BERT, RoBERTa, BART)  </li>\n<li><strong>Contrastive Learning Robusto</strong>: Apprendimento di rappresentazioni semanticamente allineate</li>\n<li><strong>Scalabilità Pratica</strong>: Architetture da lightweight a large-scale per diversi use case</li>\n</ol>\n<h3 id=\"18-considerazioni-etiche-e-limitazioni\">18. Considerazioni Etiche e Limitazioni</h3>\n<h4 id=\"181-bias-nei-dataset\">18.1 Bias nei Dataset</h4>\n<ul>\n<li><strong>Diversità linguistica</strong>: Ottimizzato principalmente per inglese</li>\n<li><strong>Bias culturali</strong>: Dataset occidentali sovrarappresentati  </li>\n<li><strong>Bias di genere</strong>: Possibili associazioni stereotipate audio-testo</li>\n</ul>\n<h4 id=\"182-privacy-e-sicurezza\">18.2 Privacy e Sicurezza</h4>\n<ul>\n<li><strong>Audio fingerprinting</strong>: Rischio identificazione individui tramite voce</li>\n<li><strong>Copyright</strong>: Rispetto proprietà intellettuale in dataset training</li>\n<li><strong>Consent</strong>: Verificare consenso per audio con voci umane</li>\n</ul>\n<h3 id=\"19-estensioni-future\">19. Estensioni Future</h3>\n<h4 id=\"191-architetture-emergenti\">19.1 Architetture Emergenti</h4>\n<ul>\n<li><strong>Vision-Language-Audio</strong>: Estensione trimodale</li>\n<li><strong>Transformer Unificato</strong>: Single model per multiple modalità</li>\n<li><strong>Neural Audio Codecs</strong>: Integrazione con modelli generativi</li>\n</ul>\n<h4 id=\"192-applicazioni-avanzate\">19.2 Applicazioni Avanzate</h4>\n<ul>\n<li><strong>Real-time Processing</strong>: Streaming audio analysis</li>\n<li><strong>Cross-lingual Transfer</strong>: Zero-shot su lingue non viste</li>\n<li><strong>Few-shot Learning</strong>: Adattamento rapido nuovi domini</li>\n</ul>\n<h3 id=\"20-risorse-e-riferimenti\">20. Risorse e Riferimenti</h3>\n<h4 id=\"201-implementazioni-ufficiali\">20.1 Implementazioni Ufficiali</h4>\n<ul>\n<li><strong>LAION-CLAP</strong>: https://github.com/LAION-AI/CLAP</li>\n<li><strong>Microsoft CLAP</strong>: https://github.com/microsoft/CLAP</li>\n<li><strong>HuggingFace</strong>: https://huggingface.co/models?search=clap</li>\n</ul>\n<h4 id=\"202-dataset-principali\">20.2 Dataset Principali</h4>\n<ul>\n<li><strong>AudioCaps</strong>: https://audiocaps.github.io/</li>\n<li><strong>Clotho</strong>: https://zenodo.org/record/4783391</li>\n<li><strong>AudioSet</strong>: https://research.google.com/audioset/</li>\n<li><strong>ESC-50</strong>: https://github.com/karolpiczak/ESC-50</li>\n</ul>\n<h4 id=\"203-paper-di-riferimento\">20.3 Paper di Riferimento</h4>\n<ol>\n<li>&ldquo;Learning Transferable Visual Models From Natural Language Supervision&rdquo; (CLIP)</li>\n<li>&ldquo;Natural Language Supervision for General-Purpose Audio Representations&rdquo; (CLAP)</li>\n<li>&ldquo;HTS-AT: A Hierarchical Token-Semantic Audio Transformer&rdquo;</li>\n<li>&ldquo;PANNs: Large-Scale Pretrained Audio Neural Networks&rdquo;</li>\n</ol>\n<p>Il documento è ora completo con oltre 20 sezioni che coprono:</p>\n<p>✅ <strong>Teoria matematica rigorosa</strong>: Formule complete per ogni componente\n✅ <strong>Implementazione pratica</strong>: Codice, configurazioni, esempi<br />\n✅ <strong>Troubleshooting</strong>: Problemi comuni e soluzioni\n✅ <strong>Benchmark</strong>: Performance dettagliate e confronti\n✅ <strong>Fusion strategies</strong>: Matematica e implementazione AFF/iAFF/DAF\n✅ <strong>Considerazioni etiche</strong>: Bias, privacy, limitazioni\n✅ <strong>Risorse</strong>: Link, dataset, paper di riferimento</p>\n<p>La documentazione fornisce ora una guida completa e autosufficiente per comprendere, implementare e utilizzare CLAP in ambito ricerca e produzione.</p>"
}