{
  "title": "Misure di Similarità Vettoriale",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n/* Blocchi di codice sempre visibili */\n.code-visible {\n    border: 1px solid #e5e7eb;\n    border-radius: 12px;\n    background: #f9fafb;\n    margin: 16px 0;\n}\n.code-visible .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<p>Quando rappresentiamo dati testuali o numerici come vettori, possiamo confrontarli tramite <strong>misure di distanza</strong> o <strong>similarità</strong>.<br />\nQueste misure sono fondamentali in molte aree: NLP, clustering, classificazione, retrieval.</p>\n<p>La scelta della misura di distanza influenza in modo decisivo le performance degli algoritmi.</p>\n<h2 id=\"1-definizioni-formali\">1. Definizioni Formali</h2>\n<p>Per procedere in modo rigoroso, definiamo il concetto matematico di <strong>distanza</strong>.</p>\n<h3 id=\"11-distanza\">1.1 Distanza</h3>\n<p>Una <strong>distanza</strong> su uno spazio $X$ è una funzione:</p>\n$$\nd: X \\times X \\to \\mathbb{R}\n$$\n<p>che associa a ogni coppia di punti $(x, y)$ un numero reale $d(x, y)$, interpretato intuitivamente come la &ldquo;lontananza&rdquo; tra $x$ e $y$.</p>\n<p>Affinché $d$ sia effettivamente considerata una distanza, deve soddisfare quattro proprietà fondamentali:</p>\n<ol>\n<li><strong>Non negatività</strong>:</li>\n</ol>\n<p>La distanza tra due punti è sempre un numero positivo o nullo:</p>\n$$\n   d(\\mathbf{x}, \\mathbf{y}) \\geq 0 \\quad \\forall \\, \\mathbf{x}, \\mathbf{y} \\in X\n   $$\n<p>(<em>Non esistono distanze negative.</em>)</p>\n<ol>\n<li><strong>Identità degli indiscernibili</strong>:</li>\n</ol>\n<p>Due punti sono a distanza zero <strong>se e solo se</strong> coincidono:</p>\n$$\n   d(\\mathbf{x}, \\mathbf{y}) = 0 \\quad \\iff \\quad \\mathbf{x} = \\mathbf{y}\n   $$\n<p>(<em>Se due oggetti sono distinti, devono avere distanza positiva.</em>)</p>\n<ol>\n<li><strong>Simmetria</strong>:</li>\n</ol>\n<p>L&rsquo;ordine dei punti non conta: la distanza da $x$ a $y$ è uguale a quella da $y$ a $x$:</p>\n$$\n   d(\\mathbf{x}, \\mathbf{y}) = d(\\mathbf{y}, \\mathbf{x})\n   $$\n<p>(<em>La distanza è &ldquo;senza direzione&rdquo;, a differenza, ad esempio, di uno spostamento vettoriale.</em>)</p>\n<ol>\n<li><strong>Disuguaglianza triangolare</strong>:</li>\n</ol>\n<p>Il percorso diretto tra due punti è sempre il più breve, o almeno non più lungo, rispetto a passare per un terzo punto:</p>\n$$\n   d(\\mathbf{x}, \\mathbf{z}) \\leq d(\\mathbf{x}, \\mathbf{y}) + d(\\mathbf{y}, \\mathbf{z})\n   $$\n<p>(<em>È la formalizzazione del concetto che &ldquo;la scorciatoia è sempre più breve&rdquo; nella geometria.</em>)</p>\n<h3 id=\"12-spazio-metrico\">1.2 Spazio Metrico</h3>\n<p>Uno <strong>spazio metrico</strong> è una coppia $(X, d)$, dove:</p>\n<ul>\n<li>$X$ è un insieme di punti (o vettori),</li>\n<li>$d$ è una funzione di distanza che soddisfa le quattro proprietà sopra.</li>\n</ul>\n<p><strong>In sintesi</strong>:</p>\n<blockquote>\n<p>Uno spazio metrico fornisce un modo formale per misurare &ldquo;quanto sono vicini&rdquo; o &ldquo;quanto sono lontani&rdquo; due elementi di un insieme.</p>\n</blockquote>\n<p>Gli spazi metrici sono la base concettuale per la geometria, l&rsquo;analisi matematica, e molte tecniche di machine learning.</p>\n<h2 id=\"2-distanze-di-minkowski\">2. Distanze di Minkowski</h2>\n<p>La <strong>famiglia di Minkowski</strong> definisce una classe di distanze parametrizzate da $p \\geq 1$:</p>\n$$\nd_p(x, y) = \\left( \\sum_{i=1}^{n} |x_i - y_i|^p \\right)^{\\frac{1}{p}}\n$$\n<h3 id=\"casi-speciali\">Casi speciali:</h3>\n<ul>\n<li><strong>Distanza Manhattan</strong> $p=1$:</li>\n</ul>\n$$\n  d_1(x, y) = \\sum_{i=1}^{n} |x_i - y_i|\n  $$\n<ul>\n<li><strong>Distanza Euclidea</strong> $p=2$:</li>\n</ul>\n$$\n  d_2(x, y) = \\sqrt{ \\sum_{i=1}^{n} (x_i - y_i)^2 }\n  $$\n<ul>\n<li><strong>Distanza di Chebyshev</strong> $p→∞$:</li>\n</ul>\n$$\n  d_\\infty(x, y) = \\max_{i} |x_i - y_i|\n  $$\n<h3 id=\"21-dimostrazione-distanza-di-chebyshev-come-limite-di-minkowski\">2.1 Dimostrazione: Distanza di Chebyshev come limite di Minkowski</h3>\n<p><strong>Teorema</strong>:<br />\n$$\nd_\\infty(x, y) = \\lim_{p \\to \\infty} d_p(x, y) = \\max_i |x_i - y_i|\n$$</p>\n<p><strong>Dimostrazione</strong>:</p>\n<p>Siano $a = |x_1 - y_1|$ e $b = |x_2 - y_2|$.<br />\nSenza perdita di generalità, supponiamo:</p>\n$$\n\\max(a, b) = a\n$$\n<p>Allora:</p>\n<ol>\n<li>Stima dal basso:</li>\n</ol>\n$$\n\\lim_{p \\to \\infty} (a^p + b^p)^{1/p}\n\\geq\n\\lim_{p \\to \\infty} (a^p)^{1/p}\n=\na\n$$\n<ol>\n<li>Stima dall&rsquo;alto:</li>\n</ol>\n$$\n\\lim_{p \\to \\infty} (a^p + b^p)^{1/p}\n\\leq\n\\lim_{p \\to \\infty} (a^p + a^p)^{1/p}\n=\n\\lim_{p \\to \\infty} (2a^p)^{1/p}\n=\na \\lim_{p \\to \\infty} 2^{1/p}\n=\na\n$$\n<p>perché $\\lim_{p\\to\\infty} 2^{1/p} = 1$.</p>\n<p><strong>Conclusione</strong>:<br />\n$$\n\\lim_{p\\to\\infty} d_p(x,y) = a = \\max(a,b)\n\\quad \\Box\n$$</p>\n<h2 id=\"3-similarita-coseno\">3. Similarità Coseno</h2>\n<p>La <strong>similarità coseno</strong> è una misura della <strong>direzione</strong> relativa tra due vettori in uno spazio vettoriale.<br />\nIn particolare, essa <strong>non</strong> considera la lunghezza dei vettori, ma solamente <strong>l&rsquo;angolo</strong> che essi formano tra loro.</p>\n<h3 id=\"formula\">Formula</h3>\n<p>La formula della similarità coseno tra due vettori $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$ è:</p>\n$$\n\\text{sim}_{\\cos}(\\mathbf{x}, \\mathbf{y}) = \\frac{ \\mathbf{x} \\cdot \\mathbf{y} }{ \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| }\n$$\n<p>dove:</p>\n<ul>\n<li>$\\mathbf{x} \\cdot \\mathbf{y} = \\sum_{i=1}^{n} x_i y_i$ è il <strong>prodotto scalare</strong>,</li>\n<li>$\\|\\mathbf{x}\\| = \\sqrt{ \\sum_{i=1}^{n} x_i^2 }$ è la <strong>norma Euclidea</strong> di $\\mathbf{x}$,</li>\n<li>$\\|\\mathbf{y}\\| = \\sqrt{ \\sum_{i=1}^{n} y_i^2 }$ è la <strong>norma Euclidea</strong> di $\\mathbf{y}$.</li>\n</ul>\n<h3 id=\"dimostrazione-della-formula-tramite-angoli\">Dimostrazione della Formula tramite Angoli</h3>\n<p>Partiamo da due vettori nel piano:</p>\n$$\n\\mathbf{x} = (x_1, x_2), \\quad \\mathbf{y} = (y_1, y_2)\n$$\n<p>Supponiamo che $\\mathbf{x}$ e $\\mathbf{y}$ abbiano rispettivamente:</p>\n<ul>\n<li>Lunghezza $\\|\\mathbf{x}\\|$ e $\\|\\mathbf{y}\\|$,</li>\n<li>Formino angoli $\\alpha$ e $\\beta$ rispetto all&rsquo;asse $x$.</li>\n</ul>\n<p>Allora, per la definizione di coseno di un angolo, possiamo scrivere le loro componenti:</p>\n$$\nx_1 = \\|\\mathbf{x}\\| \\cos(\\alpha), \\quad x_2 = \\|\\mathbf{x}\\| \\sin(\\alpha)\n$$\n$$\ny_1 = \\|\\mathbf{y}\\| \\cos(\\beta), \\quad y_2 = \\|\\mathbf{y}\\| \\sin(\\beta)\n$$\n<p>Ora il prodotto scalare è:</p>\n$$\n\\mathbf{x} \\cdot \\mathbf{y} = x_1 y_1 + x_2 y_2\n$$\n<p>Sostituendo:</p>\n$$\n= \\|\\mathbf{x}\\| \\cos(\\alpha) \\|\\mathbf{y}\\| \\cos(\\beta) + \\|\\mathbf{x}\\| \\sin(\\alpha) \\|\\mathbf{y}\\| \\sin(\\beta)\n$$\n$$\n= \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| \\left( \\cos(\\alpha) \\cos(\\beta) + \\sin(\\alpha) \\sin(\\beta) \\right)\n$$\n<p>Ora, usando l&rsquo;identità trigonometrica:</p>\n$$\n\\cos(\\alpha - \\beta) = \\cos(\\alpha) \\cos(\\beta) + \\sin(\\alpha) \\sin(\\beta)\n$$\n<p>otteniamo:</p>\n$$\n\\mathbf{x} \\cdot \\mathbf{y} = \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| \\cos(\\alpha - \\beta)\n$$\n<p>Dove:</p>\n<ul>\n<li>$\\alpha - \\beta = \\theta$ è l&rsquo;<strong>angolo</strong> tra i due vettori.</li>\n</ul>\n<p>Quindi:</p>\n$$\n\\cos(\\theta) = \\frac{ \\mathbf{x} \\cdot \\mathbf{y} }{ \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| }\n$$\n<p>che è esattamente la definizione della <strong>similarità coseno</strong>. $\\square$</p>\n<h3 id=\"interpretazione-geometrica\">Interpretazione Geometrica</h3>\n<ul>\n<li>Se $\\cos(\\theta) = 1$, allora $\\theta = 0^\\circ$, i vettori puntano nella <strong>stessa direzione</strong> → <strong>massima similarità</strong>.</li>\n<li>Se $\\cos(\\theta) = 0$, allora $\\theta = 90^\\circ$, i vettori sono <strong>ortogonali</strong> → <strong>nessuna similarità</strong>.</li>\n<li>Se $\\cos(\\theta) = -1$, allora $\\theta = 180^\\circ$, i vettori puntano in <strong>direzioni opposte</strong>.</li>\n</ul>\n<h3 id=\"riassunto-tabellare\">Riassunto Tabellare</h3>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\">$\\theta$</th>\n<th style=\"text-align: left;\">Interpretazione</th>\n<th style=\"text-align: center;\">$\\text{sim}_{\\cos}$</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">$0^\\circ$</td>\n<td style=\"text-align: left;\">Vettori paralleli, stesso verso</td>\n<td style=\"text-align: center;\">$1$</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">$90^\\circ$</td>\n<td style=\"text-align: left;\">Vettori ortogonali</td>\n<td style=\"text-align: center;\">$0$</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">$180^\\circ$</td>\n<td style=\"text-align: left;\">Vettori paralleli, verso opposto</td>\n<td style=\"text-align: center;\">$-1$</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"/images/tikz/bf74f0743b6e427e2214b06c887d9e3f.svg\" style=\"display: block; width: 100%; height: auto; max-height: 600px;\" class=\"tikz-svg\" /></p>\n<ul>\n<li><strong>L&rsquo;angolo tra $\\mathbf{x}$ e $\\mathbf{y}$</strong> determina il valore della similarità coseno.</li>\n<li><strong>Non conta quanto sono lunghi</strong> $\\mathbf{x}$ e $\\mathbf{y}$: solo <strong>l&rsquo;orientamento</strong>.</li>\n</ul>\n<h3 id=\"nota-pratica\">Nota pratica</h3>\n<p>La similarità coseno è <strong>molto usata</strong> quando:</p>\n<ul>\n<li>I dati sono rappresentati come vettori <strong>sparsi</strong> (es: bag-of-words, TF-IDF).</li>\n<li>L&rsquo;interesse è confrontare la <strong>direzione</strong> (cioè la proporzione tra componenti) piuttosto che la magnitudine assoluta.</li>\n</ul>\n<p>Esempi applicativi:</p>\n<ul>\n<li><strong>Document Retrieval</strong>: trovare documenti simili a una query.</li>\n<li><strong>Sistemi di Raccomandazione</strong>: trovare utenti o prodotti simili.</li>\n<li><strong>Clustering Testuale</strong>.</li>\n</ul>\n<h3 id=\"esempio\">Esempio</h3>\n<p>Consideriamo il seguente esempio pratico di calcolo della <strong>similarità coseno</strong> tra vettori associati a parole.</p>\n<p>Supponiamo di avere una matrice di co-occorrenza delle parole rispetto a tre contesti: <code>pie</code>, <code>data</code> e <code>computer</code>:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: center;\"></th>\n<th style=\"text-align: center;\">pie</th>\n<th style=\"text-align: center;\">data</th>\n<th style=\"text-align: center;\">computer</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: center;\">cherry</td>\n<td style=\"text-align: center;\">442</td>\n<td style=\"text-align: center;\">8</td>\n<td style=\"text-align: center;\">2</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">digital</td>\n<td style=\"text-align: center;\">5</td>\n<td style=\"text-align: center;\">1683</td>\n<td style=\"text-align: center;\">1670</td>\n</tr>\n<tr>\n<td style=\"text-align: center;\">information</td>\n<td style=\"text-align: center;\">5</td>\n<td style=\"text-align: center;\">3982</td>\n<td style=\"text-align: center;\">3325</td>\n</tr>\n</tbody>\n</table>\n<p>L&rsquo;obiettivo è confrontare la similarità tra:</p>\n<ul>\n<li><strong>cherry</strong> e <strong>information</strong></li>\n<li><strong>digital</strong> e <strong>information</strong></li>\n</ul>\n<h4 id=\"calcolo\">Calcolo</h4>\n<p>La similarità coseno si calcola come:</p>\n$$\n\\cos(\\mathbf{x}, \\mathbf{y}) = \\frac{ \\sum_{i=1}^n x_i y_i }{ \\sqrt{ \\sum_{i=1}^n x_i^2 } \\sqrt{ \\sum_{i=1}^n y_i^2 } }\n$$\n<p>Nel nostro caso:</p>\n<ul>\n<li>Vettore cherry = (442, 8, 2)</li>\n<li>Vettore digital = (5, 1683, 1670)</li>\n<li>Vettore information = (5, 3982, 3325)</li>\n</ul>\n<p>Calcoliamo:</p>\n<h5 id=\"similarita-tra-cherry-e-information\">Similarità tra cherry e information:</h5>\n$$\n\\cos(\\text{cherry}, \\text{information}) = \\frac{442 \\times 5 + 8 \\times 3982 + 2 \\times 3325}{\\sqrt{442^2 + 8^2 + 2^2} \\times \\sqrt{5^2 + 3982^2 + 3325^2}}\n$$\n$$\n= \\frac{2210 + 31856 + 6650}{\\sqrt{195364 + 64 + 4} \\times \\sqrt{25 + 15856224 + 11055625}}\n$$\n$$\n= \\frac{40716}{\\sqrt{195432} \\times \\sqrt{26911874}}\n$$\n$$\n= \\frac{40716}{442 \\times 5187}\n$$\n$$\n\\approx 0.017\n$$\n<h5 id=\"similarita-tra-digital-e-information\">Similarità tra digital e information:</h5>\n$$\n\\cos(\\text{digital}, \\text{information}) = \\frac{5 \\times 5 + 1683 \\times 3982 + 1670 \\times 3325}{\\sqrt{5^2 + 1683^2 + 1670^2} \\times \\sqrt{5^2 + 3982^2 + 3325^2}}\n$$\n$$\n= \\frac{25 + 6702906 + 5552750}{\\sqrt{25 + 2832729 + 2788900} \\times \\sqrt{25 + 15856224 + 11055625}}\n$$\n$$\n= \\frac{12255981}{\\sqrt{5621654} \\times \\sqrt{26911874}}\n$$\n$$\n= \\frac{12255981}{2370 \\times 5187}\n$$\n$$\n\\approx 0.996\n$$\n<p>✅ Quindi, <strong>digital</strong> e <strong>information</strong> sono <strong>molto più simili</strong> rispetto a <strong>cherry</strong> e <strong>information</strong>, come confermato dal valore molto vicino a 1 della loro similarità coseno.</p>\n<h2 id=\"4-visualizzazioni-intuitive\">4. Visualizzazioni Intuitive</h2>\n<h3 id=\"41-distanze-minkowski\">4.1 Distanze Minkowski</h3>\n<p>Supponi due vettori $x = (1, 2)$ e $y = (4, 6)$:</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align: left;\">Tipo</th>\n<th style=\"text-align: left;\">Formula</th>\n<th style=\"text-align: left;\">Calcolo</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align: left;\">Manhattan</td>\n<td style=\"text-align: left;\">$|1-4| + |2-6| = 3 + 4 = 7$</td>\n<td style=\"text-align: left;\">7</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Euclidea</td>\n<td style=\"text-align: left;\">$\\sqrt{(1-4)^2 + (2-6)^2} = \\sqrt{9+16} = \\sqrt{25}$</td>\n<td style=\"text-align: left;\">5</td>\n</tr>\n<tr>\n<td style=\"text-align: left;\">Chebyshev</td>\n<td style=\"text-align: left;\">$\\max(\\mid 1-4 \\mid ,  \\mid 2-6 \\mid ) = \\max(3,4)$</td>\n<td style=\"text-align: left;\">4</td>\n</tr>\n</tbody>\n</table>\n<p><img alt=\"Grafico distanze Minkowski\" src=\"/images/posts/minkowski-02-1024x288.webp\" /></p>\n<p><em>(Fonte: Wikipedia)</em></p>\n<h3 id=\"42-similarita-coseno\">4.2 Similarità Coseno</h3>\n<p>La similarità coseno si basa sull&rsquo;angolo tra due vettori:</p>\n<p><img alt=\"Grafico similarità coseno\" src=\"/images/posts/vector-search-cosine.png\" /></p>\n<p><em>(Fonte: Wikipedia)</em></p>\n<h2 id=\"5-osservazioni-finali\">5. Osservazioni Finali</h2>\n<ul>\n<li><strong>Le distanze Minkowski</strong> dipendono dalla scala delle componenti.</li>\n<li><strong>La similarità coseno</strong> è indipendente dalla scala: guarda solo la <strong>direzione</strong> dei vettori.</li>\n<li>La scelta della metrica dipende dal problema specifico:</li>\n<li>Clustering: solitamente distanza euclidea o Manhattan.</li>\n<li>Documenti di testo: similarità coseno.</li>\n<li>Sistemi di raccomandazione: dipende dalla sparsità dei dati.</li>\n</ul>"
}