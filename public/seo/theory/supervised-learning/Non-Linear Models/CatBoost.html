<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CatBoost: Unbiased Boosting with Categorical Features | Supervised Learning | ML Theory</title>
    <meta name="description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    <meta name="keywords" content="supervised learning, labeled data, classification, regression, model, data, training, learning">
    <meta name="robots" content="index, follow">
    
    <!-- Open Graph -->
    <meta property="og:title" content="CatBoost: Unbiased Boosting with Categorical Features">
    <meta property="og:description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    <meta property="og:url" content="http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Machine Learning Theory">
    
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="CatBoost: Unbiased Boosting with Categorical Features">
    <meta name="twitter:description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost">
    
    <!-- Preload critical resources -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    
    <!-- JSON-LD Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "CatBoost: Unbiased Boosting with Categorical Features",
      "description": "pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...",
      "url": "http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost",
      "datePublished": "2026-01-16T01:12:55.477Z",
      "author": {
        "@type": "Organization",
        "name": "ML Theory Platform"
      },
      "publisher": {
        "@type": "Organization",
        "name": "ML Theory Platform"
      }
    }
    </script>
    
    <!-- Critical CSS -->
    <style>
      body { 
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
        line-height: 1.6; 
        margin: 0; 
        padding: 20px;
        background: #fafafa;
      }
      .container { 
        max-width: 800px; 
        margin: 0 auto; 
        background: white;
        padding: 40px;
        border-radius: 8px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      }
      h1 { 
        color: #1a1a1a; 
        margin-bottom: 20px; 
        font-size: 2.5rem;
        line-height: 1.2;
      }
      .meta { 
        color: #666; 
        margin-bottom: 30px; 
        padding-bottom: 20px;
        border-bottom: 1px solid #eee;
      }
      .content h2, .content h3 { 
        color: #2c3e50; 
        margin-top: 40px; 
        margin-bottom: 16px;
      }
      .content p { 
        margin-bottom: 16px; 
        color: #333;
      }
      .content code { 
        background: #f8f9fa; 
        padding: 2px 6px; 
        border-radius: 4px; 
        font-size: 0.9em;
        color: #e83e8c;
      }
      .content pre { 
        background: #f8f9fa; 
        padding: 20px; 
        border-radius: 8px; 
        overflow-x: auto;
        border: 1px solid #e9ecef;
      }
      .react-redirect {
        position: fixed;
        top: 20px;
        right: 20px;
        background: #007acc;
        color: white;
        padding: 10px 20px;
        border-radius: 6px;
        text-decoration: none;
        font-weight: 500;
        box-shadow: 0 2px 8px rgba(0,122,204,0.3);
        transition: transform 0.2s;
      }
      .react-redirect:hover {
        transform: translateY(-1px);
      }
      @media (max-width: 768px) { 
        body { padding: 10px; }
        .container { padding: 20px; }
        h1 { font-size: 2rem; }
        .react-redirect { position: static; display: block; text-align: center; margin-bottom: 20px; }
      }
    </style>
</head>
<body>
    <!-- Link per versione interattiva -->
    <a href="http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost" class="react-redirect">üöÄ View Interactive Version</a>
    
    <div class="container">
        <article>
            <header>
                <h1>CatBoost: Unbiased Boosting with Categorical Features</h1>
                <div class="meta">
                    <strong>Topic:</strong> Supervised Learning | 
                    <strong>Updated:</strong> 16/01/2026
                </div>
            </header>
            
            <div class="content">
                <style>pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #F00 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #04D } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */
.codehilite .no { color: #800 } /* Name.Constant */
.codehilite .nd { color: #A2F } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #00F } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #BBB } /* Text.Whitespace */
.codehilite .mb { color: #666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666 } /* Literal.Number.Float */
.codehilite .mh { color: #666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #00F } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */

/* Styling per blocchi di codice */
.codehilite {
    background: transparent !important;
    border-radius: 8px;
    overflow: hidden;
}
.codehilite pre {
    background: transparent !important;
    margin: 0 !important;
    padding: 20px !important;
    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;
    font-size: 14px !important;
    line-height: 1.5 !important;
    white-space: pre !important;
    overflow-x: auto !important;
    color: inherit !important;
}
.codehilite code {
    background: transparent !important;
    padding: 0 !important;
    font-family: inherit !important;
}


.code-wrapper { 
    position: relative; 
}
.copy-button {
    position: absolute; 
    top: 12px; 
    right: 12px; 
    padding: 6px 12px; 
    font-size: 12px;
    cursor: pointer; 
    border: none; 
    border-radius: 4px; 
    background: rgba(255,255,255,0.9);
    color: #374151; 
    transition: all 0.2s ease;
    font-weight: 500;
}
.copy-button:hover { 
    background: rgba(255,255,255,1);
    transform: translateY(-1px);
}


details.code-container {
    border: 1px solid #e5e7eb; 
    border-radius: 12px; 
    background: #f9fafb;
    margin: 16px 0;
    transition: all 0.3s ease;
}
details.code-container summary {
    padding: 12px 16px;
    font-size: 14px; 
    color: #6b7280; 
    cursor: pointer; 
    outline: none; 
    user-select: none;
    font-weight: 500;
}
details.code-container[open] summary::after { 
    content: " (Hide Code)"; 
    color: #9ca3af; 
}
details.code-container:not([open]) summary::after { 
    content: " (Show Code)"; 
    color: #d1d5db; 
}
details.code-container .code-wrapper {
    padding: 0;
    margin: 0;
}
/* Blocchi di codice sempre visibili */
.code-visible {
    border: 1px solid #e5e7eb;
    border-radius: 12px;
    background: #f9fafb;
    margin: 16px 0;
}
.code-visible .code-wrapper {
    padding: 0;
    margin: 0;
}
</style>
<h2 id="indice">Indice</h2>
<ol>
<li><a href="#introduzione">Introduzione</a></li>
<li><a href="#background-teorico">Background Teorico</a></li>
<li><a href="#il-problema-delle-feature-categoriche">Il Problema delle Feature Categoriche</a></li>
<li><a href="#target-statistics">Target Statistics</a></li>
<li><a href="#prediction-shift-e-ordered-boosting">Prediction Shift e Ordered Boosting</a></li>
<li><a href="#implementazione-pratica">Implementazione Pratica</a></li>
<li><a href="#risultati-sperimentali">Risultati Sperimentali</a></li>
<li><a href="#conclusioni">Conclusioni</a></li>
</ol>
<hr />
<h2 id="introduzione">Introduzione</h2>
<p><strong>CatBoost</strong> (abbreviazione di &ldquo;Categorical Boosting&rdquo;) √® una libreria open-source per il gradient boosting sviluppata da Yandex che introduce due innovazioni algoritmiche fondamentali:</p>
<ol>
<li><strong>Ordered Boosting</strong>: un&rsquo;alternativa basata su permutazioni all&rsquo;algoritmo classico di gradient boosting</li>
<li><strong>Algoritmo innovativo per il processing delle feature categoriche</strong></li>
</ol>
<p>Entrambe queste tecniche sono state create per combattere il <strong>prediction shift</strong>, un particolare tipo di target leakage presente in tutte le implementazioni esistenti di gradient boosting.</p>
<h3 id="motivazione">Motivazione</h3>
<p>Il gradient boosting √® una delle tecniche di machine learning pi√π potenti e viene utilizzato con successo in moltissimi ambiti applicativi:
- Ricerca web
- Sistemi di raccomandazione
- Previsioni meteorologiche
- Problemi con feature eterogenee, dati rumorosi e dipendenze complesse</p>
<p>Nonostante il suo successo, <strong>tutti gli algoritmi esistenti soffrono di un problema statistico fondamentale</strong> che porta a un bias sistematico nelle predizioni.</p>
<hr />
<h2 id="background-teorico">Background Teorico</h2>
<h3 id="il-problema-di-apprendimento">Il Problema di Apprendimento</h3>
<p>Consideriamo un dataset $\mathcal{D} = \{(\mathbf{x}_k, y_k)\}_{k=1}^n$ dove:
- $\mathbf{x}_k = (x_k^1, \ldots, x_k^m)$ √® un vettore casuale di $m$ <strong>feature</strong>
- $y_k \in \mathbb{R}$ √® il <strong>target</strong> (pu√≤ essere binario o una risposta numerica)
- Gli esempi sono indipendenti e identicamente distribuiti secondo una distribuzione sconosciuta $P(\cdot, \cdot)$</p>
<p><strong>Obiettivo</strong>: Addestrare una funzione $F: \mathbb{R}^m \to \mathbb{R}$ che minimizza la perdita attesa:</p>
$$\mathcal{L}(F) := \mathbb{E} L(y, F(\mathbf{x}))$$
<p>dove:
- $L(\cdot, \cdot)$ √® una funzione di perdita liscia
- $(\mathbf{x}, y)$ √® un esempio di test campionato da $P$ indipendentemente dal training set</p>
<h3 id="gradient-boosting-principio-di-base">Gradient Boosting: Principio di Base</h3>
<p>Il gradient boosting costruisce iterativamente una sequenza di <strong>approssimazioni</strong> $F^t: \mathbb{R}^m \to \mathbb{R}$, per $t = 0, 1, \ldots$ in modo greedy.</p>
<p>Ad ogni step, la nuova approssimazione √® ottenuta in modo additivo:</p>
$$F^t = F^{t-1} + \alpha h^t$$
<p>dove:
- $\alpha$ √® lo <strong>step size</strong> (learning rate)
- $h^t: \mathbb{R}^m \to \mathbb{R}$ √® il <strong>base predictor</strong> (predittore di base)</p>
<p>Il base predictor viene scelto da una famiglia di funzioni $\mathcal{H}$ per minimizzare la perdita attesa:</p>
$$h^t = \arg\min_{h \in \mathcal{H}} \mathcal{L}(F^{t-1} + h) = \arg\min_{h \in \mathcal{H}} \mathbb{E} L(y, F^{t-1}(\mathbf{x}) + h(\mathbf{x}))$$
<h4 id="gradient-step">Gradient Step</h4>
<p>In pratica, questo problema di minimizzazione viene affrontato con il <strong>metodo di Newton</strong> o con uno <strong>step di gradiente negativo</strong>. Nel caso dello step di gradiente, $h^t$ viene scelto in modo che $h^t(\mathbf{x})$ approssimi $-g^t(\mathbf{x}, y)$, dove:</p>
$$g^t(\mathbf{x}, y) := \frac{\partial L(y, s)}{\partial s}\bigg|_{s=F^{t-1}(\mathbf{x})}$$
<p>Tipicamente si usa l&rsquo;approssimazione ai minimi quadrati:</p>
$$h^t = \arg\min_{h \in \mathcal{H}} \mathbb{E}\left(-g^t(\mathbf{x}, y) - h(\mathbf{x})\right)^2$$
<p><strong>Punto chiave</strong>: Questa √® la formulazione teorica. In pratica, l&rsquo;aspettazione √® sconosciuta e viene approssimata usando il training set $\mathcal{D}$.</p>
<h3 id="decision-trees-come-base-predictors">Decision Trees come Base Predictors</h3>
<p>CatBoost utilizza <strong>alberi di decisione binari</strong> come base predictors. Un albero di decisione √® un modello costruito attraverso una partizione ricorsiva dello spazio delle feature $\mathbb{R}^m$ in diverse regioni disgiunte (nodi dell&rsquo;albero).</p>
<h4 id="struttura-di-un-albero">Struttura di un Albero</h4>
<p>La partizione avviene secondo i valori di alcuni <strong>attributi di splitting</strong> $a$, che sono tipicamente variabili binarie del tipo:</p>
$$a = \mathbb{1}_{\{x^k > t\}}$$
<p>dove:
- $x^k$ √® una feature numerica o binaria
- $t$ √® una <strong>soglia</strong> (threshold)
- Nel caso di feature binarie, $t = 0.5$</p>
<p><strong>Perch√© split binari?</strong> 
- Split non binari (es. basati su tutti i valori di una feature categorica) porterebbero a:
  - Alberi poco profondi (incapaci di catturare dipendenze complesse), oppure
  - Alberi molto complessi con numero esponenziale di nodi terminali (con statistiche target pi√π deboli in ciascuno)
- La complessit√† dell&rsquo;albero ha un effetto cruciale sull&rsquo;accuratezza: alberi meno complessi sono meno soggetti a overfitting</p>
<h4 id="rappresentazione-matematica">Rappresentazione Matematica</h4>
<p>Ogni foglia (regione finale) dell&rsquo;albero √® associata a un valore che stima la risposta $y$. Un albero $h$ pu√≤ essere scritto come:</p>
$$h(\mathbf{x}) = \sum_{j=1}^J b_j \mathbb{1}_{\{\mathbf{x} \in R_j\}}$$
<p>dove:
- $R_j$ sono le regioni disgiunte corrispondenti alle foglie
- $b_j$ sono i valori assegnati a ciascuna foglia
- $J$ √® il numero totale di foglie</p>
<p>Nel gradient boosting, gli attributi di split e i valori delle foglie sono tipicamente scelti secondo il criterio dei minimi quadrati, poich√© l&rsquo;albero √® costruito per approssimare il gradiente negativo.</p>
<hr />
<h2 id="il-problema-delle-feature-categoriche">Il Problema delle Feature Categoriche</h2>
<h3 id="cosa-sono-le-feature-categoriche">Cosa sono le Feature Categoriche?</h3>
<p>Una <strong>feature categorica</strong> √® una variabile con un insieme discreto di valori chiamati <strong>categorie</strong>, che non sono confrontabili tra loro. Esempi tipici:
- User ID
- Regione geografica
- Tipo di prodotto
- Publisher
- Categoria di annuncio</p>
<p>Queste feature sono fondamentali in molte applicazioni pratiche, specialmente nel click prediction (previsione dei click su annunci pubblicitari).</p>
<h3 id="approcci-esistenti">Approcci Esistenti</h3>
<h4 id="1-one-hot-encoding">1. One-Hot Encoding</h4>
<p>La tecnica pi√π popolare consiste nel <strong>one-hot encoding</strong>: per ogni categoria si aggiunge una nuova feature binaria che indica se quella categoria √® presente.</p>
<p><strong>Problema</strong>: Per feature con <strong>alta cardinalit√†</strong> (molte categorie possibili, come &ldquo;user ID&rdquo;), questo approccio porta a un numero impraticabile di nuove feature.</p>
<p><strong>Soluzione comune</strong>: Raggruppare le categorie in un numero limitato di cluster e poi applicare one-hot encoding.</p>
<h4 id="2-target-statistics-ts">2. Target Statistics (TS)</h4>
<p>Un metodo popolare consiste nel raggruppare le categorie in base alle <strong>target statistics</strong>: si stima il valore atteso del target in ogni categoria.</p>
<p>Micci-Barreca (2001) propose di considerare le TS come nuove feature numeriche invece dell&rsquo;one-hot encoding.</p>
<p><strong>Vantaggio importante</strong>: Tra tutte le possibili partizioni delle categorie in due insiemi, uno split ottimale sui dati di training (in termini di logloss, Gini index, MSE) pu√≤ essere trovato tra le soglie sulla feature numerica TS.</p>
<h4 id="3-gradient-statistics-lightgbm">3. Gradient Statistics (LightGBM)</h4>
<p>LightGBM converte le feature categoriche in <strong>gradient statistics</strong> ad ogni step del gradient boosting.</p>
<p><strong>Problemi</strong>:
1. Aumento drammatico del tempo di computazione (calcola le statistiche per ogni valore categorico ad ogni step)
2. Aumento del consumo di memoria (deve memorizzare quale categoria appartiene a quale nodo per ogni split)
3. Per risolvere questi problemi, LightGBM raggruppa le categorie meno frequenti in un cluster unico, perdendo parte dell&rsquo;informazione</p>
<h3 id="conclusione-sullapproccio">Conclusione sull&rsquo;Approccio</h3>
<p><strong>Le Target Statistics come feature numeriche sembrano essere il metodo pi√π efficiente</strong> per gestire le feature categoriche con minima perdita di informazione. Richiedono di calcolare e memorizzare solo un numero per categoria.</p>
<p>Le TS sono ampiamente utilizzate, ad esempio nel click prediction (click-through rates), dove feature categoriche come user, region, ad, publisher giocano un ruolo cruciale.</p>
<hr />
<h2 id="target-statistics">Target Statistics</h2>
<h3 id="definizione">Definizione</h3>
<p>Come discusso, un modo efficace ed efficiente per gestire una feature categorica $i$ √® sostituire la categoria $x_k^i$ del $k$-esimo esempio di training con <strong>una</strong> feature numerica uguale a una <strong>target statistic</strong> $\hat{x}_k^i$.</p>
<p>Comunemente, questa stima il target atteso $y$ condizionato alla categoria:</p>
$$\hat{x}_k^i \approx \mathbb{E}(y \mid x^i = x_k^i)$$
<h3 id="greedy-ts-lapproccio-diretto-e-problematico">Greedy TS: L&rsquo;Approccio Diretto (e Problematico)</h3>
<p>Un approccio diretto consiste nello stimare $\mathbb{E}(y \mid x^i = x_k^i)$ come la media di $y$ sugli esempi di training con la stessa categoria $x_k^i$.</p>
<p>Per ridurre il rumore per categorie a bassa frequenza, si applica uno <strong>smoothing</strong> con un prior $p$:</p>
$$\hat{x}_k^i = \frac{\sum_{j=1}^n \mathbb{1}_{\{x_j^i = x_k^i\}} \cdot y_j + a \cdot p}{\sum_{j=1}^n \mathbb{1}_{\{x_j^i = x_k^i\}} + a}$$
<p>dove:
- $a > 0$ √® un parametro di smoothing
- $p$ √® tipicamente il valore medio del target nel dataset
- Il numeratore somma tutti i target degli esempi con la stessa categoria, pi√π un termine di prior
- Il denominatore conta quanti esempi hanno quella categoria, pi√π il peso del prior</p>
<p><strong>Spiegazione intuitiva dello smoothing</strong>: 
- Se una categoria appare poche volte, la media dei target potrebbe essere molto rumorosa
- Aggiungendo $a \cdot p$ al numeratore e $a$ al denominatore, &ldquo;mescoliamo&rdquo; la stima empirica con il prior $p$
- Quando il numero di osservazioni √® piccolo, la stima si avvicina a $p$
- Quando il numero di osservazioni √® grande, la stima si avvicina alla media empirica</p>
<h3 id="il-problema-del-target-leakage">Il Problema del Target Leakage</h3>
<p>Il problema di questo approccio <strong>greedy</strong> √® il <strong>target leakage</strong>: la feature $\hat{x}_k^i$ √® calcolata usando $y_k$, il target di $\mathbf{x}_k$ stesso!</p>
<p>Questo porta a un <strong>conditional shift</strong>: la distribuzione di $\hat{x}^i \mid y$ differisce tra esempi di training e test.</p>
<h4 id="esempio-estremo">Esempio Estremo</h4>
<p>Consideriamo un caso estremo per illustrare quanto questo possa influenzare drasticamente l&rsquo;errore di generalizzazione:</p>
<p><strong>Setup</strong>:
- La $i$-esima feature √® categorica
- Tutti i suoi valori sono unici (ogni esempio ha una categoria diversa)
- Per ogni categoria $A$: $P(y=1 \mid x^i = A) = 0.5$ (classificazione binaria)</p>
<p><strong>Sul training set</strong>:
- $\hat{x}_k^i = \frac{y_k + ap}{1 + a}$
- √à sufficiente uno split con soglia $t = \frac{0.5 + ap}{1 + a}$ per classificare perfettamente tutti gli esempi di training</p>
<p><strong>Sul test set</strong>:
- Per tutti gli esempi test, la greedy TS vale $p$
- Il modello predice $0$ per tutti se $p < t$, oppure $1$ se $p \geq t$
- <strong>Accuracy = 0.5</strong> in entrambi i casi!</p>
<h3 id="proprieta-desiderata-p1">Propriet√† Desiderata P1</h3>
<p>Formuliamo la seguente propriet√† desiderata per le TS:</p>
<p><strong>P1</strong>: $\mathbb{E}(\hat{x}^i \mid y = v) = \mathbb{E}(\hat{x}_k^i \mid y_k = v)$</p>
<p>dove $(\mathbf{x}_k, y_k)$ √® il $k$-esimo esempio di training.</p>
<p>Nell&rsquo;esempio sopra: 
- $\mathbb{E}(\hat{x}_k^i \mid y_k) = \frac{y_k + ap}{1 + a}$ (dipende da $y_k$!)
- $\mathbb{E}(\hat{x}^i \mid y) = p$ (costante)
- Le due distribuzioni sono diverse ‚Üí violazione di P1</p>
<h3 id="approcci-per-evitare-il-conditional-shift">Approcci per Evitare il Conditional Shift</h3>
<p>L&rsquo;idea generale √® calcolare la TS per $\mathbf{x}_k$ su un sottoinsieme di esempi $\mathcal{D}_k \subset \mathcal{D} \setminus \{\mathbf{x}_k\}$ che <strong>esclude</strong> $\mathbf{x}_k$:</p>
$$\hat{x}_k^i = \frac{\sum_{\mathbf{x}_j \in \mathcal{D}_k} \mathbb{1}_{\{x_j^i = x_k^i\}} \cdot y_j + a \cdot p}{\sum_{\mathbf{x}_j \in \mathcal{D}_k} \mathbb{1}_{\{x_j^i = x_k^i\}} + a}$$
<h4 id="holdout-ts">Holdout TS</h4>
<p>Un modo √® partizionare il training set in due parti: $\mathcal{D} = \hat{\mathcal{D}}_0 \sqcup \hat{\mathcal{D}}_1$</p>
<ul>
<li>Si usa $\mathcal{D}_k = \hat{\mathcal{D}}_0$ per calcolare le TS</li>
<li>Si usa $\hat{\mathcal{D}}_1$ per il training</li>
</ul>
<p><strong>Vantaggi</strong>: Questo approccio holdout soddisfa P1.</p>
<p><strong>Svantaggi</strong>: Riduce significativamente la quantit√† di dati usati sia per il training che per il calcolo delle TS. Viola la seguente propriet√† desiderata:</p>
<p><strong>P2</strong>: <em>Uso efficace di tutti i dati di training sia per calcolare le TS che per apprendere il modello</em></p>
<h4 id="leave-one-out-ts">Leave-One-Out TS</h4>
<p>A prima vista, la tecnica <strong>leave-one-out</strong> potrebbe sembrare funzionare bene:
- Per esempi di training $\mathbf{x}_k$: si prende $\mathcal{D}_k = \mathcal{D} \setminus \{\mathbf{x}_k\}$
- Per esempi di test: si prende $\mathcal{D}_k = \mathcal{D}$</p>
<p><strong>Sorprendentemente, questo NON previene il target leakage!</strong></p>
<p><strong>Controesempio</strong>: Consideriamo una feature categorica costante: $x_k^i = A$ per tutti gli esempi.</p>
<p>Sia $n^+$ il numero di esempi con $y = 1$. Allora:</p>
$$\hat{x}_k^i = \frac{n^+ - y_k + a \cdot p}{n - 1 + a}$$
<p>Si pu√≤ classificare perfettamente il training set con uno split alla soglia:</p>
$$t = \frac{n^+ - 0.5 + a \cdot p}{n - 1 + a}$$
<p>Infatti:
- Se $y_k = 1$: $\hat{x}_k^i = \frac{n^+ - 1 + ap}{n - 1 + a} < t$
- Se $y_k = 0$: $\hat{x}_k^i = \frac{n^+ + ap}{n - 1 + a} > t$</p>
<h3 id="ordered-ts-la-soluzione-di-catboost">Ordered TS: La Soluzione di CatBoost</h3>
<p>CatBoost usa una strategia pi√π efficace basata sul <strong>principio di ordinamento</strong> (ordering principle), idea centrale dell&rsquo;intero paper.</p>
<p><strong>Ispirazione</strong>: Algoritmi di online learning che ricevono esempi di training sequenzialmente nel tempo. In questi algoritmi, i valori delle TS per ogni esempio dipendono solo dalla &ldquo;storia&rdquo; osservata fino a quel momento.</p>
<p><strong>Adattamento all&rsquo;offline setting</strong>:</p>
<ol>
<li>Introduciamo un &ldquo;tempo&rdquo; artificiale: una <strong>permutazione casuale</strong> $\sigma$ degli esempi di training</li>
<li>Per ogni esempio, usiamo tutta la &ldquo;storia&rdquo; disponibile per calcolare la sua TS:</li>
<li>$\mathcal{D}_k = \{\mathbf{x}_j : \sigma(j) < \sigma(k)\}$ per un esempio di training</li>
<li>$\mathcal{D}_k = \mathcal{D}$ per un esempio di test</li>
</ol>
<p><strong>Propriet√† delle Ordered TS</strong>:
- ‚úì Soddisfa P1 (nessun conditional shift)
- ‚úì Soddisfa P2 (usa tutti i dati per il training)
- <strong>Problema</strong>: Se usiamo una sola permutazione, gli esempi iniziali hanno TS con varianza molto pi√π alta degli esempi successivi</p>
<p><strong>Soluzione</strong>: CatBoost usa <strong>diverse permutazioni</strong> per diversi step del gradient boosting (dettagli in Sezione Implementazione).</p>
<hr />
<h2 id="prediction-shift-e-ordered-boosting">Prediction Shift e Ordered Boosting</h2>
<h3 id="identificazione-del-problema">Identificazione del Problema</h3>
<p>In questa sezione riveliamo il problema del <strong>prediction shift</strong> nel gradient boosting, che non era stato precedentemente riconosciuto n√© affrontato.</p>
<p>Come nel caso delle TS, il prediction shift √® causato da un particolare tipo di target leakage.</p>
<h3 id="il-problema-nella-pratica">Il Problema nella Pratica</h3>
<p>Ricordiamo che nella teoria (Sezione Background) il gradient step √® definito come:</p>
$$h^t = \arg\min_{h \in \mathcal{H}} \mathbb{E}\left(-g^t(\mathbf{x}, y) - h(\mathbf{x})\right)^2$$
<p><strong>In pratica</strong>, l&rsquo;aspettazione √® sconosciuta e viene approssimata usando lo stesso dataset $\mathcal{D}$:</p>
$$h^t = \arg\min_{h \in \mathcal{H}} \frac{1}{n} \sum_{k=1}^n \left(-g^t(\mathbf{x}_k, y_k) - h(\mathbf{x}_k)\right)^2$$
<p>dove ricordiamo che:</p>
$$g^t(\mathbf{x}_k, y_k) = \frac{\partial L(y_k, s)}{\partial s}\bigg|_{s=F^{t-1}(\mathbf{x}_k)}$$
<h3 id="la-catena-di-shift">La Catena di Shift</h3>
<p>Descriviamo la seguente catena di problemi:</p>
<ol>
<li>
<p><strong>Shift dei gradienti</strong>: La distribuzione condizionale del gradiente $g^t(\mathbf{x}_k, y_k) \mid \mathbf{x}_k$ (considerando la casualit√† di $\mathcal{D} \setminus \{\mathbf{x}_k\}$) √® shifted rispetto alla distribuzione su un esempio test $g^t(\mathbf{x}, y) \mid \mathbf{x}$</p>
</li>
<li>
<p><strong>Bias del base predictor</strong>: Il base predictor $h^t$ definito dall&rsquo;equazione pratica √® biased rispetto alla soluzione dell&rsquo;equazione teorica</p>
</li>
<li>
<p><strong>Impatto sulla generalizzazione</strong>: Questo influenza infine la capacit√† di generalizzazione del modello addestrato $F^t$</p>
</li>
</ol>
<h3 id="causa-target-leakage">Causa: Target Leakage</h3>
<p>Questi problemi sono causati da <strong>target leakage</strong>. I gradienti usati ad ogni step sono stimati usando i valori target degli stessi data point su cui √® stato costruito il modello corrente $F^{t-1}$.</p>
<p><strong>Il problema fondamentale</strong>: La distribuzione condizionale $F^{t-1}(\mathbf{x}_k) \mid \mathbf{x}_k$ per un esempio di training $\mathbf{x}_k$ √® shifted, in generale, rispetto alla distribuzione $F^{t-1}(\mathbf{x}) \mid \mathbf{x}$ per un esempio test $\mathbf{x}$.</p>
<p>Questo √® chiamato <strong>prediction shift</strong>.</p>
<h3 id="letteratura-esistente">Letteratura Esistente</h3>
<p>Il problema √® stato menzionato in precedenza ma mai formalmente definito:</p>
<h4 id="iterated-bagging-breiman-2001">Iterated Bagging (Breiman, 2001)</h4>
<p>Basato sulla stima out-of-bag, costruisce un weak learner bagged ad ogni iterazione basandosi su stime residue &ldquo;out-of-bag&rdquo;.</p>
<p><strong>Problema</strong>: Come dimostrato formalmente dagli autori nell&rsquo;Appendice, queste stime residue sono ancora shifted!</p>
<p>Inoltre, lo schema di bagging aumenta il tempo di apprendimento di un fattore pari al numero di bucket di dati.</p>
<h4 id="subsampling-friedman-2002">Subsampling (Friedman, 2002)</h4>
<p>Proposto il subsampling del dataset ad ogni iterazione.</p>
<p><strong>Problema</strong>: Affronta il problema in modo molto pi√π euristico e solo lo allevia, non lo risolve.</p>
<h3 id="analisi-formale-caso-semplificato">Analisi Formale: Caso Semplificato</h3>
<p>Analizziamo formalmente il prediction shift in un caso semplice:
- Task di regressione con funzione di perdita quadratica: $L(y, \hat{y}) = (y - \hat{y})^2$</p>
<p>In questo caso, il gradiente negativo $-g^t(\mathbf{x}_k, y_k)$ pu√≤ essere sostituito dalla <strong>funzione residuo</strong>:</p>
$$r^{t-1}(\mathbf{x}_k, y_k) := y_k - F^{t-1}(\mathbf{x}_k)$$
<p>(abbiamo rimosso il moltiplicatore 2, che non √® rilevante per l&rsquo;analisi)</p>
<h4 id="setup-del-teorema">Setup del Teorema</h4>
<p>Assumiamo:
- $m = 2$ feature: $x^1, x^2$
- Entrambe sono variabili di Bernoulli i.i.d. con $p = 1/2$
- $y = f^*(\mathbf{x}) = c_1 x^1 + c_2 x^2$ (dipendenza lineare vera)
- Facciamo $N = 2$ step di gradient boosting con decision stumps (alberi di profondit√† 1)
- Step size $\alpha = 1$
- Otteniamo un modello $F = F^2 = h^1 + h^2$
- Assumiamo (senza perdita di generalit√†) che $h^1$ sia basato su $x^1$ e $h^2$ su $x^2$</p>
<h3 id="teorema-1-risultato-principale">Teorema 1 (Risultato Principale)</h3>
<p><strong>Parte 1</strong>: Se due campioni indipendenti $\mathcal{D}_1$ e $\mathcal{D}_2$ di dimensione $n$ sono usati per stimare $h^1$ e $h^2$ rispettivamente, allora:</p>
$$\mathbb{E}_{\mathcal{D}_1, \mathcal{D}_2} F^2(\mathbf{x}) = f^*(\mathbf{x}) + O(1/2^n)$$
<p>per ogni $\mathbf{x} \in \{0,1\}^2$.</p>
<p><strong>Interpretazione</strong>: Il modello addestrato √® una stima <strong>unbiased</strong> della vera dipendenza $y = f^*(\mathbf{x})$ (fino a un termine esponenzialmente piccolo, che si verifica per ragioni tecniche).</p>
<p><strong>Parte 2</strong>: Se lo stesso dataset $\mathcal{D} = \mathcal{D}_1 = \mathcal{D}_2$ √® usato per entrambi $h^1$ e $h^2$, allora:</p>
$$\mathbb{E}_{\mathcal{D}} F^2(\mathbf{x}) = f^*(\mathbf{x}) - \frac{1}{n-1} c_2 \left(x^2 - \frac{1}{2}\right) + O(1/2^n)$$
<p><strong>Interpretazione</strong>: Soffriamo di un <strong>bias</strong> pari a $-\frac{1}{n-1} c_2(x^2 - 1/2)$, che √®:
- Inversamente proporzionale alla dimensione dei dati $n$
- Dipendente dalla relazione vera $f^*$ (proporzionale a $c_2$)</p>
<h4 id="sketch-della-dimostrazione-parte-2">Sketch della Dimostrazione (Parte 2)</h4>
<p>Denotiamo con $\xi_{st}$, $s,t \in \{0,1\}$, il numero di esempi $(\mathbf{x}_k, y_k) \in \mathcal{D}$ con $\mathbf{x}_k = (s,t)$.</p>
<p><strong>Step 1 - Primo stump</strong>: </p>
$$h^1(s,t) = c_1 s + \frac{c_2 \xi_{s1}}{\xi_{s0} + \xi_{s1}}$$
<p>Il valore atteso su un <strong>esempio test</strong> $\mathbf{x}$ √®:</p>
$$\mathbb{E}(h^1(\mathbf{x})) = c_1 x^1 + \frac{c_2}{2}$$
<p>Il valore atteso su un <strong>esempio di training</strong> $\mathbf{x}_k$ √® diverso:</p>
$$\mathbb{E}(h^1(\mathbf{x}_k)) = \left(c_1 x^1 + \frac{c_2}{2}\right) - c_2 \left(\frac{2x^2 - 1}{n}\right) + O(2^{-n})$$
<p><strong>Questo √® il prediction shift di $h^1$!</strong></p>
<p><strong>Step 2 - Conseguenza sul secondo stump</strong>: Come conseguenza di questo shift, il valore atteso di $h^2$ √®:</p>
$$\mathbb{E}(h^2(\mathbf{x})) = c_2\left(x^2 - \frac{1}{2}\right)\left(1 - \frac{1}{n-1}\right) + O(2^{-n})$$
<p>su un esempio test $\mathbf{x}$.</p>
<p><strong>Step 3 - Risultato finale</strong>:</p>
$$\mathbb{E}(h^1(\mathbf{x}) + h^2(\mathbf{x})) = f^*(\mathbf{x}) - \frac{1}{n-1} c_2\left(x^2 - \frac{1}{2}\right) + O(1/2^n)$$
<h3 id="connessione-con-le-greedy-ts">Connessione con le Greedy TS</h3>
<p>Ricordiamo che le greedy TS $\hat{x}^i$ possono essere considerate come un semplice modello statistico che predice il target $y$.</p>
<p>Soffrono di un problema simile: conditional shift di $\hat{x}_k^i \mid y_k$, causato dal target leakage (usare $y_k$ per calcolare $\hat{x}_k^i$).</p>
<hr />
<h2 id="ordered-boosting">Ordered Boosting</h2>
<h3 id="idea-di-base">Idea di Base</h3>
<p>Proponiamo un algoritmo di boosting che non soffre del problema di prediction shift.</p>
<p><strong>Scenario ideale</strong> (con dati illimitati): Ad ogni step del boosting, campioniamo un nuovo dataset $\mathcal{D}_t$ indipendentemente e otteniamo residui unshifted applicando il modello corrente ai nuovi esempi di training.</p>
<p><strong>Problema pratico</strong>: I dati etichettati sono limitati!</p>
<h3 id="lapproccio-con-modelli-multipli">L&rsquo;Approccio con Modelli Multipli</h3>
<p>Assumiamo di voler imparare un modello con $I$ alberi.</p>
<p><strong>Osservazione chiave</strong>: Per rendere il residuo $r^{I-1}(\mathbf{x}_k, y_k)$ unshifted, abbiamo bisogno che $F^{I-1}$ sia addestrato <strong>senza</strong> l&rsquo;esempio $\mathbf{x}_k$.</p>
<p><strong>Problema apparente</strong>: Poich√© abbiamo bisogno di residui unbiased per tutti gli esempi di training, nessun esempio pu√≤ essere usato per training $F^{I-1}$, il che sembrerebbe rendere impossibile il processo di training.</p>
<p><strong>Soluzione</strong>: √à possibile mantenere un insieme di modelli che differiscono per gli esempi usati nel loro training. Poi, per calcolare il residuo su un esempio, usiamo un modello addestrato senza di esso.</p>
<h3 id="applicazione-del-principio-di-ordinamento">Applicazione del Principio di Ordinamento</h3>
<p>Per costruire tale insieme di modelli, usiamo il <strong>principio di ordinamento</strong> (gi√† applicato alle TS).</p>
<p><strong>Algoritmo concettuale</strong>:
1. Prendiamo una permutazione casuale $\sigma$ degli esempi di training
2. Manteniamo $n$ diversi <strong>modelli di supporto</strong> $M_1, \ldots, M_n$ tali che il modello $M_i$ √® appreso usando solo i primi $i$ esempi nella permutazione
3. Ad ogni step, per ottenere il residuo per il $j$-esimo esempio, usiamo il modello $M_{j-1}$</p>
<h3 id="algoritmo-1-ordered-boosting-versione-concettuale">Algoritmo 1: Ordered Boosting (Versione Concettuale)</h3>
<p><strong>Input</strong>: $\{(\mathbf{x}_k, y_k)\}_{k=1}^n$, $I$ (numero di iterazioni)</p>
<ol>
<li>$\sigma \leftarrow$ permutazione casuale di $[1,n]$</li>
<li>$M_i \leftarrow 0$ per $i = 1, \ldots, n$</li>
<li><strong>Per</strong> $t \leftarrow 1$ <strong>a</strong> $I$:</li>
<li><strong>Per</strong> $i \leftarrow 1$ <strong>a</strong> $n$:<ul>
<li>$r_i \leftarrow y_i - M_{\sigma(i)-1}(\mathbf{x}_i)$ (calcola residuo usando modello precedente)</li>
</ul>
</li>
<li><strong>Per</strong> $i \leftarrow 1$ <strong>a</strong> $n$:<ul>
<li>$\Delta M \leftarrow \text{LearnModel}((\mathbf{x}_j, r_j) : \sigma(j) \leq i)$</li>
<li>$M_i \leftarrow M_i + \Delta M$ (aggiorna modello)</li>
</ul>
</li>
<li><strong>Return</strong> $M_n$</li>
</ol>
<p><strong>Problema pratico</strong>: Questo algoritmo non √® fattibile nella maggior parte dei task pratici a causa della necessit√† di addestrare $n$ modelli diversi, il che aumenta la complessit√† e i requisiti di memoria di un fattore $n$.</p>
<p><strong>Soluzione</strong>: In CatBoost, √® implementata una modifica efficiente di questo algoritmo basata su GBDT con alberi di decisione come base predictors.</p>
<h3 id="ordered-boosting-con-feature-categoriche">Ordered Boosting con Feature Categoriche</h3>
<p>Abbiamo proposto di usare permutazioni casuali per:
- $\sigma_{cat}$: per il calcolo delle TS
- $\sigma_{boost}$: per l&rsquo;ordered boosting</p>
<p><strong>Domanda cruciale</strong>: Quando le combiniamo in un unico algoritmo, queste due permutazioni devono essere in qualche modo dipendenti?</p>
<p><strong>Risposta</strong>: S√¨! Devono coincidere: $\sigma_{cat} = \sigma_{boost}$</p>
<p><strong>Perch√©?</strong> Se le permutazioni fossero diverse, esisterebbero esempi $\mathbf{x}_i$ e $\mathbf{x}_j$ tali che:
- $\sigma_{boost}(i) < \sigma_{boost}(j)$, ma
- $\sigma_{cat}(i) > \sigma_{cat}(j)$</p>
<p>In questo caso:
- Il modello $M_{\sigma_{boost}(j)}$ √® addestrato usando, in particolare, le TS dell&rsquo;esempio $\mathbf{x}_i$
- Ma queste TS sono calcolate usando $y_j$ (il target di $\mathbf{x}_j$)
- Questo pu√≤ causare uno shift nella predizione $M_{\sigma_{boost}(j)}(\mathbf{x}_j)$</p>
<p><strong>Garanzia teorica</strong>: Impostando $\sigma_{cat} = \sigma_{boost}$, garantiamo che il target $y_i$ non sia usato per addestrare $M_i$ (n√© per il calcolo delle TS, n√© per la stima del gradiente).</p>
<hr />
<h2 id="implementazione-pratica">Implementazione Pratica</h2>
<p>CatBoost ha due modalit√† di boosting:</p>
<ol>
<li><strong>Plain</strong>: L&rsquo;algoritmo GBDT standard con TS ordinate incorporate</li>
<li><strong>Ordered</strong>: Una modifica efficiente dell&rsquo;Algoritmo 1 (Ordered Boosting)</li>
</ol>
<h3 id="permutazioni-multiple">Permutazioni Multiple</h3>
<p>All&rsquo;inizio, CatBoost genera $s+1$ permutazioni casuali indipendenti del dataset di training:</p>
<ul>
<li><strong>$\sigma_1, \ldots, \sigma_s$</strong>: Usate per la valutazione degli split che definiscono le strutture degli alberi (nodi interni)</li>
<li><strong>$\sigma_0$</strong>: Usata per scegliere i valori delle foglie $b_j$ degli alberi ottenuti</li>
</ul>
<p><strong>Perch√© multiple permutazioni?</strong></p>
<p>Per esempi con &ldquo;storia&rdquo; breve in una data permutazione:
- Le TS hanno alta varianza
- Le predizioni usate dall&rsquo;ordered boosting ($M_{\sigma(i)-1}(\mathbf{x}_i)$) hanno alta varianza</p>
<p>Usare solo una permutazione aumenterebbe la varianza delle predizioni finali del modello.</p>
<p><strong>Pi√π permutazioni</strong> permettono di ridurre questo effetto, come confermato dagli esperimenti.</p>
<h3 id="oblivious-decision-trees">Oblivious Decision Trees</h3>
<p>CatBoost usa come base predictors gli <strong>oblivious decision trees</strong> (anche chiamati decision tables).</p>
<p><strong>Definizione</strong>: Un albero si dice &ldquo;oblivious&rdquo; se lo stesso criterio di splitting √® usato attraverso un intero livello dell&rsquo;albero.</p>
<p><strong>Propriet√†</strong>:
- Alberi bilanciati
- Meno inclini all&rsquo;overfitting
- Permettono di accelerare significativamente l&rsquo;esecuzione al tempo di test</p>
<h3 id="procedura-di-costruzione-di-un-albero">Procedura di Costruzione di un Albero</h3>
<h4 id="modalita-ordered">Modalit√† Ordered</h4>
<p>Durante il processo di apprendimento, manteniamo i <strong>modelli di supporto</strong> $M_{r,j}$, dove:
- $M_{r,j}(i)$ √® la predizione corrente per il $i$-esimo esempio
- Basata sui primi $j$ esempi nella permutazione $\sigma_r$</p>
<p><strong>Ad ogni iterazione $t$</strong>:</p>
<ol>
<li>
<p><strong>Selezione permutazione</strong>: Campioniamo una permutazione casuale $\sigma_r$ da $\{\sigma_1, \ldots, \sigma_s\}$</p>
</li>
<li>
<p><strong>Calcolo TS</strong>: Per le feature categoriche, tutte le TS sono calcolate secondo questa permutazione</p>
</li>
<li>
<p><strong>Calcolo gradienti</strong>: Basandoci su $M_{r,j}(i)$, calcoliamo i gradienti corrispondenti:
   $g_{r,j}(i) = \frac{\partial L(y_i, s)}{\partial s}\bigg|_{s=M_{r,j}(i)}$</p>
</li>
<li>
<p><strong>Costruzione albero</strong>: Durante la costruzione dell&rsquo;albero, approssimiamo il gradiente $G$ in termini di similarit√† del coseno $\cos(\cdot, \cdot)$, dove per ogni esempio $i$ prendiamo il gradiente $g_{r,\sigma(i)-1}(i)$ (basato solo sugli esempi precedenti in $\sigma_r$)</p>
</li>
<li>
<p><strong>Valutazione split candidati</strong>: Il valore della foglia $\Delta(i)$ per l&rsquo;esempio $i$ √® ottenuto individualmente facendo la media dei gradienti $g_{r,\sigma_r(i)-1}$ degli esempi precedenti $p$ che si trovano nella stessa foglia $\text{leaf}_r(i)$ a cui appartiene l&rsquo;esempio $i$</p>
</li>
<li>
<p><strong>Struttura comune</strong>: Quando la struttura dell&rsquo;albero $T_t$ (sequenza di attributi di splitting) √® costruita, la usiamo per boostare <strong>tutti</strong> i modelli $M_{r',j}$. Una struttura comune √® usata per tutti i modelli, ma l&rsquo;albero √® aggiunto a diversi $M_{r',j}$ con diversi insiemi di valori delle foglie</p>
</li>
</ol>
<h4 id="modalita-plain">Modalit√† Plain</h4>
<p>Funziona similmente a una procedura GBDT standard, ma:
- Se le feature categoriche sono presenti, mantiene $s$ modelli di supporto $M_r$ corrispondenti alle TS basate su $\sigma_1, \ldots, \sigma_s$</p>
<h3 id="scelta-dei-valori-delle-foglie">Scelta dei Valori delle Foglie</h3>
<p>Dati tutti gli alberi costruiti, i valori delle foglie del modello finale $F$ sono calcolati dalla procedura standard di gradient boosting, ugualmente per entrambe le modalit√†:</p>
<ol>
<li>Gli esempi di training $i$ sono associati alle foglie $\text{leaf}_0(i)$</li>
<li>Si usa la permutazione $\sigma_0$ per calcolare le TS</li>
<li>Quando il modello finale $F$ √® applicato a un nuovo esempio al tempo di test, si usano TS calcolate sull&rsquo;intero training data</li>
</ol>
<h3 id="trick-di-complessita">Trick di Complessit√†</h3>
<p>Nell&rsquo;implementazione pratica, si usa un trick importante che riduce significativamente la complessit√† computazionale.</p>
<p><strong>Invece di</strong> $O(s \cdot n^2)$ valori $M_{r,j}(i)$, memorizziamo e aggiorniamo solo i valori:</p>
<p>$M'_{r,j}(i) := M_{r,2^j}(i)$</p>
<p>per:
- $j = 1, \ldots, \lceil \log_2 n \rceil$
- Tutti gli $i$ con $\sigma_r(i) \leq 2^{j+1}$</p>
<p><strong>Riduzione</strong>: Questo riduce il numero di predizioni di supporto mantenute a $O(s \cdot n)$.</p>
<h3 id="complessita-computazionale">Complessit√† Computazionale</h3>
<p>La complessit√† computazionale per iterazione √® mostrata nella seguente tabella:</p>
<table>
<thead>
<tr>
<th>Procedura</th>
<th>Complessit√†</th>
</tr>
</thead>
<tbody>
<tr>
<td>CalcGradient</td>
<td>$O(s \cdot n)$</td>
</tr>
<tr>
<td>Build $T$</td>
<td>$O(\|C\| \cdot n)$</td>
</tr>
<tr>
<td>Calc values $b_j^t$</td>
<td>$O(n)$</td>
</tr>
<tr>
<td>Update $M$</td>
<td>$O(s \cdot n)$</td>
</tr>
<tr>
<td>Calc ordered TS</td>
<td>$O(N_{TS,t} \cdot n)$</td>
</tr>
</tbody>
</table>
<p>dove:
- $C$ √® l&rsquo;insieme di split candidati da considerare all&rsquo;iterazione data
- $N_{TS,t}$ √® il numero di TS da calcolare all&rsquo;iterazione $t$</p>
<p><strong>Conclusione</strong>: L&rsquo;implementazione di ordered boosting con alberi di decisione ha la <strong>stessa complessit√† asintotica</strong> del GBDT standard con TS ordinate.</p>
<p>Rispetto ad altri tipi di TS, le ordered TS rallentano di un fattore $s$ le procedure: CalcGradient, aggiornamento modelli $M$, e calcolo delle TS.</p>
<h3 id="combinazioni-di-feature">Combinazioni di Feature</h3>
<p>Un dettaglio importante di CatBoost √® l&rsquo;uso di <strong>combinazioni di feature categoriche</strong> come feature categoriche aggiuntive.</p>
<p><strong>Motivazione</strong>: Catturano dipendenze di ordine superiore, come l&rsquo;informazione congiunta di user ID e topic dell&rsquo;annuncio nel task di ad click prediction.</p>
<p><strong>Problema</strong>: Il numero di combinazioni possibili cresce esponenzialmente con il numero di feature categoriche nel dataset.</p>
<p><strong>Soluzione greedy di CatBoost</strong>: Per ogni split di un albero, CatBoost combina (concatena):
- Tutte le feature categoriche (e loro combinazioni) gi√† usate per split precedenti nell&rsquo;albero corrente
- Con tutte le feature categoriche nel dataset</p>
<p>Le combinazioni sono convertite in TS al volo.</p>
<h3 id="bayesian-bootstrap">Bayesian Bootstrap</h3>
<p>Prima di addestrare un albero, si assegna un peso $w_i = a_i^t$ a ogni esempio $i$, dove $a_i^t$ sono generati secondo la procedura di Bayesian bootstrap.</p>
<p>Questi pesi sono usati come moltiplicatori per i gradienti quando si calcolano:
- $\Delta(i)$
- Le componenti del vettore $\Delta - G$ per definire $\text{loss}(T_c)$</p>
<p><strong>Motivazione</strong>: Anche se il subsampling da solo non pu√≤ evitare completamente il problema di prediction shift, si √® dimostrato efficace nella pratica.</p>
<h3 id="gestione-degli-esempi-iniziali">Gestione degli Esempi Iniziali</h3>
<p>Per esempi $i$ con valori piccoli di $\sigma_r(i)$, la varianza di $g_{r,\sigma_r(i)-1}(i)$ pu√≤ essere alta.</p>
<p><strong>Soluzione</strong>: Si scartano i $\Delta(i)$ dall&rsquo;inizio della permutazione quando si calcola la loss. Specificamente, si eliminano le componenti corrispondenti dei vettori $G$ e $\Delta$ quando si calcola la similarit√† del coseno.</p>
<hr />
<h2 id="risultati-sperimentali">Risultati Sperimentali</h2>
<h3 id="setup-sperimentale">Setup Sperimentale</h3>
<p>Gli esperimenti confrontano CatBoost con le librerie open-source pi√π popolari:
- <strong>XGBoost</strong>
- <strong>LightGBM</strong></p>
<p>Su vari task di machine learning ben noti.</p>
<h4 id="preprocessing">Preprocessing</h4>
<p>Per XGBoost, LightGBM e il raw setting di CatBoost:
- Le feature categoriche sono preprocessate calcolando ordered TS basate su una permutazione casuale degli esempi del training set
- I valori risultanti delle TS sono considerati feature numeriche</p>
<h4 id="tuning-dei-parametri">Tuning dei Parametri</h4>
<p>Si usa l&rsquo;algoritmo di ottimizzazione sequenziale <strong>Tree Parzen Estimator</strong> (implementato nella libreria Hyperopt) con 50 step, minimizzando la logloss.</p>
<h4 id="train-test-split">Train-Test Split</h4>
<ul>
<li>80% training set</li>
<li>20% test set</li>
<li>Cross-validazione a 5 fold per il tuning dei parametri</li>
</ul>
<h3 id="dataset-utilizzati">Dataset Utilizzati</h3>
<p>Gli esperimenti sono stati condotti su 9 dataset:</p>
<ol>
<li><strong>Adult</strong> (48,842 istanze, 15 feature): Previsione se una persona guadagna pi√π di 50K all&rsquo;anno</li>
<li><strong>Amazon</strong> (32,769 istanze, 10 feature): Kaggle Amazon Employee challenge</li>
<li><strong>Click Prediction</strong> (399,482 istanze, 12 feature): Previsione click su annunci (KDD Cup 2012)</li>
<li><strong>Epsilon</strong> (400,000 istanze, 2000 feature): PASCAL Challenge 2008</li>
<li><strong>KDD Appetency</strong> (50,000 istanze, 231 feature)</li>
<li><strong>KDD Churn</strong> (50,000 istanze, 231 feature)</li>
<li><strong>KDD Internet</strong> (10,108 istanze, 69 feature): Versione binarizzata</li>
<li><strong>KDD Upselling</strong> (50,000 istanze, 231 feature)</li>
<li><strong>Kick Prediction</strong> (72,983 istanze, 36 feature): Kaggle &ldquo;Don&rsquo;t Get Kicked!&rdquo; challenge</li>
</ol>
<h3 id="risultati-confronto-con-baseline">Risultati: Confronto con Baseline</h3>
<p>CatBoost (modalit√† Ordered) supera gli altri algoritmi su <strong>tutti</strong> i dataset considerati.</p>
<p><strong>Significativit√† statistica</strong>: Eccetto tre dataset (Appetency, Churn e Upselling), i miglioramenti sono statisticamente significativi con p-value $\ll 0.01$ (paired one-tailed t-test).</p>
<h4 id="risultati-dettagliati-logloss-zero-one-loss">Risultati Dettagliati (Logloss / Zero-one loss)</h4>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>CatBoost</th>
<th>LightGBM</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Adult</td>
<td><strong>0.270 / 0.127</strong></td>
<td>+2.4% / +1.9%</td>
<td>+2.2% / +1.0%</td>
</tr>
<tr>
<td>Amazon</td>
<td><strong>0.139 / 0.044</strong></td>
<td>+17% / +21%</td>
<td>+17% / +21%</td>
</tr>
<tr>
<td>Click</td>
<td><strong>0.392 / 0.156</strong></td>
<td>+1.2% / +1.2%</td>
<td>+1.2% / +1.2%</td>
</tr>
<tr>
<td>Epsilon</td>
<td><strong>0.265 / 0.109</strong></td>
<td>+1.5% / +4.1%</td>
<td>+11% / +12%</td>
</tr>
<tr>
<td>Appetency</td>
<td><strong>0.072 / 0.018</strong></td>
<td>+0.4% / +0.2%</td>
<td>+0.4% / +0.7%</td>
</tr>
<tr>
<td>Churn</td>
<td><strong>0.232 / 0.072</strong></td>
<td>+0.1% / +0.6%</td>
<td>+0.5% / +1.6%</td>
</tr>
<tr>
<td>Internet</td>
<td><strong>0.209 / 0.094</strong></td>
<td>+6.8% / +8.6%</td>
<td>+7.9% / +8.0%</td>
</tr>
<tr>
<td>Upselling</td>
<td><strong>0.166 / 0.049</strong></td>
<td>+0.3% / +0.1%</td>
<td>+0.04% / +0.3%</td>
</tr>
<tr>
<td>Kick</td>
<td><strong>0.286 / 0.095</strong></td>
<td>+3.5% / +4.4%</td>
<td>+3.2% / +4.1%</td>
</tr>
</tbody>
</table>
<p>I valori nelle colonne LightGBM e XGBoost rappresentano l&rsquo;aumento percentuale relativo rispetto a CatBoost.</p>
<p><strong>Miglioramenti particolarmente significativi</strong>:
- Amazon: +17% rispetto ai baseline
- Internet: +6.8%-7.9% rispetto ai baseline
- Epsilon: +11% rispetto a XGBoost</p>
<h3 id="confronto-tra-modalita-ordered-e-plain">Confronto tra Modalit√† Ordered e Plain</h3>
<h4 id="risultati-generali">Risultati Generali</h4>
<p>La modalit√† Ordered √® particolarmente utile su <strong>dataset piccoli</strong>.</p>
<p>Il beneficio maggiore dall&rsquo;Ordered si osserva su:
- <strong>Adult</strong>: 40K esempi di training
- <strong>Internet</strong>: &lt; 40K esempi di training</p>
<h4 id="risultati-dettagliati-plain-vs-ordered">Risultati Dettagliati (Plain vs Ordered)</h4>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Plain Logloss</th>
<th>Plain Zero-one</th>
<th>Variazione</th>
</tr>
</thead>
<tbody>
<tr>
<td>Adult</td>
<td>0.272</td>
<td>0.127</td>
<td>+1.1% / -0.1%</td>
</tr>
<tr>
<td>Amazon</td>
<td>0.139</td>
<td>0.044</td>
<td>-0.6% / -1.5%</td>
</tr>
<tr>
<td>Click</td>
<td>0.392</td>
<td>0.156</td>
<td>-0.05% / +0.19%</td>
</tr>
<tr>
<td>Epsilon</td>
<td>0.266</td>
<td>0.110</td>
<td>+0.6% / +0.9%</td>
</tr>
<tr>
<td>Appetency</td>
<td>0.072</td>
<td>0.018</td>
<td>+0.5% / +1.5%</td>
</tr>
<tr>
<td>Churn</td>
<td>0.232</td>
<td>0.072</td>
<td>-0.06% / -0.17%</td>
</tr>
<tr>
<td>Internet</td>
<td>0.217</td>
<td>0.099</td>
<td>+3.9% / +5.4%</td>
</tr>
<tr>
<td>Upselling</td>
<td>0.166</td>
<td>0.049</td>
<td>+0.1% / +0.4%</td>
</tr>
<tr>
<td>Kick</td>
<td>0.285</td>
<td>0.095</td>
<td>-0.2% / -0.1%</td>
</tr>
</tbody>
</table>
<h4 id="esperimento-con-dataset-filtrati">Esperimento con Dataset Filtrati</h4>
<p>Per validare l&rsquo;ipotesi che il bias sia pi√π grande per dataset pi√π piccoli:
- Si addestra CatBoost in modalit√† Ordered e Plain su dataset filtrati casualmente
- Si confrontano le loss ottenute</p>
<p><strong>Risultato</strong>: Per dataset pi√π piccoli, la performance relativa della modalit√† Plain peggiora, confermando l&rsquo;ipotesi che il bias (secondo il Teorema 1) sia pi√π grande per dataset pi√π piccoli.</p>
<h3 id="analisi-delle-target-statistics">Analisi delle Target Statistics</h3>
<p>Confronto di diverse TS introdotte nella sezione corrispondente, tutte implementate come opzioni di CatBoost in modalit√† Ordered:</p>
<h4 id="risultati-variazione-relativa-rispetto-a-ordered-ts">Risultati (Variazione relativa rispetto a Ordered TS)</h4>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Greedy</th>
<th>Holdout</th>
<th>Leave-one-out</th>
</tr>
</thead>
<tbody>
<tr>
<td>Adult</td>
<td>+1.1% / +0.8%</td>
<td>+2.1% / +2.0%</td>
<td>+5.5% / +3.7%</td>
</tr>
<tr>
<td>Amazon</td>
<td>+40% / +32%</td>
<td>+8.3% / +8.3%</td>
<td>+4.5% / +5.6%</td>
</tr>
<tr>
<td>Click</td>
<td>+13% / +6.7%</td>
<td>+1.5% / +0.5%</td>
<td>+2.7% / +0.9%</td>
</tr>
<tr>
<td>Appetency</td>
<td>+24% / +0.7%</td>
<td>+1.6% / -0.5%</td>
<td>+8.5% / +0.7%</td>
</tr>
<tr>
<td>Churn</td>
<td>+12% / +2.1%</td>
<td>+0.9% / +1.3%</td>
<td>+1.6% / +1.8%</td>
</tr>
<tr>
<td>Internet</td>
<td>+33% / +22%</td>
<td>+2.6% / +1.8%</td>
<td>+27% / +19%</td>
</tr>
<tr>
<td>Upselling</td>
<td>+57% / +50%</td>
<td>+1.6% / +0.9%</td>
<td>+3.9% / +2.9%</td>
</tr>
<tr>
<td>Kick</td>
<td>+22% / +28%</td>
<td>+1.3% / +0.32%</td>
<td>+3.7% / +3.3%</td>
</tr>
</tbody>
</table>
<p><strong>Osservazioni</strong>:</p>
<ol>
<li><strong>Ordered TS</strong> superano significativamente tutti gli altri approcci</li>
<li><strong>Holdout TS</strong> √® il migliore tra i baseline per la maggior parte dei dataset (non soffre di conditional shift - P1), ma √® peggiore di ordered TS (meno uso efficace dei dati - P2)</li>
<li><strong>Leave-one-out</strong> √® solitamente migliore di greedy TS, ma pu√≤ essere molto peggiore su alcuni dataset (es. Adult)</li>
<li><strong>Greedy TS</strong> soffre sia delle categorie a bassa frequenza che di quelle ad alta frequenza</li>
</ol>
<h3 id="combinazioni-di-feature_1">Combinazioni di Feature</h3>
<p>Cambiare il numero $c_{max}$ di feature consentite per le combinazioni:
- Da 1 a 2: <strong>miglioramento medio di 1.86%</strong> (fino a 11.3%)
- Da 1 a 3: <strong>miglioramento di 2.04%</strong>
- Ulteriore aumento di $c_{max}$: non influenza significativamente la performance</p>
<h3 id="numero-di-permutazioni">Numero di Permutazioni</h3>
<p>Effetto del numero $s$ di permutazioni sulla performance:
- $s = 3$: diminuzione media di logloss di <strong>0.19%</strong> rispetto a $s = 1$
- $s = 9$: diminuzione media di logloss di <strong>0.38%</strong> rispetto a $s = 1$</p>
<p><strong>Conclusione</strong>: Aumentare $s$ diminuisce leggermente la logloss, ma i guadagni diminuiscono.</p>
<h3 id="tempi-di-esecuzione">Tempi di Esecuzione</h3>
<p>Confronto dei tempi su dataset Epsilon:</p>
<table>
<thead>
<tr>
<th>Algoritmo</th>
<th>Tempo per albero</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CatBoost Plain</strong></td>
<td><strong>1.1 s</strong></td>
</tr>
<tr>
<td>CatBoost Ordered</td>
<td>1.9 s</td>
</tr>
<tr>
<td>XGBoost</td>
<td>3.9 s</td>
</tr>
<tr>
<td><strong>LightGBM</strong></td>
<td><strong>1.1 s</strong></td>
</tr>
</tbody>
</table>
<p><strong>Osservazioni</strong>:
- CatBoost Plain e LightGBM sono i pi√π veloci
- Ordered mode √® circa <strong>1.7 volte pi√π lento</strong> (come atteso)
- CatBoost ha anche un&rsquo;implementazione GPU altamente efficiente (dettagli su GitHub)</p>
<hr />
<h2 id="conclusioni">Conclusioni</h2>
<h3 id="contributi-principali">Contributi Principali</h3>
<ol>
<li>
<p><strong>Identificazione e analisi del problema di prediction shift</strong> presente in tutte le implementazioni esistenti di gradient boosting</p>
</li>
<li>
<p><strong>Proposta di una soluzione generale</strong>: ordered boosting con ordered TS</p>
</li>
<li>
<p><strong>Implementazione pratica</strong>: CatBoost, una nuova libreria di gradient boosting</p>
</li>
<li>
<p><strong>Risultati empirici</strong>: CatBoost supera i principali pacchetti GBDT e porta a nuovi risultati state-of-the-art su benchmark comuni</p>
</li>
</ol>
<h3 id="innovazioni-algoritmiche">Innovazioni Algoritmiche</h3>
<h4 id="ordered-target-statistics">Ordered Target Statistics</h4>
<ul>
<li>Evitano il conditional shift (propriet√† P1)</li>
<li>Usano efficientemente tutti i dati di training (propriet√† P2)</li>
<li>Basate sul principio di ordinamento (permutazioni casuali)</li>
<li>Superiori a greedy TS, holdout TS, e leave-one-out TS</li>
</ul>
<h4 id="ordered-boosting_1">Ordered Boosting</h4>
<ul>
<li>Elimina il prediction shift causato da target leakage</li>
<li>Mantiene modelli di supporto multipli</li>
<li>Usa permutazioni casuali per simulare un &ldquo;tempo artificiale&rdquo;</li>
<li>Implementazione efficiente con complessit√† $O(s \cdot n)$ invece di $O(n^2)$</li>
</ul>
<h4 id="gestione-delle-feature-categoriche">Gestione delle Feature Categoriche</h4>
<ul>
<li>Conversione diretta a target statistics numeriche</li>
<li>Combinazioni di feature per catturare interazioni di ordine superiore</li>
<li>Efficiente per feature ad alta cardinalit√†</li>
</ul>
<h3 id="vantaggi-pratici">Vantaggi Pratici</h3>
<ol>
<li><strong>Performance superiore</strong>: Miglioramenti significativi su tutti i dataset testati</li>
<li><strong>Robustezza</strong>: Particolarmente efficace su dataset piccoli</li>
<li><strong>Efficienza</strong>: Complessit√† computazionale comparabile ai metodi standard</li>
<li><strong>Flessibilit√†</strong>: Due modalit√† (Plain e Ordered) per diversi scenari</li>
<li><strong>Gestione nativa delle categoriche</strong>: Nessun preprocessing manuale necessario</li>
</ol>
<h3 id="aspetti-teorici-rilevanti">Aspetti Teorici Rilevanti</h3>
<p>Il paper fornisce:
- <strong>Analisi formale</strong> del prediction shift (Teorema 1)
- <strong>Dimostrazione matematica</strong> del bias introdotto dal riutilizzo dei dati
- <strong>Garanzie teoriche</strong> che ordered boosting elimina questo bias
- <strong>Spiegazione</strong> del perch√© permutazioni identiche $\sigma_{cat} = \sigma_{boost}$ sono necessarie</p>
<h3 id="limitazioni-e-considerazioni">Limitazioni e Considerazioni</h3>
<ol>
<li><strong>Ordered mode</strong>: Circa 1.7 volte pi√π lento di Plain mode</li>
<li><strong>Permutazioni multiple</strong>: Richiedono pi√π memoria ma riducono la varianza</li>
<li><strong>Trade-off</strong>: Bilanciamento tra accuratezza e velocit√†</li>
</ol>
<h3 id="impatto">Impatto</h3>
<p>CatBoost rappresenta un avanzamento significativo nel gradient boosting:
- Risolve problemi teorici fondamentali precedentemente non riconosciuti
- Fornisce risultati empirici superiori
- √à open-source e ampiamente utilizzato nella pratica</p>
<p>L&rsquo;identificazione e risoluzione del prediction shift √® un contributo importante per la comunit√† di machine learning, con implicazioni che vanno oltre CatBoost stesso.</p>
<hr />
<h2 id="riferimenti-e-approfondimenti">Riferimenti e Approfondimenti</h2>
<h3 id="concetti-chiave-da-ricordare">Concetti Chiave da Ricordare</h3>
<ol>
<li><strong>Target Leakage</strong>: Quando informazioni sul target &ldquo;fuoriescono&rdquo; nel processo di training, causando overfitting</li>
<li><strong>Conditional Shift</strong>: Quando $P(X|Y)$ differisce tra training e test</li>
<li><strong>Prediction Shift</strong>: Quando $P(F(\mathbf{x})|\mathbf{x})$ differisce tra training e test</li>
<li><strong>Ordering Principle</strong>: Usare permutazioni casuali per simulare un ordine temporale</li>
<li><strong>Oblivious Trees</strong>: Alberi che usano lo stesso split criterion su ogni livello</li>
</ol>
<h3 id="perche-catboost-funziona">Perch√© CatBoost Funziona</h3>
<p>La combinazione di:
- Ordered boosting (elimina prediction shift)
- Ordered target statistics (elimina conditional shift)
- Feature combinations (cattura interazioni complesse)
- Oblivious trees (riduce overfitting, accelera inferenza)
- Permutazioni multiple (riduce varianza)</p>
<p>porta a un algoritmo che √® sia teoricamente fondato che empiricamente superiore.</p>
<h3 id="applicazioni-pratiche">Applicazioni Pratiche</h3>
<p>CatBoost √® particolarmente adatto per:
- <strong>Click prediction</strong>: Feature categoriche come user ID, region, ad
- <strong>Recommendation systems</strong>: User-item interactions
- <strong>Fraud detection</strong>: Transazioni con molte feature categoriche
- <strong>Ranking problems</strong>: Web search, e-commerce
- <strong>Qualsiasi problema con feature categoriche ad alta cardinalit√†</strong></p>
            </div>
            
            <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #eee;">
                <p><strong>Keywords:</strong> supervised learning, labeled data, classification, regression, model, data, training, learning</p>
                <p><small>This is the SEO-optimized version. <a href="http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost">Click here for the interactive experience</a>.</small></p>
            </footer>
        </article>
    </div>
    
    <!-- Vercel Analytics (opzionale) -->
    <script>
      // Track SEO page views
      if (window.gtag) {
        gtag('config', 'GA_TRACKING_ID', {
          page_title: 'CatBoost: Unbiased Boosting with Categorical Features',
          page_location: 'http://localhost:3000/theory/supervised-learning/Non-Linear Models/CatBoost'
        });
      }
    </script>
</body>
</html>