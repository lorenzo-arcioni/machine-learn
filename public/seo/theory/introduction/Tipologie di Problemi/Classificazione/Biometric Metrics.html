<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Metriche Biometriche per Classificazione in Machine Learning | Introduction to Machine Learning | ML Theory</title>
    <meta name="description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    <meta name="keywords" content="machine learning, introduction, basics, fundamentals, AI, algorithm, model, data">
    <meta name="robots" content="index, follow">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Metriche Biometriche per Classificazione in Machine Learning">
    <meta property="og:description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    <meta property="og:url" content="http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics">
    <meta property="og:type" content="article">
    <meta property="og:site_name" content="Machine Learning Theory">
    
    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Metriche Biometriche per Classificazione in Machine Learning">
    <meta name="twitter:description" content="pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics">
    
    <!-- Preload critical resources -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    
    <!-- JSON-LD Structured Data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Metriche Biometriche per Classificazione in Machine Learning",
      "description": "pre { line-height: 125%; } td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; } span.linenos {...",
      "url": "http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics",
      "datePublished": "2026-01-15T00:29:00.202Z",
      "author": {
        "@type": "Organization",
        "name": "ML Theory Platform"
      },
      "publisher": {
        "@type": "Organization",
        "name": "ML Theory Platform"
      }
    }
    </script>
    
    <!-- Critical CSS -->
    <style>
      body { 
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
        line-height: 1.6; 
        margin: 0; 
        padding: 20px;
        background: #fafafa;
      }
      .container { 
        max-width: 800px; 
        margin: 0 auto; 
        background: white;
        padding: 40px;
        border-radius: 8px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      }
      h1 { 
        color: #1a1a1a; 
        margin-bottom: 20px; 
        font-size: 2.5rem;
        line-height: 1.2;
      }
      .meta { 
        color: #666; 
        margin-bottom: 30px; 
        padding-bottom: 20px;
        border-bottom: 1px solid #eee;
      }
      .content h2, .content h3 { 
        color: #2c3e50; 
        margin-top: 40px; 
        margin-bottom: 16px;
      }
      .content p { 
        margin-bottom: 16px; 
        color: #333;
      }
      .content code { 
        background: #f8f9fa; 
        padding: 2px 6px; 
        border-radius: 4px; 
        font-size: 0.9em;
        color: #e83e8c;
      }
      .content pre { 
        background: #f8f9fa; 
        padding: 20px; 
        border-radius: 8px; 
        overflow-x: auto;
        border: 1px solid #e9ecef;
      }
      .react-redirect {
        position: fixed;
        top: 20px;
        right: 20px;
        background: #007acc;
        color: white;
        padding: 10px 20px;
        border-radius: 6px;
        text-decoration: none;
        font-weight: 500;
        box-shadow: 0 2px 8px rgba(0,122,204,0.3);
        transition: transform 0.2s;
      }
      .react-redirect:hover {
        transform: translateY(-1px);
      }
      @media (max-width: 768px) { 
        body { padding: 10px; }
        .container { padding: 20px; }
        h1 { font-size: 2rem; }
        .react-redirect { position: static; display: block; text-align: center; margin-bottom: 20px; }
      }
    </style>
</head>
<body>
    <!-- Link per versione interattiva -->
    <a href="http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics" class="react-redirect">üöÄ View Interactive Version</a>
    
    <div class="container">
        <article>
            <header>
                <h1>Metriche Biometriche per Classificazione in Machine Learning</h1>
                <div class="meta">
                    <strong>Topic:</strong> Introduction to Machine Learning | 
                    <strong>Updated:</strong> 15/01/2026
                </div>
            </header>
            
            <div class="content">
                <style>pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #F00 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #04D } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */
.codehilite .no { color: #800 } /* Name.Constant */
.codehilite .nd { color: #A2F } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #00F } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #BBB } /* Text.Whitespace */
.codehilite .mb { color: #666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666 } /* Literal.Number.Float */
.codehilite .mh { color: #666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #00F } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */

/* Styling per blocchi di codice */
.codehilite {
    background: transparent !important;
    border-radius: 8px;
    overflow: hidden;
}
.codehilite pre {
    background: transparent !important;
    margin: 0 !important;
    padding: 20px !important;
    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;
    font-size: 14px !important;
    line-height: 1.5 !important;
    white-space: pre !important;
    overflow-x: auto !important;
    color: inherit !important;
}
.codehilite code {
    background: transparent !important;
    padding: 0 !important;
    font-family: inherit !important;
}


.code-wrapper { 
    position: relative; 
}
.copy-button {
    position: absolute; 
    top: 12px; 
    right: 12px; 
    padding: 6px 12px; 
    font-size: 12px;
    cursor: pointer; 
    border: none; 
    border-radius: 4px; 
    background: rgba(255,255,255,0.9);
    color: #374151; 
    transition: all 0.2s ease;
    font-weight: 500;
}
.copy-button:hover { 
    background: rgba(255,255,255,1);
    transform: translateY(-1px);
}


details.code-container {
    border: 1px solid #e5e7eb; 
    border-radius: 12px; 
    background: #f9fafb;
    margin: 16px 0;
    transition: all 0.3s ease;
}
details.code-container summary {
    padding: 12px 16px;
    font-size: 14px; 
    color: #6b7280; 
    cursor: pointer; 
    outline: none; 
    user-select: none;
    font-weight: 500;
}
details.code-container[open] summary::after { 
    content: " (Hide Code)"; 
    color: #9ca3af; 
}
details.code-container:not([open]) summary::after { 
    content: " (Show Code)"; 
    color: #d1d5db; 
}
details.code-container .code-wrapper {
    padding: 0;
    margin: 0;
}
/* Blocchi di codice sempre visibili */
.code-visible {
    border: 1px solid #e5e7eb;
    border-radius: 12px;
    background: #f9fafb;
    margin: 16px 0;
}
.code-visible .code-wrapper {
    padding: 0;
    margin: 0;
}
</style>
<h2 id="indice">Indice</h2>
<ol>
<li><a href="#1-introduzione-e-fondamenti">Introduzione e Fondamenti</a></li>
<li><a href="#2-verifica-biometrica">Verifica Biometrica</a></li>
<li><a href="#3-identificazione-open-set">Identificazione Open-Set</a></li>
<li><a href="#4-identificazione-closed-set">Identificazione Closed-Set</a></li>
<li><a href="#5-metodologie-di-valutazione-offline">Metodologie di Valutazione Offline</a></li>
<li><a href="#6-confronto-metriche-biometriche-vs-machine-learning">Confronto: Metriche Biometriche vs Machine Learning</a></li>
<li><a href="#7-affidabilit√†-e-qualit√†">Affidabilit√† e Qualit√†</a></li>
</ol>
<h2 id="1-introduzione-e-fondamenti">1. Introduzione e Fondamenti</h2>
<h3 id="11-contesto-dei-sistemi-biometrici">1.1 Contesto dei Sistemi Biometrici</h3>
<p>I sistemi biometrici operano in condizioni di <strong>incertezza intrinseca</strong>, una caratteristica che li distingue profondamente dai sistemi di autenticazione tradizionali basati su password o token. Mentre una password √® sempre identica e il suo confronto √® deterministico (corretta o errata), un campione biometrico dello stesso individuo non √® mai esattamente uguale al precedente. Questa √® la sfida fondamentale della biometria: nessun sistema √® perfetto perch√© la flessibilit√† necessaria per riconoscere lo stesso individuo in condizioni diverse introduce inevitabilmente errori.</p>
<h4 id="requisiti-di-una-caratteristica-biometrica">Requisiti di una caratteristica biometrica</h4>
<p>Affinch√© una caratteristica possa essere utilizzata efficacemente come <strong>tratto biometrico</strong>, deve soddisfare una serie di requisiti fondamentali. Questi criteri permettono di valutare l‚Äôaffidabilit√†, la robustezza e l‚Äôaccettabilit√† di un sistema biometrico nel mondo reale.</p>
<ul>
<li>
<p><strong>Universalit√†</strong>
Il tratto biometrico dovrebbe essere posseduto da ogni individuo. In altre parole, quasi tutte le persone devono poter essere identificate tramite quella caratteristica, fatta eccezione per rari casi particolari (ad esempio disabilit√† o condizioni mediche specifiche).</p>
</li>
<li>
<p><strong>Unicit√†</strong>
Il tratto biometrico deve essere sufficientemente diverso da persona a persona. Idealmente, ogni individuo dovrebbe poter essere distinto da qualsiasi altro sulla base di quella caratteristica, riducendo al minimo il rischio di ambiguit√† o collisioni.</p>
</li>
</ul>
<p><em>Nota: una assunzione base dei sistemi biometrici √® che ogni persona √® unica.</em></p>
<ul>
<li>
<p><strong>Permanenza</strong>
Una buona caratteristica biometrica non dovrebbe variare significativamente nel tempo. Anche se piccoli cambiamenti sono inevitabili, il tratto deve rimanere stabile abbastanza a lungo da garantire un‚Äôidentificazione affidabile nel corso degli anni.</p>
</li>
<li>
<p><strong>Collezionabilit√† (Collectability)</strong>
Il tratto biometrico deve poter essere misurato o acquisito tramite sensori appropriati (ad esempio fotocamere, scanner o microfoni). Inoltre, la misurazione dovrebbe essere sufficientemente accurata e ripetibile.</p>
</li>
<li>
<p><strong>Accettabilit√†</strong>
Le persone coinvolte non dovrebbero avere obiezioni rilevanti alla raccolta del tratto biometrico. Questo aspetto √® strettamente legato a considerazioni etiche, culturali e di privacy, ed √® cruciale per l‚Äôadozione su larga scala dei sistemi biometrici.</p>
</li>
</ul>
<h4 id="fonti-di-incertezza">Fonti di Incertezza</h4>
<ol>
<li><strong>Variazioni intra-classe</strong>: Lo stesso individuo produce campioni mai identici</li>
</ol>
<p>Immaginiamo di acquisire il volto della stessa persona in momenti diversi. Le variazioni possono essere numerose: la persona potrebbe sorridere in una foto ed essere seria nell&rsquo;altra, indossare occhiali o averli rimossi, trovarsi sotto luce naturale o artificiale. Anche fattori sottili come la stanchezza, il trucco, o semplicemente l&rsquo;angolazione della testa possono alterare significativamente l&rsquo;aspetto del campione acquisito. Queste <strong>variazioni intra-classe</strong> (cio√® variazioni all&rsquo;interno della stessa classe/identit√†) rappresentano una sfida perch√© il sistema deve essere abbastanza &ldquo;tollerante&rdquo; da riconoscere che si tratta della stessa persona nonostante le differenze.</p>
<ul>
<li>Posa, espressione, illuminazione variabili</li>
<li>Qualit√† di acquisizione diversa (sensore sporco, bassa risoluzione)</li>
<li>
<p>Cambiamenti temporali (invecchiamento, barba, accessori, chirurgia, etc.)</p>
</li>
<li>
<p><strong>Similarit√† inter-classe</strong>: Individui diversi possono apparire simili</p>
</li>
</ul>
<p>D&rsquo;altra parte, esistono persone che naturalmente si assomigliano. I gemelli omozigoti sono l&rsquo;esempio estremo, ma anche fratelli, genitori e figli, o semplicemente persone con caratteristiche facciali comuni possono generare campioni biometrici molto simili. Queste <strong>similarit√† inter-classe</strong> (cio√® somiglianze tra classi/identit√† diverse) sono problematiche perch√© il sistema deve essere abbastanza &ldquo;selettivo&rdquo; da distinguere persone diverse nonostante le somiglianze.</p>
<ul>
<li>Somiglianze familiari (gemelli, fratelli)</li>
<li>Caratteristiche comuni nella popolazione</li>
<li>
<p>Condizioni di acquisizione che &ldquo;uniformano&rdquo; i soggetti</p>
</li>
<li>
<p><strong>Non-universalit√†</strong>: Non tutti gli individui possono essere riconosciuti</p>
</li>
</ul>
<p>Un&rsquo;assunzione fondamentale dei sistemi biometrici √® che ogni persona possieda la caratteristica biometrica da rilevare. Tuttavia, questo non √® sempre vero: alcune persone hanno impronte digitali usurate o danneggiate da lavori manuali, altre hanno difficolt√† con il riconoscimento dell&rsquo;iride a causa di particolari condizioni oculari. Questa <strong>non-universalit√†</strong> significa che una percentuale della popolazione potrebbe non essere riconoscibile dal sistema, indipendentemente dalla qualit√† dell&rsquo;algoritmo.</p>
<ul>
<li>Impronte digitali usurate o danneggiate</li>
<li>Caratteristiche biometriche ambigue o assenti</li>
<li>Impossibilit√† fisica di acquisire il tratto (es. persone senza mani per fingerprint)</li>
</ul>
<h3 id="12-architettura-di-sistema">1.2 Architettura di Sistema</h3>
<p>Un sistema biometrico √® composto da diversi moduli che lavorano in sequenza per trasformare un tratto fisico o comportamentale in una decisione di autenticazione. Comprendere questa architettura √® fondamentale per identificare i punti critici dove possono verificarsi errori o attacchi.</p>
<div class="code-visible">
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>Acquisizione ‚Üí Estrazione Feature ‚Üí Matching ‚Üí Decisione
     ‚Üì              ‚Üì                  ‚Üì           ‚Üì
  Sensore      Template DB         Matcher    Threshold
</code></pre></div>
</div>
</div>

<p>Il processo inizia con l&rsquo;<strong>acquisizione</strong> tramite un sensore specifico (telecamera per il volto, scanner per impronte, microfono per la voce). Questo passaggio √® critico: un&rsquo;acquisizione di bassa qualit√† compromette irrimediabilmente le fasi successive. Successivamente, il modulo di <strong>estrazione feature</strong> analizza il campione grezzo e ne estrae le caratteristiche distintive, memorizzate come template biometrico. Il <strong>matcher</strong> confronta poi il template del probe (campione da verificare) con i template memorizzati nel database, producendo uno score di similarit√† o distanza. Infine, la <strong>decisione</strong> viene presa confrontando questo score con una soglia predefinita.</p>
<p><em>Nota: Il </em><em>sample</em><em> √® il dato grezzo acquisito dal sensore. Le </em><em>features</em><em> sono le caratteristiche estratte dai dati grezzi. Il </em><em>template</em><em> √® l&rsquo;insieme delle features estratte dai dati grezzi.</em></p>
<h4 id="tipologie-di-utenti">Tipologie di Utenti</h4>
<p>Il comportamento dell‚Äôutente influenza in modo significativo il funzionamento e la sicurezza del sistema biometrico. √à possibile distinguere diverse categorie:</p>
<ul>
<li><strong>Utenti cooperativi</strong>: l‚Äôutente √® interessato a essere riconosciuto correttamente (es. autenticazione volontaria). Un impostore in questo caso tenta di farsi riconoscere come un utente legittimo.</li>
<li><strong>Utenti non cooperativi</strong>: l‚Äôutente √® indifferente o ostile al riconoscimento (es. sorveglianza). Un impostore pu√≤ tentare di evitare deliberatamente il riconoscimento.</li>
<li><strong>Utenti pubblici / privati</strong>:</li>
<li><em>Pubblici</em>: clienti o utenti esterni (es. controllo accessi in aeroporti).</li>
<li><em>Privati</em>: dipendenti o membri interni di un‚Äôorganizzazione.</li>
<li><strong>Utenti frequenti / occasionali</strong>:</li>
<li><em>Used</em>: utilizzano il sistema frequentemente, con template aggiornati e stabili.</li>
<li><em>Non-used</em>: interagiscono raramente con il sistema, aumentando la probabilit√† di mismatch.</li>
<li><strong>Utenti consapevoli / inconsapevoli</strong>:</li>
<li><em>Aware</em>: sanno di essere sottoposti a riconoscimento biometrico.</li>
<li><em>Not aware</em>: il riconoscimento avviene in modo trasparente o passivo.</li>
</ul>
<p>Queste differenze influenzano la qualit√† dell‚Äôacquisizione, la variabilit√† intra-classe e la robustezza richiesta al sistema.</p>
<h4 id="tipologie-di-setting-di-acquisizione">Tipologie di Setting di Acquisizione</h4>
<p>Le condizioni operative del sistema hanno un impatto diretto sulle prestazioni biometriche:</p>
<ul>
<li><strong>Setting controllati</strong>:</li>
<li>condizioni ambientali controllate (illuminazione, posa, distanza)</li>
<li>distorsioni ridotte</li>
<li>possibilit√† di scartare template difettosi</li>
<li>acquisizione ripetibile</li>
<li><strong>Setting non controllati o sotto-controllati</strong>:</li>
<li>condizioni ambientali variabili</li>
<li>presenza di rumore, occlusioni, blur</li>
<li>template con diversi livelli di distorsione</li>
<li>possibilit√† di scartare template difettosi, ma <strong>senza possibilit√† di ripetere la cattura</strong></li>
</ul>
<p>I sistemi operanti in setting non controllati devono essere pi√π robusti e tolleranti alla variabilit√†.</p>
<p><strong>Vulnerabilit√† agli attacchi (spoofing)</strong>:</p>
<p>I sistemi biometrici possono essere attaccati a diversi livelli:</p>
<ul>
<li>
<p><strong>Livello sensore</strong>: Presentazione di tratti falsi (impronte artificiali in gelatina, maschere 3D, foto stampate). Questo √® l&rsquo;attacco pi√π comune e intuitivo, dove un malintenzionato cerca di &ldquo;ingannare&rdquo; il sensore presentando una replica del tratto biometrico legittimo.</p>
</li>
<li>
<p><strong>Canale di comunicazione</strong>: Intercettazione e replay di campioni. Se il sensore √® separato dall&rsquo;unit√† di elaborazione, un attaccante potrebbe intercettare i dati trasmessi e riprodurli successivamente per accedere al sistema senza presentarsi fisicamente.</p>
</li>
<li>
<p><strong>Matcher</strong>: Manipolazione degli score di similarit√†. Un attaccante con accesso al software potrebbe modificare il modulo di matching per forzare uno score alto anche quando la somiglianza √® bassa.</p>
</li>
<li>
<p><strong>Database template</strong>: Modifica o iniezione di template. Compromettere il database consente di sostituire template legittimi o inserirne di fraudolenti, ottenendo cos√¨ accesso permanente al sistema.</p>
</li>
</ul>
<h4 id="enrollment">Enrollment</h4>
<p>Acquisizione ed elaborazione dei dati biometrici dell&rsquo;utente per l&rsquo;utilizzo da parte del sistema nelle successive operazioni di autenticazione (gallery).</p>
<h4 id="recognition">Recognition</h4>
<p>Acquisizione ed elaborazione dei dati biometrici dell&rsquo;utente al fine di fornire una decisione di autenticazione basata sul risultato di un processo di abbinamento tra il modello memorizzato e quello corrente. (verifica 1:1, identificazione 1:N)</p>
<h4 id="modalita-tradizionali-di-riconoscimento-e-autenticazione">Modalit√† Tradizionali di Riconoscimento e Autenticazione</h4>
<p>Attualmente, il riconoscimento (spesso finalizzato all‚Äôautenticazione) viene effettuato secondo due principali modalit√†:</p>
<ul>
<li>
<p><strong>Qualcosa che si possiede</strong>: una carta, un badge o un documento.<br />
  Tuttavia, questi oggetti possono essere <strong>persi, rubati o copiati</strong>. In realt√†, il sistema non autentica la persona, ma <strong>l‚Äôoggetto</strong> in suo possesso.</p>
</li>
<li>
<p><strong>Qualcosa che si conosce</strong>: una password personale o condivisa.<br />
  Anche in questo caso esistono diverse criticit√†: la password pu√≤ essere <strong>indovinata, carpita o dimenticata</strong>. Inoltre, una password facile da ricordare √® spesso anche <strong>facile da indovinare</strong>.</p>
</li>
<li>
<p><strong>Basato su ci√≤ che si √®</strong>: caratteristiche <strong>biometriche</strong> dell‚Äôindividuo, come tratti fisici (impronte digitali, volto, iride) o comportamentali (voce, dinamica di digitazione, andatura).<br />
  In questo caso, l‚Äôautenticazione √® legata direttamente all‚Äôidentit√† della persona, riducendo la dipendenza da oggetti o informazioni memorizzate.</p>
</li>
</ul>
<h3 id="13-modalita-operative">1.3 Modalit√† Operative</h3>
<p>I sistemi biometrici operano principalmente in tre modalit√†, ciascuna con caratteristiche e metriche di valutazione specifiche:</p>
<p><strong>Verifica (1:1)</strong>:
- L&rsquo;utente dichiara un&rsquo;identit√† $i$ (claim)
- Sistema confronta: probe vs template dell&rsquo;identit√† dichiarata
- Decisione binaria: accetta/rifiuta
- Esempio pratico: Sblocco smartphone con Face ID - l&rsquo;utente dichiara implicitamente di essere il proprietario del dispositivo</p>
<p><strong>Identificazione Open-Set (1:N con reject option)</strong>:
- Nessuna identit√† dichiarata
- Sistema confronta: probe vs tutti i template in galleria
- Decisioni: (1) il soggetto √®/non √® in galleria, (2) se s√¨, quale identit√†
- Esempio pratico: Sorveglianza in aeroporto - il sistema cerca di identificare se una persona √® presente in una watchlist</p>
<p><strong>Watch list</strong>:
  - Il sistema possiede una lista di soggetti di interesse
  - Verifica se il <em>probe</em> appartiene alla lista</p>
<p>Tipologie di watch list:
  - <strong>White list</strong>: i soggetti presenti nella lista sono <strong>autorizzati</strong> e l‚Äôaccesso viene consentito
  - <strong>Black list</strong>: i soggetti presenti nella lista sono <strong>non autorizzati</strong>; il riconoscimento pu√≤ generare un <strong>allarme</strong></p>
<p><strong>Identificazione Closed-Set (1:N forzata)</strong>:
- Assunzione: il probe appartiene sicuramente alla galleria
- Sistema restituisce sempre un&rsquo;identit√†
- Errore solo se l&rsquo;identit√† corretta non √® al primo posto
- Esempio pratico: Gara sportiva dove tutti i partecipanti sono pre-registrati</p>
<p>La distinzione tra queste modalit√† √® cruciale perch√© determina quali errori sono possibili e come vengono misurate le performance del sistema.</p>
<h3 id="14-tipologie-di-caratteristiche-biometriche">1.4 Tipologie di Caratteristiche Biometriche</h3>
<p>I sistemi biometrici si basano sull‚Äôanalisi di <strong>caratteristiche distintive</strong> degli individui, che possono essere classificate ad <strong>alto livello</strong> in base alla loro natura e stabilit√† nel tempo. In generale, le caratteristiche biometriche si suddividono in <strong>fisiologiche</strong>, <strong>comportamentali</strong> e <strong>miste</strong>, a cui si affiancano le <strong>tracce biologiche</strong>.</p>
<h4 id="caratteristiche-fisiologiche-physiological-features">Caratteristiche Fisiologiche (Physiological Features)</h4>
<p>Sono legate alla struttura fisica dell‚Äôindividuo e tendono a essere <strong>stabili nel tempo</strong>.</p>
<ul>
<li><strong>Biometria delle impronte digitali</strong> (<em>Fingerprints biometrics</em>): riconoscimento basato sui pattern delle creste papillari.</li>
<li><strong>Biometria oculare</strong> (<em>Eye biometrics</em>):</li>
<li>riconoscimento dell‚Äô<strong>iride</strong></li>
<li>riconoscimento della <strong>retina</strong></li>
<li><strong>Biometria facciale</strong> (<em>Face biometrics</em>): riconoscimento del volto tramite immagini nel visibile o all‚Äôinfrarosso.</li>
<li><strong>Biometria dell‚Äôorecchio</strong> (<em>Ear biometrics</em>): riconoscimento basato sulla forma e struttura dell‚Äôorecchio.</li>
<li><strong>Biometria della mano</strong> (<em>Hand biometrics</em>): riconoscimento tramite la geometria delle dita e della mano.</li>
</ul>
<h4 id="caratteristiche-comportamentali-behavioural-features">Caratteristiche Comportamentali (Behavioural Features)</h4>
<p>Descrivono il <strong>comportamento</strong> dell‚Äôindividuo piuttosto che la sua struttura fisica e sono generalmente pi√π <strong>variabili</strong>.</p>
<ul>
<li><strong>Biometria della firma</strong> (<em>Signature biometrics</em>):  </li>
<li>firma statica  </li>
<li>firma dinamica (velocit√†, pressione, traiettoria)</li>
<li><strong>Dinamica di digitazione</strong> (<em>Keystroke dynamics</em>): pattern di pressione e temporizzazione durante la digitazione.</li>
<li><strong>Biometria vocale</strong> (<em>Voice biometrics</em>): riconoscimento basato sulle caratteristiche della voce.</li>
<li><strong>Riconoscimento dell‚Äôandatura</strong> (<em>Gait recognition</em>): analisi del modo di camminare.</li>
</ul>
<h4 id="caratteristiche-miste-mixed-features">Caratteristiche Miste (Mixed Features)</h4>
<p>Combinano aspetti fisiologici e comportamentali.</p>
<ul>
<li><strong>Volto</strong>: struttura facciale (fisiologica) + espressioni e movimenti (comportamentali).</li>
<li><strong>Voce</strong>: caratteristiche dell‚Äôapparato vocale (fisiologiche) + modalit√† di emissione (comportamentali).</li>
</ul>
<h4 id="tracce-biologiche-biological-traces-biometrics">Tracce Biologiche (Biological Traces Biometrics)</h4>
<ul>
<li><strong>DNA</strong>: caratteristica biometrica estremamente discriminante, utilizzata principalmente in ambito forense e non in sistemi di autenticazione in tempo reale.</li>
</ul>
<h4 id="strong-biometric-traits">Strong Biometric Traits</h4>
<p>Sono tratti biometrici caratterizzati da <strong>elevata unicit√† e persistenza nel tempo</strong>, quindi particolarmente affidabili per il riconoscimento:</p>
<ul>
<li><strong>Impronte digitali</strong></li>
<li><strong>Volto</strong></li>
<li><strong>Iride</strong></li>
</ul>
<h4 id="soft-biometric-traits">Soft Biometric Traits</h4>
<p>Sono tratti biometrici con <strong>bassa unicit√†</strong> o <strong>scarsa persistenza</strong>, ma possono essere utili per <strong>ridurre lo spazio di ricerca</strong> o supportare altre biometrie:</p>
<ul>
<li>Colore dei capelli</li>
<li>Forma del volto</li>
<li>Andatura</li>
<li>Altre caratteristiche fisiche generali</li>
</ul>
<p>Questi tratti possono variare nel tempo a causa di fattori come <strong>umore, stato di salute, et√† o condizioni ambientali</strong>, ma risultano utili come informazioni complementari nei sistemi biometrici complessi (ad esempio per limitare il numero di candidati in fase di identificazione).</p>
<h3 id="15-notazione-e-terminologia">1.5 Notazione e Terminologia</h3>
<p><strong>Insiemi fondamentali</strong>:
- $\mathcal{G}$ = Gallery (insieme di template enrollati)
- $\mathcal{P}$ = Probe set (insieme di campioni da riconoscere)
- $\mathcal{P}_G \subset \mathcal{P}$ = Probe di soggetti in galleria (enrolled)
- $\mathcal{P}_N \subset \mathcal{P}$ = Probe di soggetti NON in galleria (non-enrolled)
- $N$ = Numero di identit√† in galleria
- $|\mathcal{G}|$ = Numero totale di template in galleria</p>
<p><strong>Funzioni di ground truth</strong> (disponibili solo in fase di testing):
- $\text{id}(t)$: restituisce l&rsquo;identit√† vera associata al template $t$
- $\text{topMatch}(p, i)$: restituisce il miglior match tra probe $p$ e template dell&rsquo;identit√† $i$</p>
<p><strong>Funzioni di matching</strong>:
- $s(t_1, t_2) \in \mathbb{R}$: similarit√† tra template (maggiore = pi√π simili)
- $d(t_1, t_2) \in \mathbb{R}^+$: distanza tra template (minore = pi√π simili)</p>
<p><strong>Convenzione</strong>: Useremo principalmente <strong>distanze</strong> (valori pi√π bassi indicano maggiore somiglianza).</p>
<h3 id="15-distribuzioni-di-score">1.5 Distribuzioni di Score</h3>
<p>Le distribuzioni di score sono il concetto fondamentale per comprendere il comportamento dei sistemi biometrici. Ogni confronto tra template produce uno score (distanza o similarit√†), e questi score seguono distribuzioni statistiche diverse a seconda che i template appartengano alla stessa persona o a persone diverse.</p>
<p><strong>Definizione formale delle distribuzioni</strong>:</p>
<p>Sia $X$ un campione biometrico casuale e sia $s$ uno score (distanza o similarit√†).</p>
<p><strong>Distribuzione Impostor</strong> (o Non-Match):
$$p(s|H_0) = p(s|\text{id}(t_1) \neq \text{id}(t_2))$$</p>
<p>Score ottenuti confrontando template di <strong>identit√† diverse</strong>. Questa distribuzione rappresenta quanto sono dissimili persone diverse secondo il sistema biometrico. In un sistema ideale, tutti gli score impostor dovrebbero essere alti (se usiamo distanze) o bassi (se usiamo similarit√†).</p>
<p><strong>Distribuzione Genuine</strong> (o Match):
$$p(s|H_1) = p(s|\text{id}(t_1) = \text{id}(t_2))$$</p>
<p>Score ottenuti confrontando template della <strong>stessa identit√†</strong>. Questa distribuzione rappresenta quanto sono simili campioni diversi della stessa persona. In un sistema ideale, tutti gli score genuine dovrebbero essere bassi (per distanze) o alti (per similarit√†).</p>
<p><strong>Propriet√† teorica</strong>:
In un sistema ideale: $supp(p(s|H_0)) \cap supp(p(s|H_1)) = \emptyset$, dove </p>
$$supp(p) = \{x \in \mathbb{R} : p(x) > 0\}.$$
<p>In pratica, le distribuzioni si <strong>sovrappongono</strong>, rendendo impossibile una separazione perfetta. Questa sovrapposizione √® la causa fondamentale di tutti gli errori nei sistemi biometrici.</p>
<p><strong>Caratteristiche tipiche</strong> (usando distanze):
- Impostor distribution: score alti (alta distanza), $\sigma_I$ moderata
- Genuine distribution: score bassi (bassa distanza), $\sigma_G$ variabile
- Overlap region: $p(s|H_0) > 0 \land p(s|H_1) > 0$</p>
<p>La <strong>qualit√† del sistema</strong> √® inversamente proporzionale all&rsquo;area di sovrapposizione. Un sistema migliore ha distribuzioni pi√π separate, con meno sovrapposizione.</p>
<p><strong>Interpretazione grafica</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Numero di confronti</span>
<span class="n">n_genuine</span>  <span class="o">=</span> <span class="mi">100_000</span>
<span class="n">n_impostor</span> <span class="o">=</span> <span class="mi">100_000</span>

<span class="c1"># Distribuzione Genuine (distanze basse)</span>
<span class="n">genuine_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>      <span class="c1"># media (bassa)</span>
    <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>    <span class="c1"># deviazione standard</span>
    <span class="n">size</span><span class="o">=</span><span class="n">n_genuine</span>
<span class="p">)</span>

<span class="c1"># Distribuzione Impostor (distanze alte)</span>
<span class="n">impostor_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
    <span class="n">loc</span><span class="o">=</span><span class="mf">15.0</span><span class="p">,</span>      <span class="c1"># media (alta)</span>
    <span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>    <span class="c1"># deviazione standard</span>
    <span class="n">size</span><span class="o">=</span><span class="n">n_impostor</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">genuine_scores</span><span class="p">,</span>
    <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Genuine&quot;</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
    <span class="n">impostor_scores</span><span class="p">,</span>
    <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Impostor&quot;</span>
<span class="p">)</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="mf">12.0</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Threshold&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Score (distanza)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densit√†&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribuzioni Genuine e Impostor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
</div>
</details>

<p><img src="/images/posts/distribuzioni-genuine-impostor.png" style="display: block; margin-left: auto; margin-right: auto; width: 60%;"></p>
<p>Nella regione di overlap, √® impossibile distinguere con certezza se uno score proviene da un confronto genuine o impostor. La scelta della soglia determina quanti errori di ciascun tipo commetteremo.</p>
<h2 id="16-come-confrontiamo-due-template">1.6 Come Confrontiamo due Template?</h2>
<p>Una volta estratti i template biometrici, il passo successivo consiste nel <strong>confrontarli</strong> per ottenere uno <strong>score</strong> di similarit√† o distanza.<br />
La scelta della metrica di confronto dipende dalla <strong>natura del template</strong> (vettore, istogramma, serie temporale, insieme di punti, ecc.).</p>
<h3 id="template-come-vettori">üîπ Template come vettori</h3>
<p>In molti sistemi biometrici, i template sono rappresentati come <strong>vettori numerici</strong> in uno spazio multidimensionale.<br />
In questo caso, √® possibile utilizzare metriche standard:</p>
<ul>
<li>
<p><strong>Distanza Euclidea</strong><br />
  Misura la distanza geometrica tra due vettori nello spazio.
  üëâ Vedi: <span class="text-gray-600">Distanza Euclidea</span></p>
</li>
<li>
<p><strong>Similarit√† Coseno</strong><br />
  Misura l‚Äôangolo tra due vettori, indipendentemente dalla loro norma.
  üëâ Vedi: <span class="text-gray-600">Similarit√† Coseno</span></p>
</li>
</ul>
<p>Queste metriche possono essere interpretate rispettivamente come:
- <strong>distanza</strong> (pi√π piccola = pi√π simili)
- <strong>similarit√†</strong> (pi√π grande = pi√π simili)</p>
<h3 id="correlazione">üîπ Correlazione</h3>
<p>Per template rappresentati come <strong>istogrammi</strong> o <strong>insiemi di punti</strong>, √® possibile usare una misura di similarit√† basata sulla correlazione:</p>
<ul>
<li><strong>Correlazione di Pearson</strong><br />
  Valuta il grado di relazione lineare tra due rappresentazioni.
  üëâ Vedi: <span class="text-gray-600">Correlazione di Pearson</span></li>
</ul>
<h3 id="confronto-tra-istogrammi">üîπ Confronto tra istogrammi</h3>
<p>Quando i template sono <strong>istogrammi</strong> (ad esempio distribuzioni di orientamenti o frequenze), esistono metriche dedicate:</p>
<ul>
<li><strong>Distanza di Bhattacharyya</strong><br />
  Misura la sovrapposizione tra due distribuzioni di probabilit√†.
  üëâ Vedi: <span class="text-gray-600">Distanza di Bhattacharyya</span></li>
</ul>
<h3 id="serie-temporali">üîπ Serie temporali</h3>
<p>Per template che rappresentano <strong>segnali nel tempo</strong> (ad esempio andature, gesti, segnali biometrici dinamici):</p>
<ul>
<li><strong>Dynamic Time Warping (DTW)</strong><br />
  Allinea due serie temporali che possono avere velocit√† diverse ma forma simile.
  üëâ Vedi: <span class="text-gray-600">Dynamic Time Warping</span></li>
</ul>
<p>Un esempio tipico √® il confronto di due sequenze di camminata:<br />
anche se la velocit√† di esecuzione varia, la traiettoria spaziale degli arti rimane simile.</p>
<h3 id="template-da-modelli-deep-learning">üîπ Template da modelli Deep Learning</h3>
<p>Nel caso di sistemi basati su <strong>Deep Learning</strong>, il confronto avviene tipicamente sulle <strong>embedding</strong>:</p>
<ul>
<li>Si rimuove l‚Äôultimo strato di classificazione (di solito un <strong>softmax</strong>)</li>
<li>L‚Äôoutput intermedio della rete viene usato come <strong>vettore di feature</strong></li>
<li>Le embedding vengono confrontate usando metriche standard (es. distanza euclidea o similarit√† coseno)</li>
</ul>
<p>üëâ Vedi: <span class="text-gray-600">Embedding in Deep Learning</span></p>
<h3 id="template-strutturati-complessi">üîπ Template strutturati complessi</h3>
<p>Alcuni template richiedono strategie di confronto pi√π sofisticate.<br />
Ad esempio, nel riconoscimento delle impronte digitali:</p>
<ul>
<li>I template sono insiemi di <strong>minuzie</strong></li>
<li>√à necessario trovare il <strong>miglior accoppiamento</strong> tra punti prima di calcolare uno score</li>
</ul>
<p>üëâ Vedi: <span class="text-gray-600">Matching di Minuzie</span></p>
<h2 id="dopo-il-confronto">Dopo il Confronto</h2>
<p>Una volta calcolato uno score di <strong>similarit√†</strong> o <strong>distanza</strong>, questo viene confrontato con una <strong>soglia di accettazione</strong>:</p>
<ul>
<li><strong>Verifica</strong> o <strong>identificazione open-set</strong></li>
<li>Score ‚â• soglia ‚Üí accettazione (similarit√†)</li>
<li>Score ‚â§ soglia ‚Üí accettazione (distanza)</li>
</ul>
<p>L‚Äôanalisi delle prestazioni studia il comportamento del sistema al variare della soglia, mettendo in evidenza:
- errori del sistema
- compromesso tra falsi accettati e falsi rifiutati</p>
<h2 id="in-sintesi">In Sintesi</h2>
<ul>
<li>Selezionare ed estrarre <strong>feature sufficientemente discriminative</strong></li>
<li>Definire una <strong>strategia di matching appropriata</strong></li>
<li>Analizzare il comportamento del sistema al variare della soglia:</li>
<li>similarit√† ‚â• soglia</li>
<li>distanza ‚â§ soglia</li>
</ul>
<h2 id="2-verifica-biometrica">2. Verifica Biometrica</h2>
<h3 id="21-definizione-formale-del-task">2.1 Definizione Formale del Task</h3>
<p>La verifica √® la modalit√† operativa pi√π comune nei sistemi biometrici consumer (smartphone, laptop, accesso fisico). Il compito √® relativamente semplice da definire ma complesso da realizzare con alta accuratezza.</p>
<p><strong>Task di Verifica</strong>: Data una coppia $(p, i)$ dove:
- $p$ = probe (campione biometrico acquisito)
- $i$ = identit√† dichiarata (claim esplicito o implicito)</p>
<p>Decidere se $\text{id}(p) = i$.</p>
<p><strong>Decision rule parametrizzata da soglia</strong> $\tau$:</p>
<p>Per <strong>distanze</strong>:
$$\delta_\tau(p, i) = \begin{cases}
\text{Accept} & \text{se } d(p, \text{topMatch}(p,i)) \leq \tau \\
\text{Reject} & \text{altrimenti}
\end{cases}$$</p>
<p>Per <strong>similarit√†</strong>:
$$\delta_\tau(p, i) = \begin{cases}
\text{Accept} & \text{se } s(p, \text{topMatch}(p,i)) \geq \tau \\
\text{Reject} & \text{altrimenti}
\end{cases}$$</p>
<p>La soglia $\tau$ √® il parametro pi√π critico del sistema: determina il trade-off tra sicurezza e usabilit√†. Una soglia troppo restrittiva blocca utenti legittimi, una troppo permissiva lascia entrare impostori.</p>
<h3 id="22-tassonomia-degli-outcome">2.2 Tassonomia degli Outcome</h3>
<p><strong>Definizione rigorosa degli outcome</strong>:</p>
<p>Siano:
- $H_1$: ipotesi che $\text{id}(p) = i$ (claim genuino)
- $H_0$: ipotesi che $\text{id}(p) \neq i$ (claim impostor)
- $D_1$: decisione di accettare
- $D_0$: decisione di rifiutare</p>
<table>
<thead>
<tr>
<th><strong>Ipotesi Vera</strong></th>
<th><strong>Decisione</strong></th>
<th><strong>Outcome</strong></th>
<th><strong>Nome</strong></th>
<th><strong>Tipo</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>$H_1$</td>
<td>$D_1$</td>
<td>$\text{id}(p) = i \land \text{Accept}$</td>
<td>Genuine Acceptance (GA)</td>
<td>‚úì Corretto</td>
</tr>
<tr>
<td>$H_1$</td>
<td>$D_0$</td>
<td>$\text{id}(p) = i \land \text{Reject}$</td>
<td>False Rejection (FR)</td>
<td>‚úó Errore Tipo I</td>
</tr>
<tr>
<td>$H_0$</td>
<td>$D_0$</td>
<td>$\text{id}(p) \neq i \land \text{Reject}$</td>
<td>Genuine Rejection (GR)</td>
<td>‚úì Corretto</td>
</tr>
<tr>
<td>$H_0$</td>
<td>$D_1$</td>
<td>$\text{id}(p) \neq i \land \text{Accept}$</td>
<td>False Acceptance (FA)</td>
<td>‚úó Errore Tipo II</td>
</tr>
</tbody>
</table>
<p><strong>Interpretazione e impatto</strong>:
- <strong>GA (Genuine Acceptance)</strong>: Utente legittimo correttamente riconosciuto - esperienza utente positiva
- <strong>GR (Genuine Rejection)</strong>: Impostore correttamente respinto - sistema funziona come previsto
- <strong>FR (False Rejection)</strong>: Utente legittimo erroneamente respinto - <strong>impatto: usabilit√†, frustrazione utente</strong>
- <strong>FA (False Acceptance)</strong>: Impostore erroneamente accettato - <strong>impatto: SICUREZZA, accesso non autorizzato</strong></p>
<p><strong>Esempio concreto</strong>:
Consideriamo uno smartphone con riconoscimento facciale usato da 100 persone diverse in un giorno:
- 10 utilizzi sono dal proprietario (genuine attempts)
- 90 tentativi sono da altre persone che trovano il telefono (impostor attempts)</p>
<p>Se il sistema ha FAR = 0.01 e FRR = 0.05:
- Il proprietario verr√† bloccato circa 0.5 volte (5% di 10 tentativi)
- Circa 0.9 impostori entreranno nel telefono (1% di 90 tentativi)</p>
<h3 id="23-metriche-fondamentali">2.3 Metriche Fondamentali</h3>
<h4 id="231-false-acceptance-rate-far">2.3.1 False Acceptance Rate (FAR)</h4>
<p>Il FAR misura quanto spesso il sistema lascia entrare persone non autorizzate. √à la metrica pi√π critica per la sicurezza del sistema.</p>
<p><strong>Definizione</strong>:
$$\text{FAR}(\tau) = \frac{\text{\# False Acceptances}}{\text{\# Impostor Attempts}} = \frac{|\{(p,i) : \text{id}(p) \neq i \land d(p,i) \leq \tau\}|}{|\{(p,i) : \text{id}(p) \neq i\}|}$$</p>
<p><strong>Interpretazione probabilistica</strong>:
$$\text{FAR}(\tau) = P(D_1 | H_0) = P(\text{Accept} | \text{impostor})$$</p>
<p>Probabilit√† che un impostore venga erroneamente accettato.</p>
<p><strong>Esempio pratico</strong>: FAR = 0.001 (0.1%) significa che in media 1 impostore su 1000 viene accettato. In un sistema con milioni di accessi giornalieri, anche un FAR apparentemente basso pu√≤ tradursi in migliaia di accessi non autorizzati.</p>
<p><strong>Relazione con la distribuzione</strong>:
$$\text{FAR}(\tau) = \int_{-\infty}^{\tau} p(d|H_0) \, dd = P(d \leq \tau | H_0)$$</p>
<p>Il FAR √® quindi l&rsquo;area sotto la curva della distribuzione impostor a sinistra della soglia $\tau$.</p>
<p><strong>Considerazioni operative</strong>:
- In applicazioni di alta sicurezza (banche, accesso a dati sensibili): FAR target &lt; 0.0001 (0.01%)
- In applicazioni consumer (smartphone): FAR tipico ‚âà 0.001-0.01 (0.1%-1%)
- Il FAR aumenta con attacchi mirati (presentation attacks, deepfakes)</p>
<h4 id="232-false-rejection-rate-frr">2.3.2 False Rejection Rate (FRR)</h4>
<p>Il FRR misura quanto spesso il sistema blocca utenti legittimi. √à la metrica pi√π critica per l&rsquo;usabilit√† del sistema.</p>
<p><strong>Definizione</strong>:
$$\text{FRR}(\tau) = \frac{\text{\# False Rejections}}{\text{\# Genuine Attempts}} = \frac{|\{(p,i) : \text{id}(p) = i \land d(p,i) > \tau\}|}{|\{(p,i) : \text{id}(p) = i\}|}$$</p>
<p><strong>Interpretazione probabilistica</strong>:
$$\text{FRR}(\tau) = P(D_0 | H_1) = P(\text{Reject} | \text{genuine})$$</p>
<p>Probabilit√† che un utente genuino venga erroneamente rifiutato.</p>
<p><strong>Esempio pratico</strong>: FRR = 0.05 (5%) significa che in media 1 utente legittimo su 20 viene respinto. Se un utente tenta l&rsquo;accesso 10 volte al giorno, verr√† bloccato circa una volta ogni due giorni, causando frustrazione.</p>
<p><strong>Relazione con la distribuzione</strong>:
$$\text{FRR}(\tau) = \int_{\tau}^{\infty} p(d|H_1) \, dd = P(d > \tau | H_1)$$</p>
<p>Il FRR √® l&rsquo;area sotto la curva della distribuzione genuine a destra della soglia $\tau$.</p>
<p><strong>Considerazioni operative</strong>:
- In applicazioni consumer: FRR target &lt; 0.01-0.05 (1%-5%)
- FRR troppo alto causa abbandono del sistema biometrico (gli utenti preferiscono password)
- FRR aumenta con variazioni ambientali (illuminazione, angolazione, invecchiamento)</p>
<h4 id="233-genuine-acceptance-rate-gar">2.3.3 Genuine Acceptance Rate (GAR)</h4>
<p>Il GAR √® la metrica complementare al FRR e misura il successo del sistema nel riconoscere utenti legittimi.</p>
<p><strong>Definizione</strong>:
$$\text{GAR}(\tau) = 1 - \text{FRR}(\tau) = P(D_1 | H_1)$$</p>
<p><strong>Relazione complementare</strong>:
$$\text{GAR}(\tau) + \text{FRR}(\tau) = 1$$</p>
<p>Entrambe misurate rispetto ai <strong>genuine attempts</strong>.</p>
<p>Il GAR √® spesso preferito nelle presentazioni perch√© √® una metrica &ldquo;positiva&rdquo; (pi√π alto √® meglio), mentre il FRR √® una metrica &ldquo;negativa&rdquo; (pi√π basso √® meglio). Tuttavia, contengono la stessa informazione.</p>
<p><strong>Esempio</strong>: Un sistema con GAR = 0.98 (98%) ha FRR = 0.02 (2%). Questo significa che 98 utenti legittimi su 100 vengono correttamente riconosciuti.</p>
<h4 id="234-genuine-rejection-rate-grr">2.3.4 Genuine Rejection Rate (GRR)</h4>
<p>Il GRR misura quanto efficacemente il sistema respinge impostori.</p>
<p><strong>Definizione</strong>:
$$\text{GRR}(\tau) = 1 - \text{FAR}(\tau) = P(D_0 | H_0)$$</p>
<p><strong>Relazione complementare</strong>:
$$\text{GRR}(\tau) + \text{FAR}(\tau) = 1$$</p>
<p>Entrambe misurate rispetto agli <strong>impostor attempts</strong>.</p>
<p>Il GRR √® meno comunemente riportato rispetto al FAR, ma pu√≤ essere utile per enfatizzare l&rsquo;aspetto positivo della sicurezza del sistema.</p>
<h3 id="24-conteggi-vs-rate">2.4 Conteggi vs Rate</h3>
<p>√à fondamentale distinguere tra conteggi assoluti e rate normalizzate, poich√© questa distinzione √® fonte di errori comuni nella valutazione di sistemi biometrici.</p>
<p><strong>Distinzione critica</strong>:</p>
<p><strong>Conteggi assoluti</strong> (matcher-level):
- FM (False Match): Numero di match errati prodotti dal matcher
- FNM (False Non-Match): Numero di non-match errati
- Dipendono dalla dimensione del dataset di test
- Non confrontabili tra diversi esperimenti</p>
<p><strong>Rate normalizzate</strong> (system-level):
- FAR, FRR: Normalizzate rispetto alle popolazioni rilevanti
- Possono includere failure sistemici (FTE, FTA)
- Confrontabili tra diversi esperimenti
- Indipendenti dalla dimensione assoluta del dataset</p>
<p><strong>Failure to Enroll (FTE)</strong>:
$$\text{FTE} = \frac{\text{\# soggetti che non possono essere enrollati}}{N_{\text{popolazione}}}$$</p>
<p>Il FTE misura la percentuale di persone che non riescono a registrarsi nel sistema. Cause comuni:
- Qualit√† biometrica insufficiente (impronte danneggiate)
- Caratteristiche biometriche atipiche
- Problemi tecnici del sensore</p>
<p><strong>Failure to Acquire (FTA)</strong>:
$$\text{FTA} = \frac{\text{\# acquisizioni fallite}}{\text{\# tentativi di acquisizione}}$$</p>
<p>Il FTA misura la percentuale di tentativi di acquisizione che falliscono. Diverso dal FTE perch√©:
- FTE: problema persistente con un individuo specifico
- FTA: problema temporaneo che pu√≤ risolversi al tentativo successivo</p>
<p><strong>Esempio pratico</strong>:
Un sistema di impronte digitali in un&rsquo;azienda:
- 1000 dipendenti tentano l&rsquo;enrollment
- 5 hanno impronte troppo usurate (FTE = 0.5%)
- Durante l&rsquo;enrollment, 50 acquisizioni falliscono per dita sporche/umide (FTA ‚âà 5%)
- In operazione: 10000 accessi giornalieri, 20 FA, 100 FR
  - FAR = 20 / (numero impostori) - serve conoscere la composizione
  - FRR = 100 / (numero genuine) - serve conoscere la composizione</p>
<h3 id="25-trade-off-far-frr">2.5 Trade-off FAR-FRR</h3>
<p>Il trade-off tra FAR e FRR √® la caratteristica fondamentale dei sistemi biometrici threshold-based. Comprendere questo trade-off √® essenziale per configurare correttamente un sistema.</p>
<p><strong>Teorema 2.1</strong> (Monotonicit√†):
<em>Per un sistema di verifica basato su soglia:</em></p>
<ol>
<li>$\text{FAR}(\tau)$ √® monotona <strong>decrescente</strong> in $\tau$</li>
<li>$\text{FRR}(\tau)$ √® monotona <strong>crescente</strong> in $\tau$</li>
</ol>
<p><strong>Dimostrazione</strong>:</p>
<p>(1) Aumentando $\tau$, rendiamo pi√π restrittiva l&rsquo;accettazione (richiediamo distanza pi√π bassa):
$$\tau_1 < \tau_2 \Rightarrow P(d \leq \tau_1 | H_0) \geq P(d \leq \tau_2 | H_0)$$
$$\Rightarrow \text{FAR}(\tau_1) \geq \text{FAR}(\tau_2)$$</p>
<p>(2) Simmetricamente per FRR:
$$\tau_1 < \tau_2 \Rightarrow P(d > \tau_1 | H_1) \leq P(d > \tau_2 | H_1)$$</p>
$$
\Rightarrow \text{FRR}(\tau_1) \leq \text{FRR}(\tau_2)
$$
<p>$\square$</p>
<p><strong>Implicazione pratica</strong>: Non √® possibile minimizzare simultaneamente FAR e FRR modificando solo la soglia. Ogni miglioramento in sicurezza (FAR pi√π basso) costa in usabilit√† (FRR pi√π alto) e viceversa.</p>
<p><strong>Casi estremi</strong>:</p>
$$
\lim_{\tau \to 0} \begin{cases}
\text{FAR}(\tau) \to 1 \\
\text{FRR}(\tau) \to 0
\end{cases} \quad \text{(accetta tutti - sistema inutile per sicurezza)}
$$
$$
\lim_{\tau \to \infty} 
\begin{cases}
\text{FAR}(\tau) \to 0 \\
\text{FRR}(\tau) \to 1
\end{cases} \quad \text{(rifiuta tutti - sistema inutile per accesso)}
$$
<p><strong>Visualizzazione del trade-off</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>Rate
 1.0 |     FRR
     |       /
     |      /
     |     /
     |    /
     |   /  
     |  / X (EER)
     | /   \
     |/     \
     |\      \
     | \      _____ FAR
 0.0 |_____________________&gt; Threshold
     0              œÑ*       ‚àû
</code></pre></div>
</div>
</details>

<p>Il punto X rappresenta l&rsquo;Equal Error Rate (EER), dove FAR = FRR. Questo √® spesso usato come punto di riferimento, ma non necessariamente il punto operativo ottimale.</p>
<h3 id="26-equal-error-rate-eer">2.6 Equal Error Rate (EER)</h3>
<p>L&rsquo;EER √® la metrica scalare pi√π comunemente usata per riassumere la performance di un sistema biometrico in un singolo numero.</p>
<p><strong>Definizione</strong>:
$$\text{EER} = \text{FAR}(\tau^*) = \text{FRR}(\tau^*)$$</p>
<p>dove $\tau^*$ √® la soglia per cui FAR e FRR si uguagliano.</p>
<p><strong>Calcolo</strong>:
$$\tau^* = \arg\min_\tau |\text{FAR}(\tau) - \text{FRR}(\tau)|$$</p>
<p><strong>Propriet√†</strong>:
- Metrica <strong>scalare</strong> che riassume la performance complessiva
- EER basso indica sistema migliore (tipicamente 0.1%-5% per sistemi moderni)
- Punto di <strong>bilanciamento naturale</strong> tra i due errori
- Utile quando non si hanno informazioni sui costi relativi di FA e FR
- Indipendente dalla scelta arbitraria di una soglia operativa</p>
<p><strong>Limitazione critica</strong>: L&rsquo;EER potrebbe non essere il punto operativo ottimale se FA e FR hanno costi asimmetrici. Ad esempio:
- In un sistema bancario: costo(FA) &gt;&gt; costo(FR) ‚Üí opereremo a FAR molto pi√π basso dell&rsquo;EER
- In un sistema di accesso rapido: costo(FR) &gt;&gt; costo(FA) ‚Üí opereremo a FRR molto pi√π basso dell&rsquo;EER</p>
<p><strong>Esempio di calcolo</strong>:</p>
<table>
<thead>
<tr>
<th>Threshold</th>
<th>FAR</th>
<th>FRR</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.1</td>
<td>0.250</td>
<td>0.001</td>
</tr>
<tr>
<td>0.2</td>
<td>0.100</td>
<td>0.005</td>
</tr>
<tr>
<td>0.3</td>
<td>0.050</td>
<td>0.015</td>
</tr>
<tr>
<td>0.4</td>
<td>0.020</td>
<td>0.035</td>
</tr>
<tr>
<td>0.5</td>
<td>0.010</td>
<td>0.070</td>
</tr>
<tr>
<td>0.6</td>
<td>0.005</td>
<td>0.150</td>
</tr>
</tbody>
</table>
<p>EER ‚âà 0.027 alla soglia ‚âà 0.42 (interpolando tra 0.4 e 0.5)</p>
<p><strong>Confronto tra sistemi</strong>:
- Sistema A: EER = 1% - Eccellente
- Sistema B: EER = 5% - Buono
- Sistema C: EER = 10% - Accettabile per applicazioni non critiche
- Sistema D: EER = 20% - Scadente, non utilizzabile</p>
<h3 id="27-punti-operativi-speciali">2.7 Punti Operativi Speciali</h3>
<p>Oltre all&rsquo;EER, esistono altri punti operativi di interesse che corrispondono a requisiti applicativi specifici.</p>
<h4 id="zero-far-zerofmr">Zero FAR (ZeroFMR)</h4>
<p><strong>Definizione</strong>:
$$\text{ZeroFAR} = \text{FRR}(\tau_{\text{max}})$$</p>
<p>dove $\tau_{\text{max}}$ √® la soglia pi√π restrittiva che garantisce FAR = 0.</p>
<p>Per distanze: $\tau_{\text{max}} = \min\{d(p,g) : \text{id}(p) \neq \text{id}(g)\}$</p>
<p>FRR ottenuto quando la soglia √® impostata per garantire FAR = 0.</p>
<p><strong>Uso</strong>: Applicazioni di <strong>massima sicurezza</strong> (accesso a sistemi critici, vault bancari, laboratori militari).</p>
<p><strong>Esempio</strong>: Sistema di accesso a un data center con dati sensibili:
- Impostato a ZeroFAR
- FAR = 0% (nessun impostore pu√≤ entrare)
- FRR potrebbe essere 30-40% (alto, ma accettabile dato il contesto)
- Gli utenti legittimi hanno metodi di backup (PIN, badge)</p>
<h4 id="zero-frr-zerofnmr">Zero FRR (ZeroFNMR)</h4>
<p><strong>Definizione</strong>:
$\text{ZeroFRR} = \text{FAR}(\tau_{\text{min}})$</p>
<p>dove $\tau_{\text{min}}$ √® la soglia pi√π permissiva che garantisce FRR = 0.</p>
<p>Per distanze: $\tau_{\text{min}} = \max\{d(p,g) : \text{id}(p) = \text{id}(g)\}$</p>
<p>FAR ottenuto quando la soglia √® impostata per garantire FRR = 0.</p>
<p><strong>Uso</strong>: Applicazioni di <strong>massima usabilit√†</strong> (accesso prioritario, sistemi di emergenza).</p>
<p><strong>Esempio</strong>: Sistema di accesso per personale medico in pronto soccorso:
- Impostato a ZeroFRR
- FRR = 0% (nessun medico viene bloccato in emergenza)
- FAR potrebbe essere 5-10% (relativamente alto, ma compensato da altri controlli)</p>
<p><strong>Nota pratica</strong>: A causa della sovrapposizione delle distribuzioni, ottenere esattamente FAR = 0 o FRR = 0 √® generalmente impossibile nella pratica. Questi sono punti <strong>concettuali</strong> o <strong>asintotici</strong> che rappresentano i limiti teorici del sistema.</p>
<h3 id="28-receiver-operating-characteristic-roc">2.8 Receiver Operating Characteristic (ROC)</h3>
<p>La curva ROC √® lo strumento pi√π potente per visualizzare e confrontare le performance di sistemi biometrici. Fornisce una visione completa del comportamento del sistema a tutte le possibili soglie.</p>
<p><strong>Definizione formale</strong>:</p>
<p>La curva ROC √® la funzione parametrica:
$\text{ROC}(\tau) = (\text{FAR}(\tau), \text{GAR}(\tau)) = (\text{FAR}(\tau), 1 - \text{FRR}(\tau))$</p>
<p>al variare di $\tau \in [0, \infty)$.</p>
<p><strong>Coordinate</strong>:
- <strong>Asse X</strong>: FAR (False Accept Rate) - l&rsquo;errore di sicurezza
- <strong>Asse Y</strong>: GAR (Genuine Accept Rate) = 1 - FRR - il successo nell&rsquo;accettare legittimi</p>
<p><strong>Punti notevoli</strong>:</p>
<ul>
<li>$(0, 0)$: $\tau = \infty$ ‚Üí rifiuta tutto (inutilmente restrittivo)</li>
<li>$(1, 1)$: $\tau = 0$ ‚Üí accetta tutto (inutilmente permissivo)</li>
<li>$(0, 1)$: Sistema perfetto (separazione completa delle distribuzioni - irraggiungibile)</li>
<li>Diagonale $y = x$: Classificatore casuale (equivalente a lanciare una moneta)</li>
</ul>
<p><strong>Interpretazione geometrica</strong>:
- Curva pi√π vicina all&rsquo;angolo $(0,1)$ ‚Üí sistema migliore
- Curva sopra la diagonale ‚Üí potere discriminante positivo
- Curva sulla diagonale ‚Üí nessun potere discriminante
- Curva sotto la diagonale ‚Üí sistema &ldquo;invertito&rdquo; (peggio del caso, probabilmente bug nel codice)</p>
<p><strong>Area Under the Curve (AUC-ROC)</strong>:
$\text{AUC} = \int_0^1 \text{GAR}(t) \, d(\text{FAR}(t))$</p>
<p><strong>Range</strong>: $[0, 1]$ dove:
- AUC = 1: Perfetto (le distribuzioni non si sovrappongono)
- AUC = 0.5: Casuale (nessuna capacit√† discriminante)
- AUC &gt; 0.5: Potere discriminante positivo
- AUC tipico per sistemi moderni: 0.95-0.999</p>
<p><strong>Interpretazione probabilistica dell&rsquo;AUC</strong>:
L&rsquo;AUC rappresenta la probabilit√† che uno score genuine casuale sia migliore (pi√π basso per distanze) di uno score impostor casuale. Formalmente:</p>
<p>$\text{AUC} = P(d_{\text{genuine}} < d_{\text{impostor}})$</p>
<p><strong>Confronto tra sistemi usando ROC</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>GAR
 1.0|    Sistema A (migliore)
    |      _.-&#39;&#39;&#39;
    |    _/
    |   /      Sistema B
    | _/     _/
    |/    _/
    |  _/  Diagonale (casuale)
    |_/
 0.0|__________________ FAR
   0.0               1.0
</code></pre></div>
</div>
</details>

<p>Sistema A domina Sistema B: per ogni valore di FAR, Sistema A ha GAR pi√π alto.</p>
<p><strong>Esempio pratico</strong>:
Confronto di tre algoritmi di face recognition:</p>
<table>
<thead>
<tr>
<th>Sistema</th>
<th>AUC</th>
<th>EER</th>
<th>Interpretazione</th>
</tr>
</thead>
<tbody>
<tr>
<td>Deep CNN</td>
<td>0.998</td>
<td>0.5%</td>
<td>Stato dell&rsquo;arte</td>
</tr>
<tr>
<td>Traditional Features</td>
<td>0.950</td>
<td>3%</td>
<td>Buono, ma superato</td>
</tr>
<tr>
<td>Baseline</td>
<td>0.850</td>
<td>8%</td>
<td>Accettabile per applicazioni non critiche</td>
</tr>
</tbody>
</table>
<h3 id="29-detection-error-tradeoff-det">2.9 Detection Error Tradeoff (DET)</h3>
<p>La curva DET √® un&rsquo;alternativa alla ROC, particolarmente utile per analizzare sistemi ad alta accuratezza dove gli errori sono molto bassi.</p>
<p><strong>Definizione</strong>:
$\text{DET}(\tau) = (\text{FAR}(\tau), \text{FRR}(\tau))$</p>
<p><strong>Differenze chiave con ROC</strong>:
- Confronto <strong>diretto</strong> tra i due errori (non usa GAR)
- Scala <strong>logaritmica</strong> su entrambi gli assi
- Curva pi√π <strong>bassa e a sinistra</strong> √® migliore (opposto di ROC)
- Visualizza direttamente il trade-off FAR-FRR</p>
<p><strong>Vantaggi</strong>:
- Evidenzia meglio differenze a bassi error rate (0.1%, 0.01%, 0.001%)
- Pi√π intuitivo per applicazioni di sicurezza
- Simmetrico rispetto ai due tipi di errore
- Permette di vedere chiaramente i punti operativi a FAR molto basso</p>
<p><strong>Scala logaritmica</strong>:
$\log_{10}(\text{FAR}(\tau)) \text{ vs } \log_{10}(\text{FRR}(\tau))$</p>
<p>Assi tipici: da 0.01% (10‚Åª‚Å¥) a 50% (10‚Åª‚Å∞¬∑¬≥)</p>
<p>Permette di distinguere $10^{-3}$ da $10^{-4}$ (cruciale in sicurezza), cosa difficile con scala lineare.</p>
<p><strong>Interpretazione DET</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>FRR (log)
 10%|
    |  \
    |   \  Sistema B (peggiore)
    |    \
 1% |     \
    |   \  \ Sistema A (migliore)
    |    \  \
0.1%|     \  \
    |      \  \
0.01|________________ FAR (log)
    0.01  0.1  1%  10%
</code></pre></div>
</div>
</details>

<p>Sistema A ha errori pi√π bassi per tutte le soglie operative.</p>
<p><strong>Esempio</strong>: Sistema di riconoscimento iris:
- Su scala lineare: differenza tra FAR=0.0001 e FAR=0.00001 invisibile
- Su scala log DET: differenza chiaramente visibile (ordine di grandezza)
- Critico per applicazioni ad alta sicurezza dove questi numeri contano</p>
<h3 id="210-scelta-della-soglia-ottimale">2.10 Scelta della Soglia Ottimale</h3>
<p>La scelta della soglia ottimale dipende dal contesto applicativo, dai costi degli errori e dai prior sulle popolazioni. Non esiste una soglia universalmente ottimale.</p>
<h4 id="approccio-bayesiano-con-costi">Approccio Bayesiano con Costi</h4>
<p>Il framework Bayesiano formalizza la scelta della soglia in termini di minimizzazione del rischio atteso.</p>
<p><strong>Rischio atteso</strong>:
$R(\tau) = C_{FA} \cdot \text{FAR}(\tau) \cdot \pi_I + C_{FR} \cdot \text{FRR}(\tau) \cdot \pi_G$</p>
<p>dove:
- $C_{FA}$ = costo di una False Acceptance (es. perdita finanziaria, compromissione sicurezza)
- $C_{FR}$ = costo di una False Rejection (es. frustrazione utente, perdita di tempo)
- $\pi_I$ = prior probability di impostor (proporzione di tentativi di accesso da impostori)
- $\pi_G$ = prior probability di genuine (proporzione di tentativi da utenti legittimi)</p>
<p><strong>Soglia ottimale</strong>:
$\tau^* = \arg\min_\tau R(\tau)$</p>
<p><strong>Teorema 2.2</strong> (Soglia di Neyman-Pearson):
<em>Data la loss matrix asimmetrica, la soglia ottimale soddisfa:</em></p>
<p>$\frac{p(d|\text{genuine})}{p(d|\text{impostor})} = \frac{C_{FA} \cdot \pi_I}{C_{FR} \cdot \pi_G}$</p>
<p>valutata in $d = \tau^*$.</p>
<p>Questa √® la <strong>likelihood ratio</strong> al punto di soglia ottimale.</p>
<p><strong>Casi speciali</strong>:</p>
<ol>
<li>
<p><strong>Costi uguali</strong> ($C_{FA} = C_{FR}$) e <strong>prior uniforme</strong> ($\pi_I = \pi_G = 0.5$):
   $\tau^* = \text{valore per cui } p(d|H_1) = p(d|H_0)$
   Corrisponde approssimativamente all&rsquo;EER (punto di intersezione delle distribuzioni).</p>
</li>
<li>
<p><strong>Sicurezza critica</strong> ($C_{FA} \gg C_{FR}$):
   $\frac{C_{FA}}{C_{FR}} \text{ grande} \Rightarrow \tau^* \to 0 \quad \text{(soglia molto restrittiva)}$
   Esempio: $C_{FA} = ‚Ç¨1.000.000$ (furto di dati), $C_{FR} = ‚Ç¨1$ (utente riprova)
   ‚Üí Opereremo a FAR ‚âà 0.0001% anche se FRR ‚âà 20%</p>
</li>
<li>
<p><strong>Usabilit√† critica</strong> ($C_{FR} \gg C_{FA}$):
   $\frac{C_{FR}}{C_{FA}} \text{ grande} \Rightarrow \tau^* \to \infty \quad \text{(soglia molto permissiva)}$
   Esempio: Sistema di screening rapido dove i falsi positivi vengono catturati da controlli successivi</p>
</li>
<li>
<p><strong>Prior sbilanciati</strong>:
   Se $\pi_I \gg \pi_G$ (molti pi√π tentativi impostor): soglia pi√π restrittiva
   Se $\pi_G \gg \pi_I$ (quasi tutti tentativi genuine): soglia pi√π permissiva</p>
</li>
</ol>
<p><strong>Esempio pratico completo</strong>:</p>
<p>Scenario: Sistema di accesso a un edificio aziendale
- 1000 dipendenti (genuine users)
- 10 tentativi di accesso giornalieri per dipendente = 10.000 genuine attempts/giorno
- 100 tentativi da non-dipendenti (impostor) = 100 impostor attempts/giorno
- $\pi_G = 10000/10100 \approx 0.99$, $\pi_I = 100/10100 \approx 0.01$</p>
<p>Costi:
- $C_{FA}$ = ‚Ç¨500 (costo medio per gestire intrusion, investigate, ecc.)
- $C_{FR}$ = ‚Ç¨2 (tempo perso dipendente + frustrazione)</p>
<p>Rischio atteso per diversi punti operativi:</p>
<table>
<thead>
<tr>
<th>Punto</th>
<th>FAR</th>
<th>FRR</th>
<th>R(œÑ)</th>
</tr>
</thead>
<tbody>
<tr>
<td>EER</td>
<td>2%</td>
<td>2%</td>
<td>500√ó0.02√ó0.01 + 2√ó0.02√ó0.99 = ‚Ç¨0.14</td>
</tr>
<tr>
<td>Low FAR</td>
<td>0.1%</td>
<td>10%</td>
<td>500√ó0.001√ó0.01 + 2√ó0.1√ó0.99 = ‚Ç¨0.203</td>
</tr>
<tr>
<td>Low FRR</td>
<td>5%</td>
<td>0.5%</td>
<td>500√ó0.05√ó0.01 + 2√ó0.005√ó0.99 = ‚Ç¨0.26</td>
</tr>
</tbody>
</table>
<p>‚Üí In questo caso, EER √® vicino all&rsquo;ottimo perch√© $C_{FA}/C_{FR} \approx 250$ ma $\pi_G/\pi_I \approx 100$ compensano.</p>
<p><strong>Considerazioni aggiuntive</strong>:
- I costi possono non essere solo monetari (reputazione, rischio legale, privacy)
- I prior possono cambiare nel tempo (attacchi mirati aumentano $\pi_I$)
- La soglia pu√≤ essere adattata dinamicamente in base a risk analysis real-time</p>
<h2 id="3-identificazione-open-set">3. Identificazione Open-Set</h2>
<h3 id="31-definizione-del-task">3.1 Definizione del Task</h3>
<p>L&rsquo;identificazione open-set √® la modalit√† operativa pi√π complessa e realistica, tipica di applicazioni di sorveglianza, watchlist e controllo accessi dove non tutti i soggetti sono pre-registrati.</p>
<p><strong>Task di Identificazione Open-Set</strong>: Dato un probe $p$:</p>
<ol>
<li><strong>Determinare</strong> se $\text{id}(p) \in \mathcal{G}$ (detection/presence)</li>
<li><strong>Se s√¨</strong>, identificare quale identit√†: $\arg\min_{g \in \mathcal{G}} d(p, g)$ (identification)</li>
</ol>
<p><strong>Differenze chiave con verifica</strong>:
- Nessuna identit√† dichiarata (no claim) ‚Üí sistema deve fare tutto autonomamente
- Confronto <strong>1-to-N</strong>: probe vs tutta la galleria ‚Üí computazionalmente intensivo
- Decisione binaria <strong>+ identificazione</strong> ‚Üí due possibili tipi di errore
- Pi√π errori possibili ‚Üí metriche pi√π complesse</p>
<p><strong>Terminologia</strong>:
- <strong>Enrolled</strong>: $\text{id}(p) \in \mathcal{G}$ - il soggetto √® nel database
- <strong>Non-enrolled</strong>: $\text{id}(p) \notin \mathcal{G}$ - il soggetto non √® nel database
- Non usiamo &ldquo;impostor&rdquo; (termine riservato alla verifica con claim esplicito)</p>
<p><strong>Applicazioni pratiche</strong>:
- <strong>Watchlist</strong>: aeroporti, stazioni, eventi pubblici - cercare soggetti di interesse
- <strong>Controllo accessi</strong>: edifici aziendali dove visitatori esterni devono essere gestiti
- <strong>Investigazioni</strong>: identificare persone in video/foto confrontando con database criminali
- <strong>Sorveglianza</strong>: monitoraggio continuo per rilevare presenza di persone note</p>
<h3 id="32-procedura-operativa">3.2 Procedura Operativa</h3>
<p><strong>Algoritmo dettagliato</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>Input: 
  - probe p (campione biometrico da identificare)
  - gallery G = {g‚ÇÅ, g‚ÇÇ, ..., g|G|} (database template)
  - threshold œÑ (soglia di decisione)

Output: 
  - identity or &quot;not in gallery&quot;

1. Compute all distances:
   D = {d(p, g‚ÇÅ), d(p, g‚ÇÇ), ..., d(p, g|G|)}

2. Sort D in ascending order:
   d‚ÇÅ ‚â§ d‚ÇÇ ‚â§ ... ‚â§ d|G|

   Otteniamo ranked list: [(g‚ÇÅ, d‚ÇÅ), (g‚ÇÇ, d‚ÇÇ), ..., (g|G|, d|G|)]
   dove g‚ÇÅ √® il template pi√π simile a p

3. Decision logic:
   If d‚ÇÅ &gt; œÑ:
     Return &quot;not in gallery&quot; (no detection)
     // Nemmeno il match migliore supera la soglia
   Else:
     // Detection positivo, ora verifichiamo l&#39;identit√†
     Return id(g‚ÇÅ)  // Identit√† del template con distanza minima
</code></pre></div>
</div>
</details>

<p><strong>Ruolo critico della soglia</strong>:
- Funge da <strong>presence detector</strong> - decide se il probe appartiene a qualcuno in galleria
- NON verifica un&rsquo;identit√† dichiarata (differenza con verifica)
- Controlla se <strong>qualcuno</strong> in galleria √® sufficientemente simile
- Troppo permissiva ‚Üí molti falsi allarmi (persone non in galleria rilevate erroneamente)
- Troppo restrittiva ‚Üí molte persone in galleria non vengono rilevate</p>
<p><strong>Complessit√† computazionale</strong>:
- O(|G|) confronti per ogni probe
- Per gallerie grandi (milioni di template): necessari algoritmi di indicizzazione/hashing
- Trade-off accuracy vs speed: approssimazioni (LSH, quantization) riducono accuracy ma aumentano velocit√†</p>
<h3 id="33-tassonomia-degli-outcome">3.3 Tassonomia degli Outcome</h3>
<p>A differenza della verifica (4 outcome), l&rsquo;identificazione open-set ha outcome pi√π complessi perch√© combina detection e identification.</p>
<p><strong>Caso 1: Probe enrolled</strong> ($p \in \mathcal{P}_G$) - Il soggetto √à nel database</p>
<table>
<thead>
<tr>
<th><strong>Condizione</strong></th>
<th><strong>Outcome</strong></th>
<th><strong>Nome</strong></th>
<th><strong>Interpretazione</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>$d_1 \leq \tau \land \text{id}(g_1) = \text{id}(p)$</td>
<td>Detection ‚úì, ID ‚úì</td>
<td><strong>Correct Detection &amp; Identification</strong></td>
<td>Successo completo</td>
</tr>
<tr>
<td>$d_1 \leq \tau \land \text{id}(g_1) \neq \text{id}(p)$</td>
<td>Detection ‚úì, ID ‚úó</td>
<td><strong>False Rejection</strong> (misidentification)</td>
<td>Rilevato ma ID sbagliata</td>
</tr>
<tr>
<td>$d_1 > \tau$</td>
<td>Detection ‚úó</td>
<td><strong>False Rejection</strong> (missed detection)</td>
<td>Non rilevato affatto</td>
</tr>
</tbody>
</table>
<p><strong>Caso 2: Probe non-enrolled</strong> ($p \in \mathcal{P}_N$) - Il soggetto NON √® nel database</p>
<table>
<thead>
<tr>
<th><strong>Condizione</strong></th>
<th><strong>Outcome</strong></th>
<th><strong>Nome</strong></th>
<th><strong>Interpretazione</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>$d_1 > \tau$</td>
<td>Nessun detection</td>
<td><strong>Genuine Rejection</strong></td>
<td>Corretto - nessun allarme</td>
</tr>
<tr>
<td>$d_1 \leq \tau$</td>
<td>Detection errato</td>
<td><strong>False Acceptance</strong> (false alarm)</td>
<td>Falso allarme</td>
</tr>
</tbody>
</table>
<p><strong>Importante</strong>: In open-set, FR pu√≤ avvenire in <strong>due modi</strong>:
1. Soggetto enrolled non rilevato affatto ($d_1 > \tau$)
2. Soggetto enrolled rilevato ma con identit√† sbagliata al primo posto ($d_1 \leq \tau$ ma $\text{id}(g_1) \neq \text{id}(p)$)</p>
<p><strong>Esempio pratico - Watchlist aeroportuale</strong>:</p>
<p>Galleria: 1000 soggetti pericolosi
Probe stream: 10000 passeggeri/giorno, di cui 2 sono in watchlist</p>
<p>Scenario A - Soglia troppo permissiva (œÑ = alto):
- I 2 soggetti pericolosi vengono rilevati (‚úì)
- Ma anche 500 passeggeri innocenti attivano falsi allarmi (‚úó)
- FAR = 500/9998 ‚âà 5% (inaccettabile - troppe false investigazioni)</p>
<p>Scenario B - Soglia troppo restrittiva (œÑ = basso):
- Solo 50 falsi allarmi (‚úì)
- Ma 1 dei 2 soggetti pericolosi non viene rilevato (‚úó)
- FRR = 1/2 = 50% (inaccettabile - obiettivo principale fallito)</p>
<p>Scenario C - Soglia bilanciata:
- I 2 soggetti pericolosi rilevati correttamente
- 100 falsi allarmi (gestibili con verifica secondaria)
- FAR = 100/9998 ‚âà 1%, FRR = 0/2 = 0%</p>
<h3 id="34-metriche-con-ranking">3.4 Metriche con Ranking</h3>
<p>In open-set, la posizione nella ranked list √® fondamentale perch√© il sistema pu√≤ restituire una short-list di candidati, non solo il top-1.</p>
<h4 id="341-detection-and-identification-rate-dir">3.4.1 Detection and Identification Rate (DIR)</h4>
<p><strong>Definizione generale</strong>:</p>
<p>$\text{DIR}(\tau, k) = \frac{|\{p \in \mathcal{P}_G : d_1 \leq \tau \land \text{rank}(\text{id}(p)) \leq k\}|}{|\mathcal{P}_G|}$</p>
<p>dove $\text{rank}(\text{id}(p))$ √® la posizione della prima occorrenza dell&rsquo;identit√† corretta nella lista ordinata.</p>
<p><strong>Interpretazione</strong>: Probabilit√† che un probe enrolled sia:
1. Rilevato (detection): almeno un template sotto soglia
2. Correttamente identificato entro rank k</p>
<p><strong>Caso speciale - DIR a rank 1</strong>:
$\text{DIR}(\tau, 1) = \frac{|\{p \in \mathcal{P}_G : d_1 \leq \tau \land \text{id}(g_1) = \text{id}(p)\}|}{|\mathcal{P}_G|}$</p>
<p>Questo √® il caso pi√π importante: identit√† corretta al primo posto.</p>
<p><strong>Interpretazione</strong>: Probabilit√† che un probe enrolled sia correttamente identificato al primo posto <strong>e</strong> che la distanza superi la soglia.</p>
<p><strong>Propriet√† di monotonicit√†</strong>:
$\text{DIR}(\tau, k_1) \leq \text{DIR}(\tau, k_2) \quad \forall k_1 < k_2$</p>
<p>All&rsquo;aumentare di $k$, DIR pu√≤ solo aumentare o restare costante (pi√π posizioni = pi√π opportunit√† di trovare l&rsquo;identit√† corretta).</p>
<p><strong>Esempio pratico</strong>:</p>
<p>Watchlist con 100 soggetti, 200 probe enrolled:
- DIR(œÑ, 1) = 0.85 ‚Üí 170 probe identificati correttamente al rank 1
- DIR(œÑ, 5) = 0.92 ‚Üí 184 probe hanno identit√† corretta entro top-5
- DIR(œÑ, 10) = 0.95 ‚Üí 190 probe hanno identit√† corretta entro top-10</p>
<p>Interpretazione: Per 30 probe (15%), l&rsquo;identit√† corretta non √® al primo posto ma appare entro i primi 10 candidati. In applicazioni dove un operatore umano verifica la short-list, DIR(œÑ, 10) √® pi√π rilevante di DIR(œÑ, 1).</p>
<h4 id="342-false-rejection-rate">3.4.2 False Rejection Rate</h4>
<p><strong>Definizione</strong>:
$\text{FRR}(\tau) = 1 - \text{DIR}(\tau, 1)$</p>
<p><strong>Interpretazione</strong>: Probabilit√† che un soggetto enrolled non sia correttamente identificato al primo posto.</p>
<p><strong>Decomposizione</strong>:
$\text{FRR}(\tau) = P(\text{no detection}|p \in \mathcal{P}_G) + P(\text{misidentification}|p \in \mathcal{P}_G)$</p>
<p>$= \frac{|\{p \in \mathcal{P}_G : d_1 > \tau\}|}{|\mathcal{P}_G|} + \frac{|\{p \in \mathcal{P}_G : d_1 \leq \tau \land \text{id}(g_1) \neq \text{id}(p)\}|}{|\mathcal{P}_G|}$</p>
<p>Questa decomposizione √® utile per diagnosticare problemi:
- Se termine 1 domina: problema di detection (soglia troppo restrittiva)
- Se termine 2 domina: problema di identification (matcher non discriminativo)</p>
<p><strong>Esempio diagnostico</strong>:</p>
<p>Sistema A: FRR = 10% (5% no detection + 5% misidentification)
‚Üí Problema bilanciato: migliorare sia soglia che matcher</p>
<p>Sistema B: FRR = 10% (9% no detection + 1% misidentification)
‚Üí Problema di detection: aumentare soglia (accettare pi√π FAR per ridurre FRR)</p>
<p>Sistema C: FRR = 10% (1% no detection + 9% misidentification)
‚Üí Problema di identification: migliorare matcher (feature extraction pi√π discriminativa)</p>
<h4 id="343-false-acceptance-rate-false-alarm-rate">3.4.3 False Acceptance Rate (False Alarm Rate)</h4>
<p><strong>Definizione</strong>:
$\text{FAR}(\tau) = \text{FPIR}(\tau) = \frac{|\{p \in \mathcal{P}_N : d_1 \leq \tau\}|}{|\mathcal{P}_N|}$</p>
<p>FPIR = False Positive Identification Rate (terminologia alternativa, comune in letteratura)</p>
<p><strong>Interpretazione</strong>: Probabilit√† che un soggetto non-enrolled produca una distanza sotto soglia (false alarm).</p>
<p><strong>Nota importante</strong>: In open-set, la posizione nella ranked list √® <strong>irrilevante</strong> per FA. Conta solo se $d_1 \leq \tau$. Questo perch√©:
- Per probe non-enrolled, non esiste identit√† corretta in galleria
- Qualsiasi detection √® un errore, indipendentemente da quale identit√† viene restituita
- L&rsquo;identit√† restituita √® casuale/arbitraria (dipende da chi somiglia di pi√π al probe)</p>
<p><strong>Differenza con verifica</strong>:
- Verifica: FAR richiede claim specifico
- Open-set: FAR √® detection errato di qualsiasi tipo</p>
<p><strong>Impatto operativo del FAR</strong>:</p>
<p>In applicazioni watchlist reali, FAR alto ha conseguenze pratiche:</p>
<p>Esempio aeroporto con 10000 passeggeri/giorno, 100 in watchlist:
- FAR = 1%: 99 falsi allarmi/giorno
- Ogni falso allarme richiede:
  - Investigazione di sicurezza (15 min)
  - Potenziale interrogatorio
  - Stress per passeggero innocente
  - Costo operativo (personale)</p>
<p>Con 99 falsi allarmi: 24.75 ore operative/giorno solo per gestire falsi positivi!</p>
<p>‚Üí Necessario FAR &lt; 0.1% (&lt; 10 falsi allarmi/giorno) per essere operativamente sostenibile.</p>
<h3 id="35-open-set-roc-watchlist-roc">3.5 Open-Set ROC (Watchlist ROC)</h3>
<p>La curva ROC per identificazione open-set ha interpretazione simile alla ROC di verifica, ma con metriche diverse sugli assi.</p>
<p><strong>Definizione</strong>:
$\text{ROC}_{\text{open}}(\tau) = (\text{FAR}(\tau), \text{DIR}(\tau, 1))$</p>
<p><strong>Differenza con ROC di verifica</strong>:
- Asse Y: <strong>DIR</strong> invece di GAR
- DIR √® pi√π restrittiva: richiede detection <strong>E</strong> identification corretti
- GAR richiede solo acceptance di genuine (decision threshold)
- Curve open-set tendenzialmente pi√π basse della ROC verification</p>
<p><strong>Interpretazione geometrica</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>DIR
 1.0|      Perfetto (0,1)
    |       *
    |      /
    |     /  Open-set ROC
    |    /   (pi√π bassa)
    |   /
    |  /
    | /    Verification ROC
    |/     (pi√π alta)
    /
   /  EER
  /
 /_____________________ FAR
0                      1.0
</code></pre></div>
</div>
</details>

<p><strong>Perch√© DIR &lt; GAR (a parit√† di FAR)?</strong></p>
<ol>
<li><strong>GAR</strong> (verifica): Accetta genuine che dichiarano identit√† corretta</li>
<li>Confronto 1:1 con template della identit√† dichiarata</li>
<li>
<p>Solo test: &ldquo;score abbastanza basso?&rdquo;</p>
</li>
<li>
<p><strong>DIR</strong> (open-set): Identifica correttamente enrolled al rank 1</p>
</li>
<li>Confronto 1:N con tutta la galleria</li>
<li>Test: &ldquo;score abbastanza basso?&rdquo; + &ldquo;√® il pi√π basso?&rdquo;</li>
<li>Pi√π restrittivo: altri template in galleria possono &ldquo;competere&rdquo;</li>
</ol>
<p><strong>Esempio numerico</strong>:</p>
<p>Sistema con soglia œÑ = 0.3:
- Probe genuine p con id(p) = A
  - Verifica: d(p, template_A) = 0.25 &lt; 0.3 ‚Üí Accept (GA contribuisce a GAR) ‚úì
  - Open-set: 
    - d(p, template_A) = 0.25 &lt; 0.3 ‚Üí Detection ‚úì
    - Ma d(p, template_B) = 0.22 &lt; d(p, template_A) ‚Üí ID = B (wrong!) ‚úó
    - Risultato: Non contribuisce a DIR, √® un FR</p>
<p>‚Üí Stesso probe, stessa soglia: successo in verifica, fallimento in open-set</p>
<p><strong>AUC-DIR</strong> (Area Under DIR curve):
$\text{AUC}_{\text{DIR}} = \int_0^1 \text{DIR}(t, 1) \, d(\text{FAR}(t))$</p>
<p>Tipicamente: AUC_DIR &lt; AUC_GAR per stesso algoritmo, perch√© identificazione √® pi√π difficile.</p>
<p><strong>Utilizzo pratico</strong>:
- Confronto algoritmi per applicazioni watchlist
- Selezione soglia operativa per specifiche FAR/DIR requirements
- Analisi robustezza al crescere della galleria (DIR degrada pi√π rapidamente di GAR)</p>
<h3 id="36-equal-error-rate-in-open-set">3.6 Equal Error Rate in Open-Set</h3>
<p><strong>Definizione</strong>:
$\text{EER}_{\text{open}} = \text{FAR}(\tau^*) = \text{FRR}(\tau^*)$</p>
<p>dove:
$\tau^* = \arg\min_\tau |\text{FAR}(\tau) - \text{FRR}(\tau)|$</p>
<p><strong>Relazione con DIR</strong>:
$\text{FRR}(\tau) = 1 - \text{DIR}(\tau, 1)$</p>
<p>quindi:
$\text{EER}_{\text{open}} = \text{FAR}(\tau^*) = 1 - \text{DIR}(\tau^*, 1)$</p>
<p>Al punto EER: $\text{FAR} = 1 - \text{DIR}$, ovvero $\text{DIR} = 1 - \text{FAR}$</p>
<p><strong>Interpretazione</strong>:
- Open-set EER tipicamente pi√π alto di verification EER (task pi√π difficile)
- Sistema eccellente: EER &lt; 2%
- Sistema buono: EER 2-5%
- Sistema accettabile: EER 5-10%
- Sistema scadente: EER &gt; 10%</p>
<p><strong>Esempio comparative</strong>:</p>
<table>
<thead>
<tr>
<th>Sistema</th>
<th>Verification EER</th>
<th>Open-Set EER</th>
<th>Degradazione</th>
</tr>
</thead>
<tbody>
<tr>
<td>Face Recognition (Deep)</td>
<td>0.5%</td>
<td>1.5%</td>
<td>3√ó</td>
</tr>
<tr>
<td>Fingerprint</td>
<td>1%</td>
<td>2.5%</td>
<td>2.5√ó</td>
</tr>
<tr>
<td>Iris</td>
<td>0.1%</td>
<td>0.3%</td>
<td>3√ó</td>
</tr>
</tbody>
</table>
<p>La degradazione (rapporto EER_open/EER_verif) √® tipicamente 2-4√ó, dipende dalla discriminativit√† del matcher e dalla dimensione della galleria.</p>
<h3 id="37-regioni-operative">3.7 Regioni Operative</h3>
<p>In applicazioni watchlist, si identificano 5 regioni operative tipiche, ciascuna adatta a contesti specifici.</p>
<p><strong>1. Extremely Low False Alarm</strong> ($\tau \to 0$, molto restrittivo):</p>
<p><strong>Caratteristiche</strong>:
- FAR ‚âà 0 (quasi nessun falso allarme)
- DIR basso (molti enrolled non vengono rilevati)
- Ogni allarme richiede azione immediata</p>
<p><strong>Applicazioni</strong>:
- Sorveglianza discreta in eventi pubblici
- Monitoraggio diplomatico (non si vuole allertare i soggetti)
- Sistemi dove investigating ogni allarme √® costoso</p>
<p><strong>Esempio</strong>: Sorveglianza durante visita diplomatica
- Watchlist: 50 potenziali minacce
- 100.000 persone monitorate
- FAR target: 0.001% ‚Üí ~1 falso allarme
- DIR tollerato: 60% ‚Üí 30/50 soggetti rilevati
- Obiettivo: minimizzare distur bo operativo, investigare solo alert reali</p>
<p><strong>2. Extremely High Detection</strong> ($\tau \to \infty$, molto permissivo):</p>
<p><strong>Caratteristiche</strong>:
- DIR ‚âà 1 (quasi tutti enrolled vengono rilevati)
- FAR alto (molti falsi allarmi)
- Priorit√†: non perdere nessun soggetto in watchlist</p>
<p><strong>Applicazioni</strong>:
- Border control (terrorismo)
- Ricerca latitanti
- Situazioni dove missing un soggetto ha conseguenze gravi</p>
<p><strong>Esempio</strong>: Controllo frontiera alta sicurezza
- Watchlist: 1000 terroristi noti
- 50.000 attraversamenti/giorno
- DIR target: 99.9% ‚Üí massimo 1 miss su 1000
- FAR tollerato: 2% ‚Üí 1000 falsi allarmi/giorno
- Obiettivo: catturare tutti, costo operativo secondario</p>
<p><strong>3. Low False Alarm + Moderate Detection</strong> (bilanciato conservativo):</p>
<p><strong>Caratteristiche</strong>:
- FAR basso ma non zero
- DIR accettabile (70-85%)
- Bilanciamento verso sicurezza operativa</p>
<p><strong>Applicazioni</strong>:
- Investigazioni ordinarie
- Sorveglianza eventi medi
- Risk management standard</p>
<p><strong>Esempio</strong>: Sorveglianza stazione ferroviaria
- Watchlist: 200 soggetti ricercati
- 200.000 passeggeri/giorno
- FAR target: 0.01% ‚Üí 20 falsi allarmi/giorno
- DIR target: 80% ‚Üí 160/200 rilevati se passano
- Obiettivo: gestibile da team di 3-4 operatori</p>
<p><strong>4. High Detection + Moderate False Alarm</strong> (bilanciato aggressivo):</p>
<p><strong>Caratteristiche</strong>:
- DIR alto (90-95%)
- FAR tollerabile (0.1-0.5%)
- Bilanciamento verso efficacia detection</p>
<p><strong>Applicazioni</strong>:
- Security screening aeroportuale
- Accessi ad aree critiche
- Situazioni con verifica secondaria disponibile</p>
<p><strong>Esempio</strong>: Pre-screening aeroportuale
- Watchlist: 5000 persone sospette
- 100.000 passeggeri/giorno
- FAR tollerato: 0.2% ‚Üí 200 falsi allarmi
- DIR target: 95% ‚Üí massimo 250 miss su 5000
- Verifica secondaria: controllo documenti per tutti gli alert
- Obiettivo: alta detection, false alarm gestiti da controlli successivi</p>
<p><strong>5. No Threshold</strong> (tutto logged):</p>
<p><strong>Caratteristiche</strong>:
- Nessuna soglia operativa
- Sistema restituisce tutto con confidence scores
- Post-processing umano/automatico</p>
<p><strong>Applicazioni</strong>:
- Investigazioni forensi
- Analisi retrospettiva
- Ricerca intelligence</p>
<p><strong>Esempio</strong>: Analisi post-evento criminalit√†
- Video sorveglianza di 72 ore
- Watchlist: 10000 persone di interesse
- Sistema: estrae tutti i volti, computa similarit√† con watchlist
- Output: ranked list con confidence per ogni detection
- Investigatori: filtrano manualmente basandosi su confidence + context
- Obiettivo: non perdere nessuna possibile corrispondenza</p>
<p><strong>Selezione della regione operativa</strong>:</p>
<p>La scelta dipende da:
1. <strong>Costi operativi</strong>: Quanto costa investigare un false alarm?
2. <strong>Conseguenze miss</strong>: Quanto √® grave non rilevare un soggetto?
3. <strong>Prevalenza</strong>: Quanti enrolled vs non-enrolled?
4. <strong>Verifica secondaria</strong>: Esistono controlli successivi?
5. <strong>Constraints legali</strong>: Privacy, proporzionalit√† misure</p>
<p><strong>Trade-off analysis</strong>:</p>
<table>
<thead>
<tr>
<th>Regione</th>
<th>FAR</th>
<th>DIR</th>
<th>Costo FA/giorno</th>
<th>Miss/anno</th>
<th>Preferita quando</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.001%</td>
<td>60%</td>
<td>Basso</td>
<td>Alto</td>
<td>Costo FA &gt;&gt; Costo miss</td>
</tr>
<tr>
<td>2</td>
<td>2%</td>
<td>99%</td>
<td>Molto alto</td>
<td>Bassissimo</td>
<td>Costo miss &gt;&gt; Costo FA</td>
</tr>
<tr>
<td>3</td>
<td>0.01%</td>
<td>80%</td>
<td>Moderato</td>
<td>Moderato</td>
<td>Bilanciato, risorse limitate</td>
</tr>
<tr>
<td>4</td>
<td>0.2%</td>
<td>95%</td>
<td>Moderato-alto</td>
<td>Basso</td>
<td>Verifica secondaria disponibile</td>
</tr>
<tr>
<td>5</td>
<td>N/A</td>
<td>100% (teorico)</td>
<td>Altissimo</td>
<td>Zero</td>
<td>Solo post-processing</td>
</tr>
</tbody>
</table>
<h2 id="4-identificazione-closed-set">4. Identificazione Closed-Set</h2>
<h3 id="41-definizione-del-task">4.1 Definizione del Task</h3>
<p>L&rsquo;identificazione closed-set √® una modalit√† operativa semplificata, irrealistica per applicazioni reali ma molto utile per valutazione di algoritmi di matching.</p>
<p><strong>Task di Identificazione Closed-Set</strong>: Dato un probe $p$:</p>
<p><strong>Assunzione forte</strong>: $\text{id}(p) \in \mathcal{G}$ (sempre, per definizione del task)</p>
<p><strong>Output</strong>: L&rsquo;identit√† $\hat{i} = \arg\min_{g \in \mathcal{G}} d(p, g)$</p>
<p><strong>Caratteristiche distintive</strong>:
- <strong>Nessuna soglia</strong> di accettazione/rigetto
- Sistema <strong>deve sempre</strong> restituire un&rsquo;identit√† dalla galleria
- Unico errore possibile: identit√† sbagliata al primo posto
- <strong>Non realistico</strong> per applicazioni reali (assunzione di probe sempre enrolled irrealistica)</p>
<p><strong>Perch√© √® usato?</strong>:
1. <strong>Valutazione pura del matcher</strong>: Isola la capacit√† discriminativa dell&rsquo;algoritmo di matching dalla scelta della soglia
2. <strong>Semplicit√†</strong>: Metriche pi√π semplici da calcolare e interpretare
3. <strong>Benchmark standard</strong>: Molti dataset pubblici usano protocollo closed-set per confronti
4. <strong>Upper bound</strong>: Fornisce performance massima teorica (best case) del sistema</p>
<p><strong>Uso principale</strong>: Ricerca accademica per confrontare algoritmi di feature extraction e matching. NON per deployment operativo.</p>
<p><strong>Limitazioni critiche</strong>:
- Ignora il problema della detection (soggetti non in galleria)
- Non modella false acceptances
- Performance closed-set &gt; open-set sempre (task pi√π facile)
- Risultati closed-set NON trasferibili direttamente a scenari operativi</p>
<h3 id="42-ranked-list-e-cumulative-match-score">4.2 Ranked List e Cumulative Match Score</h3>
<p>In closed-set, il concetto fondamentale √® la <strong>ranked list</strong>: lista ordinata di tutte le identit√† in galleria per similarit√† al probe.</p>
<p><strong>Procedura</strong>:
1. Calcola distanze: $\{d(p, g_i)\}_{i=1}^{|\mathcal{G}|}$
2. Ordina in ordine crescente (per distanze): $d_1 \leq d_2 \leq ... \leq d_{|\mathcal{G}|}$
3. Identifica rank della risposta corretta</p>
<p><strong>Definizione di Rank</strong>:
$\text{rank}(p) = \min\{k : \text{id}(g_k) = \text{id}(p)\}$</p>
<p>Posizione della <strong>prima occorrenza</strong> dell&rsquo;identit√† corretta nella lista ordinata.</p>
<p><strong>Esempio</strong>:</p>
<p>Probe p con id(p) = Alice
Galleria: {Alice, Bob, Charlie, David, Eve}</p>
<p>Ranked list dopo matching:
1. Bob (d = 0.15)
2. Alice (d = 0.18) ‚Üê identit√† corretta
3. Charlie (d = 0.23)
4. David (d = 0.29)
5. Eve (d = 0.35)</p>
<p>‚Üí rank(p) = 2 (Alice √® al secondo posto)</p>
<p><strong>Cumulative Match Score (CMS)</strong>:
$\text{CMS}(k) = \frac{|\{p \in \mathcal{P} : \text{rank}(p) \leq k\}|}{|\mathcal{P}|}$</p>
<p><strong>Interpretazione</strong>: Probabilit√† che l&rsquo;identit√† corretta appaia entro le prime $k$ posizioni.</p>
<p>Equivalentemente: percentuale di probe per cui l&rsquo;identit√† corretta √® al rank ‚â§ k.</p>
<p><strong>Casi speciali</strong>:</p>
<p><strong>CMS(1)</strong> = <strong>Recognition Rate (RR)</strong> = <strong>Rank-1 Accuracy</strong>:
$\text{RR} = \text{CMS}(1) = \frac{|\{p \in \mathcal{P} : \text{rank}(p) = 1\}|}{|\mathcal{P}|}$</p>
<p>Metrica pi√π importante in closed-set. Sistema con RR &lt; 90% considerato scadente.</p>
<p><strong>CMS(5)</strong>, <strong>CMS(10)</strong>: Spesso riportate per analisi completa
- Sistema con CMS(1)=85%, CMS(5)=95%, CMS(10)=98%
  ‚Üí Interpretazione: per 10% probe, identit√† corretta non √® top-1 ma appare entro top-5
  ‚Üí Utile per sistemi con human-in-the-loop (operatore verifica top-5)</p>
<p><strong>CMS($|\mathcal{G}|$) = 1</strong>: Sempre, per definizione di closed-set
  ‚Üí L&rsquo;identit√† corretta √® sempre da qualche parte nella lista</p>
<p><strong>Propriet√† di monotonicit√†</strong>:
$\text{CMS}(k_1) \leq \text{CMS}(k_2) \quad \forall k_1 < k_2$</p>
<p>La funzione √® monotona non-decrescente (logico: pi√π posizioni consideriamo, pi√π probe hanno identit√† corretta inclusa).</p>
<p><strong>Esempio pratico completo</strong>:</p>
<p>Dataset: 100 probe, galleria di 50 identit√†</p>
<table>
<thead>
<tr>
<th>Rank k</th>
<th># probe con rank‚â§k</th>
<th>CMS(k)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>82</td>
<td>0.82</td>
</tr>
<tr>
<td>2</td>
<td>90</td>
<td>0.90</td>
</tr>
<tr>
<td>3</td>
<td>93</td>
<td>0.93</td>
</tr>
<tr>
<td>5</td>
<td>96</td>
<td>0.96</td>
</tr>
<tr>
<td>10</td>
<td>98</td>
<td>0.98</td>
</tr>
<tr>
<td>20</td>
<td>99</td>
<td>0.99</td>
</tr>
<tr>
<td>50</td>
<td>100</td>
<td>1.00</td>
</tr>
</tbody>
</table>
<p>Interpretazione:
- 82% identificazioni corrette immediate (rank-1)
- 8% probe hanno identit√† corretta al rank 2
- 3% probe richiedono vedere top-3
- 2% probe richiedono top-5 o pi√π</p>
<p>Sistema valutazione:
- RR = 82%: buono ma non eccellente
- CMS(5) = 96%: se operatore pu√≤ verificare top-5, molto utile
- 2% probe hanno identit√† corretta oltre rank-5: casi difficili</p>
<h3 id="43-cumulative-match-characteristic-cmc">4.3 Cumulative Match Characteristic (CMC)</h3>
<p>La curva CMC √® la visualizzazione grafica della funzione CMS, strumento standard per presentare risultati closed-set.</p>
<p><strong>Definizione</strong>:</p>
<p>La curva CMC √® la funzione:
$\text{CMC}(k) = \text{CMS}(k), \quad k = 1, 2, \ldots, |\mathcal{G}|$</p>
<p><strong>Coordinate</strong>:
- <strong>Asse X</strong>: Rank $k$ (scala lineare, tipicamente 1-20 o log-scale per gallerie grandi)
- <strong>Asse Y</strong>: CMS($k$) = frazione probe con identit√† corretta entro rank k</p>
<p><strong>Propriet√† grafiche</strong>:
- Curva sempre <strong>crescente</strong> (o costante a tratti)
- Parte da CMS(1) = RR (punto pi√π importante)
- Arriva sempre a CMS($|\mathcal{G}|$) = 1 (estremo destro)
- Sistema migliore: curva che cresce pi√π velocemente (raggiunge valori alti con k piccolo)
- Curva ideale: verticale in k=1 (salto da 0 a 1 immediatamente)</p>
<p><strong>Visualizzazione tipica</strong>:</p>
<details class="code-container">
<summary>Code</summary>
<div class="code-wrapper">
<button class="copy-button" onclick="
                const code = this.parentElement.querySelector('pre');
                if (code) {
                    navigator.clipboard.writeText(code.innerText);
                    this.textContent = 'Copied!';
                    setTimeout(() => this.textContent = 'Copy', 2000);
                }
            ">Copy</button>
<div class="codehilite"><pre><span></span><code>CMS(k)
 1.0|                    Sistema A (migliore)
    |     _______________
    |    /               Sistema B
    |   /     ___
    |  /     /           Sistema C (peggiore)
    | /     /
    |/     /
    |     /
    |    /
 0.5|   /
    |  /
    |_/
    |/_________________
 0.0|__________________ Rank k
    1   5   10      50
</code></pre></div>
</div>
</details>

<p>Sistema A: RR=95%, sale rapidamente ‚Üí eccellente
Sistema B: RR=85%, sale moderatamente ‚Üí buono
Sistema C: RR=70%, sale lentamente ‚Üí scadente</p>
<p><strong>Area Under CMC (AUC-CMC)</strong>:
$\text{AUC}_{\text{CMC}} = \sum_{k=1}^{|\mathcal{G}|} \text{CMS}(k)$</p>
<p><strong>Range</strong>: $[0, |\mathcal{G}|]$</p>
<p><strong>Interpretazione</strong>: Somma di tutti i CMS. Sistema perfetto avrebbe AUC = |G| (CMS=1 per tutti i rank).</p>
<p><strong>Versione normalizzata</strong>:
$\text{nAUC}_{\text{CMC}} = \frac{\text{AUC}_{\text{CMC}}}{|\mathcal{G}|} \in [0, 1]$</p>
<p>Normalizza per dimensione galleria, permette confronto tra dataset con |G| diverse.</p>
<p><strong>Interpretazione alternativa di nAUC</strong>: Mean rank atteso normalizzato (inversamente).
- nAUC vicino a 1: rank medi bassi (buono)
- nAUC vicino a 0.5: rank medi alti (scadente)</p>
<p><strong>Esempio calcolo</strong>:</p>
<p>Galleria: 10 identit√†
CMS values: [0.6, 0.7, 0.8, 0.85, 0.9, 0.93, 0.95, 0.97, 0.98, 1.0]</p>
<p>AUC = 0.6 + 0.7 + 0.8 + 0.85 + 0.9 + 0.93 + 0.95 + 0.97 + 0.98 + 1.0 = 8.68
nAUC = 8.68 / 10 = 0.868</p>
<p><strong>Confronto multi-sistema</strong>:</p>
<table>
<thead>
<tr>
<th>Sistema</th>
<th>RR (rank-1)</th>
<th>CMS(5)</th>
<th>CMS(10)</th>
<th>nAUC</th>
</tr>
</thead>
<tbody>
<tr>
<td>DeepFace</td>
<td>97.4%</td>
<td>99.2%</td>
<td>99.8%</td>
<td>0.985</td>
</tr>
<tr>
<td>FaceNet</td>
<td>95.1%</td>
<td>98.7%</td>
<td>99.5%</td>
<td>0.972</td>
</tr>
<tr>
<td>Traditional</td>
<td>78.3%</td>
<td>88.9%</td>
<td>94.2%</td>
<td>0.891</td>
</tr>
</tbody>
</table>
<p>Tutti i numeri concordano: DeepFace &gt; FaceNet &gt; Traditional</p>
<p><strong>Utilizzo pratico della CMC</strong>:</p>
<ol>
<li><strong>Rank-1 (RR)</strong>: Metrica principale per sistemi fully automatic</li>
<li><strong>Rank-5 o Rank-10</strong>: Per sistemi semi-automatic con human verification</li>
<li><strong>Forma della curva</strong>: Diagnostica robustezza</li>
<li>Curva molto ripida dopo rank-1: pochi casi ambigui</li>
<li>Curva graduale: molti probe hanno multiple identit√† simili</li>
<li><strong>nAUC</strong>: Metrica scalare per confronto rapido, meno influenzata da outlier di RR</li>
</ol>
<p><strong>Attenzione</strong>: CMC non fornisce informazioni su:
- Performance con probe non in galleria (by definition, tutti sono in galleria)
- Trade-off FAR vs FRR (nessuna soglia)
- Robustezza a impostori (nessun impostor scenario)</p>
<h3 id="44-confronto-tra-modalita">4.4 Confronto tra Modalit√†</h3>
<p>Riassunto comparativo delle tre modalit√† operative principali.</p>
<table>
<thead>
<tr>
<th><strong>Aspetto</strong></th>
<th><strong>Verifica</strong></th>
<th><strong>Open-Set</strong></th>
<th><strong>Closed-Set</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Claim</strong></td>
<td>S√¨ (esplicito o implicito)</td>
<td>No</td>
<td>No</td>
</tr>
<tr>
<td><strong>Confronti</strong></td>
<td>1:1 (probe vs claimed ID)</td>
<td>1:N (probe vs galleria)</td>
<td>1:N (probe vs galleria)</td>
</tr>
<tr>
<td><strong>Soglia</strong></td>
<td>S√¨ (critica)</td>
<td>S√¨ (critica)</td>
<td>No</td>
</tr>
<tr>
<td><strong>Possibili FA</strong></td>
<td>S√¨ (impostor accepted)</td>
<td>S√¨ (false alarm)</td>
<td>No (by definition)</td>
</tr>
<tr>
<td><strong>Possibili FR</strong></td>
<td>S√¨ (genuine rejected)</td>
<td>S√¨ (missed + misID)</td>
<td>Solo misID (ranked)</td>
</tr>
<tr>
<td><strong>Metrica primaria</strong></td>
<td>FAR, FRR, EER</td>
<td>DIR, FAR, EER</td>
<td>CMS(k), RR</td>
</tr>
<tr>
<td><strong>Curva principale</strong></td>
<td>ROC (GAR vs FAR)</td>
<td>Open-Set ROC (DIR vs FAR)</td>
<td>CMC (CMS vs rank)</td>
</tr>
<tr>
<td><strong>Realismo applicativo</strong></td>
<td>Alto</td>
<td>Alto</td>
<td>Basso</td>
</tr>
<tr>
<td><strong>Complessit√† computazionale</strong></td>
<td>Bassa O(1)</td>
<td>Alta O(N)</td>
<td>Alta O(N)</td>
</tr>
<tr>
<td><strong>Uso principale</strong></td>
<td>Accesso personale</td>
<td>Watchlist, sorveglianza</td>
<td>Ricerca, benchmark</td>
</tr>
</tbody>
</table>
<p><strong>Relazioni di difficolt√†</strong>:</p>
<p>Per stesso matcher e dataset:
$\text{Accuracy}_{\text{closed-set}} \geq \text{Accuracy}_{\text{open-set}} \geq \text{Accuracy}_{\text{verification}}$</p>
<p>(in termini di successo relativo)</p>
<p>Perch√©:
- Closed-set: nessuna detection, identit√† sempre presente
- Open-set: detection richiesta, ma 1:N confronto
- Verification: deve anche gestire claim checking, ma 1:1 facilita</p>
<p><strong>In termini di EER</strong> (quando comparabile):
$\text{EER}_{\text{closed-set}} \leq \text{EER}_{\text{open-set}}$</p>
<p><strong>Esempio numerico</strong>:</p>
<p>Sistema face recognition su stesso dataset:</p>
<table>
<thead>
<tr>
<th>Modalit√†</th>
<th>Metrica</th>
<th>Valore</th>
<th>Interpretazione</th>
</tr>
</thead>
<tbody>
<tr>
<td>Verification</td>
<td>EER</td>
<td>2%</td>
<td>Baseline</td>
</tr>
<tr>
<td>Verification</td>
<td>FAR @ FRR=1%</td>
<td>0.1%</td>
<td>Security setting</td>
</tr>
<tr>
<td>Open-Set</td>
<td>EER</td>
<td>5%</td>
<td>Pi√π difficile (detection+ID)</td>
</tr>
<tr>
<td>Open-Set</td>
<td>DIR @ FAR=0.1%</td>
<td>88%</td>
<td>Watchlist setting</td>
</tr>
<tr>
<td>Closed-Set</td>
<td>RR (rank-1)</td>
<td>94%</td>
<td>Best case (no detection)</td>
</tr>
<tr>
<td>Closed-Set</td>
<td>CMS(5)</td>
<td>98%</td>
<td>Top-5 accuracy</td>
</tr>
</tbody>
</table>
<p><strong>Quando usare quale modalit√†?</strong>:</p>
<p><strong>Verifica</strong>:
- Smartphone unlock
- Laptop login
- Physical access control (badge + biometric)
- ATM authentication</p>
<p><strong>Open-Set</strong>:
- Airport watchlist
- Casino excluded persons
- Retail loss prevention
- Missing person search</p>
<p><strong>Closed-Set</strong>:
- Research paper benchmarks
- Algorithm development
- Competition leaderboards
- Academic datasets (LFW, IJB-C, etc.)</p>
<p><strong>NON usare closed-set per</strong>:
- System procurement decisions (irrealisticamente ottimistico)
- Real-world deployments (manca detection component)
- Security analysis (ignora false acceptances)</p>
<h2 id="5-metodologie-di-valutazione-offline">5. Metodologie di Valutazione Offline</h2>
<h3 id="51-principi-generali">5.1 Principi Generali</h3>
<p>La valutazione offline √® il processo di testing di un sistema biometrico usando dataset statici con ground truth noto, prima del deployment operativo.</p>
<p><strong>Valutazione offline</strong>: Testing su dataset statici con <strong>ground truth</strong> noto per ogni campione.</p>
<p><strong>Requisiti fondamentali</strong>:
- Ogni campione ha label corretta nota (identit√† vera)
- Nessun vincolo temporale (possiamo ripetere esperimenti)
- Permette analisi sistematica e riproducibile
- Consente confronto equo tra algoritmi diversi</p>
<p><strong>Importanza critica</strong>: In operazione reale, l&rsquo;identit√† del probe potrebbe essere sconosciuta (questo √® il punto!). La valutazione offline stima l&rsquo;affidabilit√† del sistema <strong>prima</strong> del deployment, evitando di scoprire problemi in produzione.</p>
<p><strong>Differenza online vs offline</strong>:</p>
<p><strong>Online (produzione)</strong>:
- Ground truth sconosciuto (eccetto per audit/logging)
- Decisioni immediate richieste
- Costi di errore reali (sicurezza, usabilit√†)
- Impossibile ripetere condizioni esatte
- Difficile debugging</p>
<p><strong>Offline (valutazione)</strong>:
- Ground truth disponibile
- Tempo illimitato per analisi
- Simulazione di costi di errore
- Ripetibilit√† completa
- Facile debugging e ottimizzazione</p>
<p><strong>Obiettivi valutazione offline</strong>:
1. <strong>Stimare performance</strong> aspettata in operazione
2. <strong>Confrontare algoritmi</strong> in condizioni controllate
3. <strong>Ottimizzare parametri</strong> (soglie, feature extraction, ecc.)
4. <strong>Identificare failure modes</strong> (quali probe causano errori)
5. <strong>Certificare compliance</strong> con standard (ISO/IEC 19795, NIST, etc.)</p>
<h3 id="52-partizionamento-dei-dati">5.2 Partizionamento dei Dati</h3>
<p>Il partizionamento corretto dei dati √® fondamentale per ottenere stime affidabili di performance. Partizionamenti errati portano a sovrastima dell&rsquo;accuratezza (overfitting).</p>
<h4 id="training-vs-testing-trts">Training vs Testing (TR/TS)</h4>
<p><strong>Regola fondamentale</strong>: 
$\text{TR} \cap \text{TS} = \emptyset$</p>
<p>Nessun campione pu√≤ apparire sia in training che in testing.</p>
<p><strong>Partizionamento basato su soggetti</strong> (preferito e pi√π rigoroso):
- Alcuni soggetti <strong>solo in training</strong>: usati per apprendere modello
- Altri soggetti <strong>solo in testing</strong>: mai visti dal modello
- Valuta <strong>generalizzazione</strong> a nuovi individui (obiettivo reale del sistema)
- Pi√π realistico: in deployment, sistema vedr√† persone nuove</p>
<p>Esempio:
- Dataset 1000 persone, 10 immagini/persona
- Training: 700 persone (7000 immagini)
- Testing: 300 persone (3000 immagini)
- Zero overlap tra identit√†</p>
<p><strong>Partizionamento basato su campioni</strong> (meno rigoroso):
- Stesso soggetto pu√≤ apparire in entrambi i set
- Campioni diversi dello stesso soggetto per TR e TS
- Meno robusto: rischio di overfitting all&rsquo;identit√†
- Utilizzabile quando soggetti scarsi ma campioni abbondanti</p>
<p>Esempio:
- Dataset 100 persone, 100 immagini/persona
- Training: 70 immagini/persona (7000 tot)
- Testing: 30 immagini/persona (3000 tot)
- Stesse identit√†, immagini diverse</p>
<p><strong>Training set composition</strong>: Deve avere:</p>
<ol>
<li><strong>Alta variabilit√†</strong> (esposizione a diverse condizioni):</li>
<li>Pose: frontal, profile, ¬±45¬∞</li>
<li>Illuminazione: indoor, outdoor, artificial, natural</li>
<li>Espressioni: neutral, smile, surprise</li>
<li>Accessori: glasses, hats, scarves</li>
<li>
<p>Qualit√†: sharp, blurred, low-resolution</p>
</li>
<li>
<p><strong>Campioni di qualit√† diversa</strong>:</p>
</li>
<li>Non solo immagini perfette</li>
<li>Include degradazioni realistiche</li>
<li>
<p>Simula condizioni operative</p>
</li>
<li>
<p><strong>Rappresentativit√† della popolazione target</strong>:</p>
</li>
<li>Distribuzione et√†, gender, etnia simile al deployment</li>
<li>Evita bias: training solo su giovani caucasici, testing su anziani asiatici</li>
<li>Balanced representation</li>
</ol>
<p><strong>Esempio fallimento</strong>:
- Training: Solo immagini indoor, frontal, alta risoluzione
- Testing: Immagini outdoor, profile, bassa risoluzione
- Risultato: Performance crolla (train/test mismatch)</p>
<p><strong>Rule of thumb</strong>:
- Training: 60-80% dei soggetti (o campioni se subject-based impossibile)
- Testing: 20-40% dei soggetti
- MAI testare su training data (overfitting)</p>
<h4 id="gallery-vs-probe-gp">Gallery vs Probe (G/P)</h4>
<p>Partizionamento interno al test set, specifico per modalit√† operative biometriche.</p>
<p><strong>Regola</strong>: 
$\mathcal{G} \cap \mathcal{P} = \emptyset \quad \text{(per i template, non per le identit√†)}$</p>
<p>Stesso soggetto pu√≤ avere template in galleria E probe nel probe set, ma <strong>template diversi</strong>.</p>
<p><strong>Composizione della Gallery</strong>:</p>
<p><strong>Strategia 1 - High-quality enrollment</strong> (pi√π realistica):
- Template acquisiti in condizioni controllate
- Simula enrollment reale in sistema operativo
- Esempio: foto ID card, acquisizione in ufficio
- Pro: realismo alto
- Contro: probe low-quality vs gallery high-quality (scenario difficile ma reale)</p>
<p><strong>Strategia 2 - Multiple conditions</strong>:
- Template con diverse condizioni per ciascuna identit√†
- Aumenta robustezza del matcher
- Esempio: frontal + profile, indoor + outdoor per ogni ID
- Pro: performance migliori
- Contro: pu√≤ sovrastimare performance operative (enrollment reale √® mono-condition)</p>
            </div>
            
            <footer style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #eee;">
                <p><strong>Keywords:</strong> machine learning, introduction, basics, fundamentals, AI, algorithm, model, data</p>
                <p><small>This is the SEO-optimized version. <a href="http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics">Click here for the interactive experience</a>.</small></p>
            </footer>
        </article>
    </div>
    
    <!-- Vercel Analytics (opzionale) -->
    <script>
      // Track SEO page views
      if (window.gtag) {
        gtag('config', 'GA_TRACKING_ID', {
          page_title: 'Metriche Biometriche per Classificazione in Machine Learning',
          page_location: 'http://localhost:3000/theory/introduction/Tipologie di Problemi/Classificazione/Biometric Metrics'
        });
      }
    </script>
</body>
</html>