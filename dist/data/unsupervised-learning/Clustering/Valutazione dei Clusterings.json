{
  "title": "Untitled",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<h2 id=\"introduzione\">Introduzione</h2>\n<p>La valutazione di un algoritmo di clustering è una fase cruciale per determinare la qualità delle partizioni generate rispetto ai dati.</p>\n<p>Esistono due principali approcci per valutare un clustering.</p>\n<h3 id=\"valutazione-esterna-external-evaluation\">Valutazione Esterna (External Evaluation)</h3>\n<p>La valutazione esterna confronta i risultati del clustering con una &ldquo;verità di base&rdquo; (ground truth o gold standard base) predefinita, ovvero un insieme di etichette o partizioni conosciute. Questo approccio misura quanto il clustering trovato sia coerente con la classificazione reale. È solitamente meno utilizzato in quanto è difficile che ci siano conoscenze a priori delle etichette dei dati se si vuole fare clustering. Metriche comuni includono:\n- <strong>Purezza (purity)</strong>: Siano:\n    - $C_i, \\cdots, C_K$ i clusters.\n    - $L_1, \\cdots, L_J$ le labels conosciute a priori.\n    - $n_{i, j}$ il numero degli items con label $j$ nel cluster $C_i$\n    - $\\sum_{j=1}^J n_{i, j} = n_i$ ovviamente il numero di elementi nel cluster $C_i$.\n    La purezza $P(C_i)$ di un certo cluster $C_i$ è calcolata come\n    $$\n\tP(C_i) = \\frac{1}{n_i} \\max_{j \\in [J]} n_{i, j}\n\t$$\n    Cioè la label che appare più volte nel cluster $C_i$ diviso la dimensione del cluster stesso.</p>\n<div class=\"codehilite\"><pre><span></span><code>Ovviamente, la purezza totale del clustering, è data dalla media aritmetica delle purezze dei clusters:\n$$\n\tP = \\frac{1}{K} \\sum_{k=1}^K P(C_k)\n\t$$\nC&#39;è comunque un problema di bias, in quanto la purezza cresce all&#39;aumentare del numero di clusters.\n</code></pre></div>\n\n<ul>\n<li>\n<p><strong>Rand Index</strong>: Misura il livello di coerenza tra il clustering e il ground truth. \n    $$\n\t\\begin{array}{c|c|c|c} & \\textbf{Stessa Classe in Ground Truth} & \\textbf{Classi Diverse in Ground Truth} & \\textbf{Totale} \\\\ \\hline \\textbf{Stessa Classe in Clustering} & a & b & a + b \\\\ \\textbf{Classi Diverse in Clustering} & c & d & c + d \\\\ \\hline \\textbf{Totale} & a + c & b + d & N \\end{array}\n\t$$\n    <strong>Legenda</strong>: </p>\n<ul>\n<li>$a$: True Positive. </li>\n<li>$b$: False Positive. </li>\n<li>$c$: False Negative. </li>\n<li>$d$: True negative.\nIl Rand-Index equivale all&rsquo;accuracy delle predizioni, quindi:\n$$\n\t\\text{RI} = \\frac{a + d}{a + b + c + d} = \\frac{a + d}{N} = \\frac{\\text{Previsioni giuste}}{\\text{Previsioni totali}}\n\t$$</li>\n</ul>\n<h2 id=\"metriche-di-valutazione-per-il-rand-index\">Metriche di Valutazione per il Rand Index</h2>\n<p>Oltre al Rand Index, possiamo calcolare altre metriche di valutazione basate sulla matrice di confusione:</p>\n<p><strong>Precision</strong>\nLa precisione misura la frazione di coppie correttamente identificate come appartenenti allo stesso cluster rispetto a tutte quelle assegnate allo stesso cluster:\n$$\n\t\\text{Precision} = \\frac{a}{a + b}.\n\t$$</p>\n<p><strong>Recall</strong>\nIl recall misura la frazione di coppie nello stesso cluster nella ground truth che sono state assegnate correttamente allo stesso cluster nel clustering:\n$$\n\t\\text{Recall} = \\frac{a}{a + c}.\n\t$$</p>\n<p><strong>F1-score</strong>\nL&rsquo;<strong>F1-Score</strong> è la media armonica tra precision e recall:\n$$\n\t\\text{F1-Score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} = \\frac{2a}{2a + b + c}.\n\t$$</p>\n<p><strong>F$\\beta$-Score</strong>\nL&rsquo;<strong>F$\\beta$-Score</strong> è una generalizzazione dell&rsquo;F1-Score, che permette di dare più peso alla precision o al recall. È definito come:\n$$\n\tF_\\beta = \\frac{(1 + \\beta^2) \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\beta^2 \\cdot \\text{Precision} + \\text{Recall}}.\n\t$$\nSostituendo precision e recall:\n$$\n\tF_\\beta = \\frac{(1 + \\beta^2) \\cdot a}{(1 + \\beta^2) \\cdot a + \\beta^2 \\cdot b + c}.\n\t$$</p>\n<h3 id=\"considerazioni\">Considerazioni</h3>\n<ul>\n<li>Quando $\\beta = 1$, l&rsquo;$F_\\beta$-Score diventa equivalente all&rsquo;F1-Score.</li>\n<li>Quando $\\beta > 1$, viene data più importanza al recall.</li>\n<li>\n<p>Quando $\\beta < 1$, viene data più importanza alla precision.</p>\n</li>\n<li>\n<p><strong>Adjusted Rand Index (ARI)</strong>: Valuta la similarità tra le partizioni considerando correzioni per la casualità.</p>\n</li>\n<li><strong>Normalized Mutual Information (NMI)</strong>: Misura la dipendenza statistica tra le partizioni trovate e quelle della ground truth.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"valutazione-interna-internal-evaluation\">Valutazione Interna (Internal Evaluation)</h3>\n<p>La valutazione interna si basa esclusivamente sui dati e sui risultati del clustering, senza fare riferimento a etichette esterne. Questo approccio mira a misurare la coesione interna ai cluster (quanto i punti all&rsquo;interno di un cluster sono vicini tra loro) e la separazione tra cluster distinti. </p>\n<p>In generale, un clustering è considerato &ldquo;buono&rdquo; se i suoi cluster hanno:\n- Alta similarità intra-cluster (i data points in ogni cluster sono vicini).\n- Bassa similarità inter-cluster (i clusters sono ben separati tra di loro).\nLa qualità di un clustering quindi dipende sia dalla rappresentazione dei dati e sia dalla metrica di similarità utilizzata.</p>\n<p>Metriche comuni includono:</p>\n<ul>\n<li><strong>Davies-Bouldin Index</strong>: il Davies-Bouldin Index (DBI) è una metrica di valutazione interna per il clustering che misura la qualità dei cluster basandosi sulla compattezza e sulla separabilità dei cluster stessi. Un valore più basso del DBI indica cluster più compatti e meglio separati, quindi un clustering più efficace. È calcolato come segue:\n  $$\n  DBI = \\frac{1}{K} \\sum_{i=1}^K \\max_{j \\neq i} \\left(\\frac{\\sigma_i + \\sigma_j}{\\delta(\\vec \\mu_i, \\vec \\mu_j)} \\right)\n   $$\n   Dove:</li>\n<li>$K$ è il numero di clusters</li>\n<li>$\\vec \\mu_k$ è il centroide del cluster $C_k$</li>\n<li>$\\sigma_k$ è la distanza media di tutti gli elementi del cluster $C_k$ dal suo centroide $\\mu_k$.</li>\n<li>\n<p>$\\delta(\\vec \\mu_i, \\vec \\mu_j) = \\delta(\\vec \\Theta_i, \\vec \\Theta_j)$ è la distanza tra il centroide del cluster $C_i$ e quello del cluster $C_j$.</p>\n</li>\n<li>\n<p><strong>Dunn Index</strong>: Il Dunn Index è una metrica di valutazione interna per il clustering che misura il rapporto tra la minima distanza tra cluster distinti (separabilità) e la massima distanza interna a un cluster (compattezza). Un valore più alto del Dunn Index indica un clustering migliore, con cluster ben separati e poco dispersi. Si calcola come segue:\n  $$\n  D = \\frac{\\min_{1 \\leq i \\leq j \\leq K} \\delta(\\vec \\Theta_i, \\vec \\Theta_j)}{\\max_{1 \\leq k \\leq K} \\delta'(\\vec \\Theta_k)}\n  $$\n  Dove:</p>\n</li>\n<li>$K$ è il numero di clusters</li>\n<li>$\\vec \\Theta_k$ è il centroide del cluster $C_k$</li>\n<li>$\\sigma_k$ è la distanza media di tutti gli elementi del cluster $C_k$ dal suo centroide $\\mu_k$.</li>\n<li>$\\delta(\\vec \\Theta_i, \\vec \\Theta_j)$ è la distanza tra il centroide del cluster $C_i$ e quello del cluster $C_j$.</li>\n<li>\n<p>$\\delta'(\\vec \\Theta_k)$ è la distanza massima tra due punti nel cluster $k$.</p>\n</li>\n<li>\n<p><strong>Silhouette Score</strong>: Combina coesione e separazione per ogni punto e calcola un valore medio. \n  Dato un punto dati $i \\in C_I$, definiamo il coefficiente $a(i)$ come la media delle distanze tra $i$ e tutti gli altri data points nel cluster $C_I$. Calcolata come:\n  $$\n  a(i) = \\frac{1}{|C_I| -1} \\sum_{j \\in C_I \\setminus \\{i\\}} \\delta(i, j)\n   $$\n   Possiamo interpretare il valore $a(i)$ come una misura di quanto abbiamo sbagliato ad assegnare il punto $i$ al cluster $C_I$. Questo è un modo per valutare la similarità intra-cluster.</p>\n</li>\n</ul>\n<p>!<span class=\"text-gray-600\">300</span>\n   Analogamente, possiamo definire una media di diversità del punto $i$ con un certo cluster $C_J$ come la media delle distanze tra $i$ e tutti i punti nel cluster $C_J$, dove ovviamente $C_I \\neq C_J$: \n  $$\n   b(i) = \\min_{J \\in [K] \\setminus \\{i\\}} \\frac{1}{|C_J|} \\sum_{j \\in C_J} \\delta(i, j)\n   $$\n   $b(i)$ è la più piccola distanza media tra $i$ e tutti i punti negli altri cluster. Il cluster $C_J$ che minimizza questa media di distanze è detto cluster &ldquo;vicino&rdquo; (neighboring cluster) di $i$ perché è il cluster migliore, dopo $C_I$, che lo possa ospitare.\n   !<span class=\"text-gray-600\">silhouette_b.svg</span></p>\n<p>Ora possiamo finalmente definire il <strong>silhouette score</strong> $S(i)$ definito come:\n   $$\n   S(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n   $$\n   Quindi ora abbiamo che:\n   $$\n   S(i) = \\begin{cases}\n   1 - \\frac{a(i)}{b(i)} \\quad &\\text{se} \\ \\  a(i) < b(i)\\\\\n   0 \\quad &\\text{se} \\ \\  a(i) = b(i)\\\\\n   \\frac{b(i)}{a(i)} - 1 \\quad &\\text{se} \\ \\  a(i) > b(i)\n   \\end{cases}\n   $$\n   Dalla formula, appare chiaro che $-1 \\leq S(i) \\leq 1 \\ \\ \\forall i$ .\n   Notiamo inoltre che $a(i)$ non è chiaramente definito quando $|C_I| = 1$, quindi in questo caso poniamo $S(i) = 0$.</p>\n<p>Un <strong>silhouette score</strong> alto è indice di un buon clustering, uno basso il contrario.</p>\n<p>L&rsquo;obiettivo della valutazione è garantire che i risultati del clustering siano significativi e utili per il problema specifico in analisi, tenendo conto delle caratteristiche intrinseche dei dati.</p>"
}