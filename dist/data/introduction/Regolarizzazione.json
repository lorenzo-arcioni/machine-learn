{
  "title": "Regolarizzazione",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<p>La <strong>regolarizzazione</strong> è una tecnica utilizzata per prevenire l&rsquo;overfitting nei modelli di machine learning, aggiungendo un termine di penalità alla funzione di perdita. Questo termine di penalità controlla la complessità del modello, limitando la crescita dei parametri e migliorando la generalizzazione su dati non visti. Di seguito esploriamo i diversi tipi di regolarizzazione, il loro funzionamento e il loro impatto sui modelli.</p>\n<h2 id=\"introduzione-alla-regolarizzazione\"><strong>Introduzione alla Regolarizzazione</strong></h2>\n<p>L&rsquo;<a href=\"/theory/introduction/Overfitting e Underfitting\" class=\"text-blue-600 hover:underline\">overfitting</a> si verifica quando un modello è troppo complesso e si adatta eccessivamente ai dati di training, catturando anche il rumore presente nei dati. Questo porta a un errore basso sui dati di training, ma a un errore elevato sui dati di validazione. La regolarizzazione aiuta a mitigare questo problema aggiungendo un termine di penalità alla funzione di perdita che limita la crescita dei parametri del modello.</p>\n<h2 id=\"tipi-di-regolarizzazione\"><strong>Tipi di Regolarizzazione</strong></h2>\n<h3 id=\"1-regolarizzazione-l2-ridge-regression-o-tikhonov-o-weight-decay\"><strong>1. Regolarizzazione L2 (Ridge Regression o Tikhonov o weight decay)</strong></h3>\n<p>La regolarizzazione L2, nota anche come <strong>Ridge Regression</strong>, aggiunge un termine di penalità basato sulla norma L2 (o norma Frobenius per le matrici) dei parametri. La funzione di perdita regolarizzata è data da:</p>\n$$\n\\argmin_{\\Theta} \\ell_{\\Theta} + \\lambda \\|\\Theta\\|_2^2\n$$\n<p>Dove:\n- $\\ell_{\\Theta}$ è la funzione di perdita originale (ad esempio, l&rsquo;errore quadratico medio).\n- $\\|\\Theta\\|_2^2$ è la norma L2 al quadrato dei parametri $\\Theta$.\n- $\\lambda$ è un parametro di regolarizzazione che controlla il trade-off tra l&rsquo;adattamento ai dati e la penalità.</p>\n<h4 id=\"effetto-della-regolarizzazione-l2\"><strong>Effetto della Regolarizzazione L2</strong></h4>\n<ul>\n<li><strong>Shrinkage</strong>: La regolarizzazione L2 riduce i valori dei parametri, ma non li azzera completamente. Questo è utile per controllare la complessità del modello senza eliminare completamente alcune feature.</li>\n<li><strong>Convessità</strong>: La norma L2 è una funzione convessa, quindi la funzione di perdita regolarizzata rimane convessa, garantendo l&rsquo;esistenza di un minimo globale.</li>\n</ul>\n<h3 id=\"2-regolarizzazione-l1-lasso-regression\"><strong>2. Regolarizzazione L1 (Lasso Regression)</strong></h3>\n<p>La regolarizzazione L1, nota anche come <strong>Lasso Regression</strong>, aggiunge un termine di penalità basato sulla norma L1 dei parametri. La funzione di perdita regolarizzata è data da:</p>\n$$\n\\argmin_{\\Theta} \\ell_{\\Theta} + \\lambda \\|\\Theta\\|_1\n$$\n<p>Dove:\n- $\\|\\Theta\\|_1$ è la norma L1 dei parametri $\\Theta$, definita come la somma dei valori assoluti dei parametri.</p>\n<h4 id=\"effetto-della-regolarizzazione-l1\"><strong>Effetto della Regolarizzazione L1</strong></h4>\n<ul>\n<li><strong>Sparsità</strong>: La regolarizzazione L1 tende a produrre modelli sparsi, cioè modelli in cui molti parametri sono esattamente zero. Questo è utile per la selezione delle feature, poiché elimina le feature irrilevanti.</li>\n<li><strong>Push Uniforme</strong>: La regolarizzazione L1 applica una spinta uniforme verso zero per tutti i parametri, indipendentemente dalla loro grandezza.</li>\n</ul>\n<h3 id=\"3-elastic-net\"><strong>3. Elastic Net</strong></h3>\n<p>L&rsquo;<strong>Elastic Net</strong> combina la regolarizzazione L1 e L2, offrendo un compromesso tra sparsity e shrinkage. La funzione di perdita regolarizzata è data da:</p>\n$$\n\\argmin_{\\Theta} \\ell_{\\Theta} + \\lambda_1 \\|\\Theta\\|_1 + \\lambda_2 \\|\\Theta\\|_2^2\n$$\n<p>Dove:\n- $\\lambda_1$ e $\\lambda_2$ sono parametri di regolarizzazione che controllano il trade-off tra la regolarizzazione L1 e L2.</p>\n<h4 id=\"effetto-dellelastic-net\"><strong>Effetto dell&rsquo;Elastic Net</strong></h4>\n<ul>\n<li><strong>Sparsità e Shrinkage</strong>: L&rsquo;Elastic Net combina i vantaggi della regolarizzazione L1 (sparsity) e L2 (shrinkage), rendendolo utile quando le feature sono correlate tra loro.</li>\n</ul>\n<h2 id=\"intuizione-sui-gradienti\"><strong>Intuizione sui Gradienti</strong></h2>\n<p>Per comprendere perché la regolarizzazione L1 e L2 hanno effetti diversi, consideriamo il gradiente dei termini di regolarizzazione rispetto a un singolo parametro $\\theta$:</p>\n<h3 id=\"regolarizzazione-l1\"><strong>Regolarizzazione L1</strong></h3>\n<p>Dato che la regolarizzazione L1 non è derivabile in $\\theta = 0$, il gradiente viene definito come:\n$$\n\\frac{\\partial}{\\partial \\theta} (\\lambda \\|\\Theta\\|_1) = \n\\begin{cases}\n\\lambda, & \\theta > 0 \\\\\n-\\lambda, & \\theta < 0\n\\end{cases}\n$$</p>\n<p>secondo il concetto di <a href=\"/theory/math-for-ml/Calcolo/Sottoderivata e Sottogradiente\" class=\"text-blue-600 hover:underline\">Sottoderivata e Sottogradiente</a>.</p>\n<h3 id=\"regolarizzazione-l2\"><strong>Regolarizzazione L2</strong></h3>\n$$\n\\frac{\\partial}{\\partial \\theta} (\\lambda \\|\\Theta\\|_2^2) = 2\\lambda \\theta\n$$\n<ul>\n<li><strong>L1</strong>: Applica una spinta costante ($\\lambda$ o $-\\lambda$) verso zero, indipendentemente dal valore di $\\theta$.</li>\n<li><strong>L2</strong>: Applica una spinta proporzionale al valore di $\\theta$, portando i parametri più grandi a ridursi più rapidamente.</li>\n</ul>\n<h4 id=\"come-cambia-la-normal-equation-qando-si-applica-regolarizzazione-math_inline_27\">Come cambia la normal equation qando si applica regolarizzazione $L_2$?</h4>\n<p>La funzione di errore da minimizzare diventa:\n$$\n\\ell(\\mathbf{W}) = \\|\\mathbf{Y} - \\mathbf{X} \\mathbf{W}\\|_2^2 + \\lambda \\|\\mathbf{W}\\|_2^2\n$$</p>\n<p>Espandiamo la norma euclidea:</p>\n$$\n\\ell(\\mathbf{W}) = (\\mathbf{Y} - \\mathbf{X} \\mathbf{W})^\\top (\\mathbf{Y} - \\mathbf{X} \\mathbf{W}) + \\lambda \\mathbf{W}^\\top \\mathbf{W}\n$$\n<p>Sviluppiamo il prodotto:</p>\n$$\n\\ell(\\mathbf{W}) = \\mathbf{Y}^\\top \\mathbf{Y} - 2 \\mathbf{W}^\\top \\mathbf{X}^\\top \\mathbf{Y} + \\mathbf{W}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{W} + \\lambda \\mathbf{W}^\\top \\mathbf{W}\n$$\n<p>Ora calcoliamo la derivata rispetto a $\\mathbf{W}$:</p>\n$$\n\\frac{\\partial \\ell(\\mathbf{W})}{\\partial \\mathbf{W}} = -2 \\mathbf{X}^\\top \\mathbf{Y} + 2 \\mathbf{X}^\\top \\mathbf{X} \\mathbf{W} + 2 \\lambda \\mathbf{W}\n$$\n<p>Imponiamo la condizione di ottimalità:</p>\n$$\n-2 \\mathbf{X}^\\top \\mathbf{Y} + 2 \\mathbf{X}^\\top \\mathbf{X} \\mathbf{W} + 2 \\lambda \\mathbf{W} = 0\n$$\n<p>Semplificando:</p>\n$$\\begin{align*}\n\\mathbf{X}^\\top \\mathbf{X} \\mathbf{W} + \\lambda \\mathbf{W} &= \\mathbf{X}^\\top \\mathbf{Y}\\\\\n(\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I}) \\mathbf{W} &= \\mathbf{X}^\\top \\mathbf{Y}\n\\end{align*}\n$$\n<p>Se $\\mathbf{X}^\\top \\mathbf{X} + \\lambda I$ è invertibile, la soluzione ottimale è:</p>\n$$\n\\mathbf{W} = (\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})^{-1} \\mathbf{X}^\\top \\mathbf{Y}\n$$\n<p>Questa è la soluzione <strong>OLS</strong> nel caso multidimensionale con regolarizzazione $L_2$. In <a href=\"/theory/math-for-ml/Ottimizzazione/Dimostrazione di Invertibilità Ridge\" class=\"text-blue-600 hover:underline\">questa</a> nota, è presente una dimostrazione sul perché la soluzione OLS con regolarizzazione $L_2$ sia ben definita e la matrice $(\\mathbf{X}^\\top \\mathbf{X} + \\lambda \\mathbf{I})$ sia sempre invertibile.</p>\n<h2 id=\"definizione-formale-di-regolarizzazione\"><strong>Definizione Formale di Regolarizzazione</strong></h2>\n<p><strong>Definizione 3.2 (Regolarizzazione)</strong>: Qualsiasi modifica intesa a ridurre l&rsquo;errore di generalizzazione ma non l&rsquo;errore di training.</p>\n<p>La regolarizzazione non si limita all&rsquo;aggiunta di termini di penalità alla funzione di perdita. Altre forme includono la scelta di una rappresentazione, l&rsquo;early stopping e il dropout.</p>\n<p>In generale, le $p$-norme sono una buona scelta per i regolarizzatori, poiché sono sempre convesse.<br />\nQuindi, quando $\\ell_\\Theta$ è convessa, anche $\\ell_\\Theta + \\lambda \\|\\Theta\\|_p^2$ lo è, poiché la somma di due funzioni convesse è ancora convessa.<br />\nQuesto è molto importante perché significa che possiamo sperare di trovare un&rsquo;espressione in forma chiusa per l&rsquo;ottimo globale del problema di minimizzazione:</p>\n$$\n\\argmin_{\\Theta} \\ \\ell_\\Theta + \\lambda \\|\\Theta\\|_p^2.\n$$\n<p>Inoltre, notiamo che qualsiasi $p$-norma non sarà lineare in $\\Theta$ poiché contiene almeno il valore assoluto.</p>\n<p>In generale, la regolarizzazione ci consente di imporre un certo comportamento atteso nel nostro modello di apprendimento.<br />\nEssa permette di controllare la complessità del modello e, facendo ciò, riduce la necessità di disporre di grandi quantità di dati, poiché impone un determinato comportamento.<br />\nSi noti che i regolarizzatori non sono sempre definiti come penalizzazioni incluse nelle funzioni di perdita.</p>\n<blockquote>\n<p><em>Se i regolarizzatori riducono l&rsquo;overfitting, non basterebbe ridurre la complessità del modello invece che introdurre un termine di penalizzazione?</em></p>\n<p>A volte può essere sufficiente ridurre la complessità del modello per evitare l&rsquo;overfitting, questo approccio può essere funzionale se il problema di apprendimento non richiede un modello molto complesso. Ma se siamo di fronte ad un problema che richiede un modello più complesso, la regolarizzazione è la scelta migliore in quanto permette comunque al modello di catturare pattern complessi senza basarsi troppo sui dati di addestramento.</p>\n</blockquote>\n<h2 id=\"altre-forme-di-regolarizzazione\"><strong>Altre Forme di Regolarizzazione</strong></h2>\n<p>Oltre alle norme L1 e L2, esistono altre forme di regolarizzazione che impongono comportamenti desiderati sui parametri:</p>\n<h3 id=\"1-early-stopping\"><strong>1. Early Stopping</strong></h3>\n<p>L&rsquo;early stopping interrompe l&rsquo;addestramento del modello quando la performance sul validation set smette di migliorare, prevenendo l&rsquo;overfitting.</p>\n<h3 id=\"2-dropout\"><strong>2. Dropout</strong></h3>\n<p>Il dropout è una tecnica utilizzata nelle reti neurali, dove durante l&rsquo;addestramento alcuni neuroni vengono &ldquo;disattivati&rdquo; casualmente, riducendo la dipendenza del modello da specifici neuroni e migliorando la generalizzazione.</p>\n<h3 id=\"3-scelta-della-rappresentazione\"><strong>3. Scelta della Rappresentazione</strong></h3>\n<p>La scelta di una rappresentazione appropriata dei dati (ad esempio, trasformazioni non lineari o feature engineering) può agire come una forma di regolarizzazione, migliorando la capacità del modello di generalizzare.</p>\n<h2 id=\"conclusione\"><strong>Conclusione</strong></h2>\n<p>La regolarizzazione è uno strumento essenziale per migliorare la generalizzazione dei modelli di machine learning. Le tecniche come la regolarizzazione L1, L2 e Elastic Net offrono diversi modi per controllare la complessità del modello, mentre altre forme come l&rsquo;early stopping e il dropout forniscono ulteriori meccanismi per prevenire l&rsquo;overfitting. La scelta della giusta forma di regolarizzazione dipende dal problema specifico e dalle caratteristiche dei dati.</p>\n<h2 id=\"collegamenti-correlati\"><strong>Collegamenti Correlati</strong></h2>\n<ul>\n<li><span class=\"text-gray-600\">Underfitting e Overfitting</span></li>\n<li><a href=\"/theory/supervised-learning/Non-Linear Models/Regressione Polinomiale\" class=\"text-blue-600 hover:underline\">Regressione Polinomiale</a></li>\n<li><span class=\"text-gray-600\">Minimi Quadrati Ordinari (OLS)</span></li>\n<li><span class=\"text-gray-600\">Teorema di Stone-Weierstrass</span></li>\n<li><span class=\"text-gray-600\">Selezione del Modello</span></li>\n</ul>"
}