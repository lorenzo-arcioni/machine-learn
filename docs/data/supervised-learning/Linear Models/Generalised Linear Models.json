{
  "title": "Generalized Linear Models (GLMs)",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<p>I <strong>Generalized Linear Models (GLMs)</strong> sono una classe flessibile di modelli statistici che generalizzano la regressione lineare per target che seguono distribuzioni appartenenti alla famiglia esponenziale. Forniscono un framework unificato per trattare problemi con target continui, binari o discreti. I GLMs sono ampiamente utilizzati in vari campi, come l&rsquo;econometria, la biostatistica e il machine learning, grazie alla loro capacità di adattarsi a diversi tipi di dati e di modellare relazioni complesse tra variabili.</p>\n<h2 id=\"componenti-principali-dei-glms\">Componenti principali dei GLMs</h2>\n<p>Un GLM è definito da tre componenti principali: la <strong>distribuzione dei target</strong>, la <strong>funzione di link</strong> e la <strong>funzione di varianza</strong>. Questi componenti lavorano insieme per modellare la relazione tra le variabili indipendenti (input) e la variabile dipendente (target).</p>\n<h3 id=\"1-distribuzione-dei-target\">1. Distribuzione dei target</h3>\n<p>I target $y$ appartengono alla <strong>famiglia esponenziale delle distribuzioni</strong>, che è una classe di distribuzioni che può essere espressa nella forma:</p>\n$$\np(y|\\theta, \\phi) = \\exp\\left(\\frac{y\\theta - b(\\theta)}{\\phi} + c(y, \\phi)\\right)\n$$\n<p>Dove:\n- <strong>$\\theta$</strong>: è il <strong>parametro naturale</strong>, una trasformazione del parametro della distribuzione che facilita la rappresentazione nella forma esponenziale. Questo parametro è legato alla media della distribuzione.\n- <strong>$b(\\theta)$</strong>: è la <strong>funzione cumulativa logaritmica</strong>, che determina la normalizzazione della distribuzione e la relazione tra $\\theta$ e la media della distribuzione.\n- <strong>$\\phi$</strong>: è il <strong>parametro di dispersione</strong>, che controlla la variabilità dei dati intorno alla media. Questo parametro è rilevante per distribuzioni come la gamma e la normale, ma è fissato per distribuzioni come Bernoulli e Poisson.\n- <strong>$c(y, \\phi)$</strong>: è la <strong>funzione di normalizzazione</strong>, che garantisce che la distribuzione si integri a 1 e dipende dalla specifica distribuzione utilizzata.</p>\n<p><strong>Esempi comuni di distribuzioni nella famiglia esponenziale</strong>:\n- <strong>Normale</strong>: $\\theta = \\mu$, $\\phi = \\sigma^2$.\n- <strong>Bernoulliana</strong>: $\\theta = \\log\\frac{\\pi}{1-\\pi}$.\n- <strong>Poissoniana</strong>: $\\theta = \\log(\\lambda)$.</p>\n<h3 id=\"2-funzione-di-link\">2. Funzione di link</h3>\n<p>La <strong>funzione di link</strong> collega la media condizionale $\\mu = \\mathbb{E}[y|x]$ al <strong>predictor lineare</strong> $\\eta$, che è una combinazione lineare delle variabili indipendenti:</p>\n$$\ng(\\mu) = \\eta = \\mathbf{w}^\\top \\mathbf{x} + b\n$$\n<p>Dove:\n- <strong>$g(\\cdot)$</strong>: è la funzione di link, che trasforma la media $\\mu$ in una scala lineare.\n- <strong>$\\eta$</strong>: è il <strong>predictor lineare</strong>, una combinazione lineare degli input $\\mathbf{x}$ con pesi $\\mathbf{w}$ e un termine di bias $b$.</p>\n<p><strong>Esempi comuni di funzioni di link</strong>:\n- <strong>Identità</strong>: $g(\\mu) = \\mu$ (usata nella regressione lineare).\n- <strong>Logit</strong>: $g(\\mu) = \\log\\frac{\\mu}{1-\\mu}$ (usata nella regressione logistica).\n- <strong>Logaritmica</strong>: $g(\\mu) = \\log(\\mu)$ (usata nella regressione di Poisson).</p>\n<h3 id=\"3-funzione-di-varianza\">3. Funzione di varianza</h3>\n<p>Nei GLMs, la varianza di $y$ è una funzione della media $\\mu$:</p>\n$$\n\\text{Var}(y) = \\phi v(\\mu)\n$$\n<p>Dove:\n- <strong>$v(\\mu)$</strong>: è la <strong>funzione di varianza</strong>, che dipende dalla specifica distribuzione utilizzata. Ad esempio, per la distribuzione normale, $v(\\mu) = 1$, mentre per la distribuzione di Poisson, $v(\\mu) = \\mu$.</p>\n<h2 id=\"formulazione-matematica\">Formulazione matematica</h2>\n<h3 id=\"4-probabilita-condizionale\">4. Probabilità condizionale</h3>\n<p>La probabilità condizionale di $y$ dato $\\mathbf{x}$ e i parametri $\\mathbf{w}$ è data da:</p>\n$$\np(y | \\mathbf{x}, \\mathbf{w}) = \\exp\\left(\\frac{y\\theta - b(\\theta)}{\\phi} + c(y, \\phi)\\right)\n$$\n<p>Dove:\n- <strong>$\\theta = g^{-1}(\\eta)$</strong>: è il parametro naturale, ottenuto applicando l&rsquo;inversa della funzione di link al predictor lineare $\\eta$.\n- <strong>$\\eta = \\mathbf{w}^\\top \\mathbf{x}$</strong>: è il predictor lineare.</p>\n<h3 id=\"5-stima-dei-parametri\">5. Stima dei parametri</h3>\n<p>La stima dei parametri $\\mathbf{w}$ avviene massimizzando la <strong>log-verosimiglianza</strong>:</p>\n$$\n\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^N \\left( \\frac{y_i \\theta_i - b(\\theta_i)}{\\phi} + c(y_i, \\phi) \\right)\n$$\n<p>Dove:\n- <strong>$\\theta_i = g^{-1}(\\mathbf{w}^\\top \\mathbf{x}_i)$</strong>: è il parametro naturale per l&rsquo;osservazione $i$-esima.\n- <strong>Metodi iterativi</strong>: come il <strong>reweighted least squares</strong> o il <strong>metodo di Newton-Raphson</strong> sono utilizzati per massimizzare la log-verosimiglianza.</p>\n<h3 id=\"6-predizione\">6. Predizione</h3>\n<p>Per un nuovo input $\\mathbf{x}^*$, la predizione avviene in due passaggi:\n1. Calcolo del predictor lineare:\n   $$\n   \\eta^* = \\mathbf{w}^\\top \\mathbf{x}^*\n   $$\n2. Applicazione della funzione di link inversa per ottenere la media predetta:\n   $$\n   \\mu^* = g^{-1}(\\eta^*)\n   $$</p>\n<h2 id=\"esempi-comuni-di-glms\">Esempi comuni di GLMs</h2>\n<h3 id=\"7-regressione-lineare\">7. <a href=\"/theory/supervised-learning/Linear Models/Regressione Lineare\" class=\"text-blue-600 hover:underline\">Regressione Lineare</a></h3>\n<ul>\n<li><strong>Distribuzione</strong>: Normale.</li>\n<li><strong>Funzione di link</strong>: Identità $g(\\mu) = \\mu$.</li>\n<li><strong>Modello</strong>: $y = \\mathbf{w}^\\top \\mathbf{x} + \\epsilon$, con $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.</li>\n</ul>\n<h3 id=\"8-regressione-logistica\">8. <a href=\"/theory/supervised-learning/Linear Models/Regressione Logistica\" class=\"text-blue-600 hover:underline\">Regressione Logistica</a></h3>\n<ul>\n<li><strong>Distribuzione</strong>: Bernoulliana.</li>\n<li><strong>Funzione di link</strong>: Logit $g(\\mu) = \\log\\frac{\\mu}{1-\\mu}$.</li>\n<li><strong>Modello</strong>: $\\pi = \\sigma(\\mathbf{w}^\\top \\mathbf{x})$, dove $\\sigma(\\cdot)$ è la funzione sigmoide.</li>\n</ul>\n<h3 id=\"9-regressione-di-poisson\">9. Regressione di Poisson</h3>\n<ul>\n<li><strong>Distribuzione</strong>: Poissoniana.</li>\n<li><strong>Funzione di link</strong>: Logaritmica $g(\\mu) = \\log(\\mu)$.</li>\n<li><strong>Modello</strong>: $\\lambda = \\exp(\\mathbf{w}^\\top \\mathbf{x})$.</li>\n</ul>\n<h2 id=\"proprieta-dei-glms\">Proprietà dei GLMs</h2>\n<h3 id=\"10-flessibilita\">10. Flessibilità</h3>\n<p>I GLMs sono estremamente flessibili e possono modellare diversi tipi di dati scegliendo la distribuzione e una funzione di link appropriata. Ad esempio, possono essere utilizzati per dati continui, binari o di conteggio.</p>\n<h3 id=\"11-proprieta-analitiche\">11. Proprietà analitiche</h3>\n<p>La linearità nei parametri consente una stima efficiente tramite metodi iterativi standard, come il metodo di Newton-Raphson o il reweighted least squares.</p>\n<h3 id=\"12-limitazioni\">12. Limitazioni</h3>\n<ul>\n<li><strong>Assunzione di indipendenza</strong>: I GLMs assumono che i target siano indipendenti e distribuiti in modo identico (i.i.d.).</li>\n<li><strong>Scelta della distribuzione e della funzione di link</strong>: Scelte errate possono compromettere le prestazioni del modello.</li>\n</ul>\n<h2 id=\"espansioni-e-variazioni\">Espansioni e variazioni</h2>\n<h3 id=\"1-glmms-generalized-linear-mixed-models\">1. GLMMs (Generalized Linear Mixed Models)</h3>\n<p>I <strong>GLMMs</strong> sono un&rsquo;estensione dei GLMs che include effetti randomici per modellare dati gerarchici o correlati. Sono particolarmente utili in contesti come studi longitudinali o dati con strutture gerarchiche.</p>\n<h3 id=\"2-regolarizzazione\">2. Regolarizzazione</h3>\n<p>Tecniche di regolarizzazione come <strong>Lasso</strong>, <strong>Ridge</strong> o <strong>Elastic Net</strong> possono essere applicate ai GLMs per evitare overfitting e migliorare la generalizzazione del modello.</p>\n<h3 id=\"3-modelli-non-lineari\">3. Modelli non lineari</h3>\n<p>I GLMs possono essere combinati con funzioni di base (ad esempio, polinomi o spline) per modellare relazioni non lineari tra le variabili indipendenti e il target.</p>\n<h2 id=\"conclusione\">Conclusione</h2>\n<p>I <strong>Generalized Linear Models (GLMs)</strong> sono uno strumento potente e versatile per l&rsquo;analisi statistica e il machine learning. Grazie alla loro flessibilità e alla capacità di adattarsi a diversi tipi di dati, i GLMs sono ampiamente utilizzati in molti campi applicativi. Tuttavia, è importante comprendere le loro assunzioni e limitazioni per utilizzarli in modo efficace.</p>"
}