{
  "title": "Hidden Markov Models in PoS Tagging",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<p>A partire dagli anni &lsquo;70, il <strong>PoS tagging</strong> ha iniziato a essere affrontato anche con <strong>metodi probabilistici</strong>, cio√® <strong>stocastici</strong>.</p>\n<p>L&rsquo;idea alla base √® semplice: usare i <strong>modelli di Markov nascosti (HMM)</strong> per selezionare la <strong>sequenza di etichette grammaticale pi√π probabile</strong> data una sequenza di parole.</p>\n<p>Formalmente, il problema pu√≤ essere formulato come segue:</p>\n$$\n\\hat{t}_1^n = \\underset{t_1^n \\in \\text{Tagset}^n}{\\arg\\max} \\ P(t_1^n \\mid w_1^n)\n$$\n<p>In altre parole, cerchiamo la sequenza di tag $t_1^n$ che <strong>massimizza la probabilit√† condizionata</strong> dato l&rsquo;input $w_1^n$, ovvero la sequenza di parole osservate.</p>\n<h2 id=\"teorema-di-bayes\">Teorema di Bayes</h2>\n<p>Per calcolare questa probabilit√†, possiamo ricorrere al <strong>teorema di Bayes</strong>:</p>\n$$\nP(x \\mid y) = \\frac{P(y \\mid x) \\cdot P(x)}{P(y)}\n$$\n<p>Applicandolo al nostro problema:</p>\n$$\nP(t_1^n \\mid w_1^n) = \\frac{P(w_1^n \\mid t_1^n) \\cdot P(t_1^n)}{P(w_1^n)}\n$$\n<p>Poich√© $P(w_1^n)$ √® costante rispetto ai tag $t_1^n$, possiamo ignorarlo nel calcolo dell&rsquo;$\\arg\\max$. Otteniamo quindi:</p>\n$$\n\\hat{t}_1^n = \\underset{t_1^n \\in \\text{Tagset}^n}{\\arg\\max} \\ \\frac{P(w_1^n \\mid t_1^n) \\cdot P(t_1^n)}{P(w_1^n)} \\approx \\underset{t_1^n \\in \\text{Tagset}^n}{\\arg\\max} P(w_1^n \\mid t_1^n) \\cdot P(t_1^n)\n$$\n<p>Dove:\n- $P(w_1^n \\mid t_1^n)$ √® la <strong>verosimiglianza</strong> (<em>likelihood</em>): probabilit√† di osservare le parole date le etichette.\n- $P(t_1^n)$ √® la <strong>probabilit√† a priori</strong> (<em>prior</em>) delle etichette grammaticali.</p>\n<p>In pratica, cerchiamo la sequenza di PoS tag che <strong>spiega meglio le parole osservate</strong>, tenendo anche conto di quanto sia <strong>probabile a priori</strong> quella sequenza di tag. Ma come calcolare queste probabilit√†?</p>\n<h2 id=\"assunzione-1-la-parola-dipende-solo-dal-suo-pos-tag\">Assunzione 1: La parola dipende solo dal suo PoS tag</h2>\n<p>Per semplificare il calcolo della <strong>verosimiglianza</strong> $P(w_1^n \\mid t_1^n)$, si fa la seguente assunzione:</p>\n<blockquote>\n<p>Ogni parola $w_i$ dipende solo dal suo corrispondente tag $t_i$.</p>\n</blockquote>\n<p>Formalmente:</p>\n$$\nP(w_1^n \\mid t_1^n) = \\prod_{i=1}^{n} P(w_i \\mid t_i)\n$$\n<p>Questa √® un‚Äô<strong>assunzione di indipendenza condizionata</strong>: ci permette di calcolare la probabilit√† delle parole in modo <strong>locale</strong>, tag per tag, invece che sull&rsquo;intera sequenza.</p>\n<h2 id=\"assunzione-2-ogni-tag-dipende-solo-dal-tag-precedente\">Assunzione 2: Ogni tag dipende solo dal tag precedente</h2>\n<p>Per semplificare il calcolo della <strong>prior</strong> $P(t_1^n)$, si assume che ogni tag dipenda <strong>solo dal tag precedente</strong>:</p>\n<blockquote>\n<p>Questo √® noto come <strong>bigram model</strong> o <strong>Markov assumption di primo ordine</strong>.</p>\n</blockquote>\n<p>Formalmente:</p>\n$$\nP(t_1^n) = \\prod_{i=1}^{n} P(t_i \\mid t_{i-1})\n$$\n<p>Questo significa che la sequenza dei tag viene modellata come una <strong>catena di Markov</strong>: non consideriamo tutta la storia passata dei tag, ma solo quello immediatamente precedente.</p>\n<h2 id=\"combinazione-delle-due-assunzioni\">Combinazione delle due assunzioni</h2>\n<p>Applicando insieme le due assunzioni precedenti otteniamo:</p>\n$$\nP(w_1^n \\mid t_1^n) \\cdot P(t_1^n) = \\prod_{i=1}^{n} P(w_i \\mid t_i) \\cdot P(t_i \\mid t_{i-1})\n$$\n<p>Questo prodotto √® il cuore del PoS tagging stocastico: stimiamo la <strong>probabilit√† congiunta</strong> della sequenza parole-tag usando stime locali.</p>\n<h2 id=\"stima-delle-probabilita-dai-corpora\">Stima delle probabilit√† dai corpora</h2>\n<p>Grazie a <strong>corpora annotati</strong> (es. Penn Treebank, Universal Dependencies), possiamo stimare le due componenti:</p>\n<ul>\n<li>\n<p><strong>Probabilit√† di emissione</strong> (likelihood):<br />\n  $$\n  P(w_i \\mid t_i) = \\frac{\\text{conteggio}(t_i, w_i)}{\\text{conteggio}(t_i)}\n  $$</p>\n</li>\n<li>\n<p><strong>Probabilit√† di transizione</strong> (prior):<br />\n  $$\n  P(t_i \\mid t_{i-1}) = \\frac{\\text{conteggio}(t_{i-1}, t_i)}{\\text{conteggio}(t_{i-1})}\n  $$</p>\n</li>\n</ul>\n<p>Queste stime si basano sulla <strong>frequenza relativa</strong> osservata nei corpus PoS-annotati.</p>\n<h2 id=\"come-trovare-la-sequenza-di-tag-ottimale\">Come trovare la sequenza di tag ottimale?</h2>\n<p>Ora abbiamo:\n- le probabilit√† $P(w_i \\mid t_i)$ ‚Üí emissione\n- le probabilit√† $P(t_i \\mid t_{i-1})$ ‚Üí transizione</p>\n<p>Ma dobbiamo trovare la <strong>sequenza di tag $\\hat{t}_1^n$</strong> che <strong>massimizza il prodotto</strong> di questi termini.</p>\n<p>Questo √® un problema classico di <strong>decodifica in modelli di Markov nascosti</strong>.</p>\n<h2 id=\"utilizzo-degli-hidden-markov-models\">Utilizzo degli Hidden Markov Models</h2>\n<p>Per risolvere il problema del PoS tagging ‚Äî ovvero associare la sequenza di parole a una sequenza di tag grammaticale ‚Äî si pu√≤ modellare il processo come un <strong>Hidden Markov Model (HMM)</strong>.</p>\n<p>Un HMM √® un modello statistico in cui:\n- Esiste una <strong>sequenza nascosta di stati</strong> (nel nostro caso, i <strong>tag</strong> grammaticali).\n- Ogni stato emette un&rsquo;<strong>osservazione</strong> (nel nostro caso, una <strong>parola</strong> del testo).\n- Le transizioni tra stati e le emissioni sono regolate da <strong>probabilit√†</strong>.</p>\n<p><strong>Formalmente</strong>:</p>\n<ul>\n<li>\n<p>$Q = q_1 q_2 \\dots q_N$  <strong>un insieme di $N$ stati</strong></p>\n</li>\n<li>\n<p>$A = a_{11} \\dots a_{ij} \\dots a_{NN}$ <strong>una matrice di probabilit√† di transizione</strong> $A$, dove ogni $a_{ij}$ rappresenta la probabilit√†<br />\n  di passare dallo stato $i$ allo stato $j$, tale che $\\sum_{j=1}^N a_{ij} = 1 \\quad \\forall i$</p>\n</li>\n<li>\n<p>$O = o_1 o_2 \\dots o_T$ <strong>una sequenza di $T$ osservazioni</strong>, ciascuna presa da un vocabolario $V = v_1, v_2, \\dots, v_V$</p>\n</li>\n<li>\n<p>$B = b_i(o_t)$ <strong>una sequenza di probabilit√† di osservazione</strong>, dette anche <strong>probabilit√† di emissione</strong>, ognuna delle quali esprime la probabilit√† che un&rsquo;osservazione $o_t$ venga generata dallo stato $q_i$</p>\n</li>\n<li>\n<p>$\\pi = \\pi_1, \\pi_2, \\dots, \\pi_N$ <strong>una distribuzione di probabilit√† iniziale</strong> sugli stati. $\\pi_i$ √® la probabilit√† che la catena di Markov inizi nello stato $i$. Alcuni stati $j$ possono avere $\\pi_j = 0$,<br />\n  cio√® non possono essere stati iniziali. Inoltre, $\\sum_{i=1}^n \\pi_i = 1$</p>\n</li>\n</ul>\n<h3 id=\"due-assunzioni-fondamentali-di-un-hmm-di-primo-ordine\">Due assunzioni fondamentali di un HMM di primo ordine</h3>\n<ol>\n<li>\n<p><strong>Assunzione di Markov</strong>:<br />\n   Ogni stato (tag) dipende solo dallo <strong>stato precedente</strong>:\n   $$\n   P(t_i \\mid t_1^{i-1}) \\approx P(t_i \\mid t_{i-1})\n   $$</p>\n</li>\n<li>\n<p><strong>Assunzione di emissione indipendente</strong>:<br />\n   Ogni parola dipende solo dal <strong>tag corrente</strong>, non dagli altri tag o parole:\n   $$\n   P(w_i \\mid t_1^n, w_1^{i-1}) \\approx P(w_i \\mid t_i)\n   $$</p>\n</li>\n</ol>\n<p>Applicando queste due assunzioni otteniamo la formula:\n$$\n\\hat{t}_1^n = \\arg\\max_{t_1^n \\in Tagset^n} \\prod_{i=1}^n P(w_i \\mid t_i) \\cdot P(t_i \\mid t_{i-1})\n$$</p>\n<p><span class=\"text-gray-600\">Qui</span> √® diposnibile una descrizione dettagliata degli HMM.</p>\n<h3 id=\"esempio-jason-eisner-task-2002\">Esempio: Jason Eisner task (2002)</h3>\n<p>Un esempio classico per spiegare gli HMM √® il <strong>&ldquo;Jason Eisner task&rdquo;</strong>:</p>\n<blockquote>\n<p>Jason tiene un diario con il numero di gelati mangiati ogni giorno dell&rsquo;estate.\nIl suo obiettivo √® ricostruire, a partire da questi numeri, se ogni giorno era caldo (<strong>H</strong>) o freddo (<strong>C</strong>).</p>\n</blockquote>\n<p>Formalmente:\n- La sequenza <strong>osservata</strong> $O$ √® il numero di gelati mangiati ogni giorno.\n- La sequenza <strong>nascosta</strong> $Q$ √® la condizione meteorologica (<strong>H</strong>ot o <strong>C</strong>old).\n- Ogni giorno Jason sceglie quanti gelati mangiare <strong>in base al meteo</strong>.\n- L‚Äôobiettivo √® <strong>inferire la sequenza di stati</strong> che ha prodotto le osservazioni.</p>\n<p>Questo √® del tutto analogo al PoS tagging:\n- Le <strong>osservazioni</strong> sono le parole del testo.\n- Gli <strong>stati nascosti</strong> sono i tag grammaticali.\n- L‚Äôobiettivo √® inferire la <strong>sequenza di tag pi√π probabile</strong> dato il testo osservato.</p>\n<h3 id=\"riassunto-dei-componenti-di-un-hmm-per-il-pos-tagging\">Riassunto dei componenti di un HMM per il PoS tagging</h3>\n<table>\n<thead>\n<tr>\n<th>Componente</th>\n<th>Significato NLP</th>\n<th>Simbolo</th>\n<th>Come si calcola</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Stati $Q$</td>\n<td>Tag PoS</td>\n<td>$t_i$</td>\n<td>Predefiniti nel tagset</td>\n</tr>\n<tr>\n<td>Osservazioni $O$</td>\n<td>Parole del testo</td>\n<td>$w_i$</td>\n<td>Input della frase</td>\n</tr>\n<tr>\n<td>Transizione</td>\n<td>$P(t_i \\mid t_{i-1})$</td>\n<td>Tag ‚Üí Tag</td>\n<td>Frequenze nei corpora</td>\n</tr>\n<tr>\n<td>Emissione</td>\n<td>$P(w_i \\mid t_i)$</td>\n<td>Tag ‚Üí Parola</td>\n<td>Frequenze nei corpora</td>\n</tr>\n<tr>\n<td>Iniziale $\\pi(t_1)$</td>\n<td>Probabilit√† iniziale di ogni tag</td>\n<td>$P(t_1)$</td>\n<td>Conta quanti tag iniziali in corpus</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"obiettivo-finale\">Obiettivo finale</h3>\n<p>Data una frase (sequenza di parole), vogliamo trovare:</p>\n$$\n\\hat{t}_1^n = \\arg\\max_{t_1^n} P(w_1^n \\mid t_1^n) \\cdot P(t_1^n)\n$$\n<p>Dove $P(w_1^n \\mid t_1^n)$ e $P(t_1^n)$ sono le <strong>verosimiglianze</strong> e <strong>probabilit√† a priori</strong>.</p>\n<h3 id=\"esempio-pratico\">Esempio pratico</h3>\n<p>Supponiamo di avere il seguente <strong>corpus annotato</strong> (PoS-tagged):</p>\n<div class=\"codehilite\"><pre><span></span><code>the/DT dog/NN barks/VBZ\nthe/DT can/NN falls/VBZ\nwe/PRP can/MD win/VB\nbook/NN the/DT book/VB\ndogs/NNS bark/VBP\ncats/NNS sleep/VBP\nthe/DT can/MD run/VB\ncan/MD you/PRP run/VB\nsome/DT dogs/NNS bark/VBP\n</code></pre></div>\n\n<h4 id=\"1-insieme-dei-tag-e-parole\">1. Insieme dei tag e parole</h4>\n<ul>\n<li><strong>Tag (Q)</strong> = { <code>DT</code>, <code>PRP</code>, <code>NN</code>, <code>NNS</code>, <code>MD</code>, <code>VBZ</code>, <code>VBP</code>, <code>VB</code> }  </li>\n<li><strong>Parole (O)</strong> = { the, some, we, you, dog, dogs, cat(s), can, book, bark, barks, falls, sleep, run, win }</li>\n</ul>\n<h4 id=\"2-probabilita-di-transizione\">2. Probabilit√† di transizione</h4>\n<table>\n<thead>\n<tr>\n<th>Transizione</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>‚ü®s‚ü© ‚Üí DT</td>\n<td>4</td>\n<td>4/9 ‚âÉ 0.44</td>\n</tr>\n<tr>\n<td>‚ü®s‚ü© ‚Üí PRP</td>\n<td>1</td>\n<td>1/9 ‚âÉ 0.11</td>\n</tr>\n<tr>\n<td>‚ü®s‚ü© ‚Üí NN</td>\n<td>1</td>\n<td>1/9 ‚âÉ 0.11</td>\n</tr>\n<tr>\n<td>‚ü®s‚ü© ‚Üí NNS</td>\n<td>2</td>\n<td>2/9 ‚âÉ 0.22</td>\n</tr>\n<tr>\n<td>‚ü®s‚ü© ‚Üí MD</td>\n<td>1</td>\n<td>1/9 ‚âÉ 0.11</td>\n</tr>\n<tr>\n<td>DT ‚Üí NN</td>\n<td>2</td>\n<td>2/5 = 0.40</td>\n</tr>\n<tr>\n<td>DT ‚Üí MD</td>\n<td>1</td>\n<td>1/5 = 0.20</td>\n</tr>\n<tr>\n<td>DT ‚Üí NNS</td>\n<td>1</td>\n<td>1/5 = 0.20</td>\n</tr>\n<tr>\n<td>DT ‚Üí VB</td>\n<td>1</td>\n<td>1/5 = 0.20</td>\n</tr>\n<tr>\n<td>PRP ‚Üí MD</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n<tr>\n<td>PRP ‚Üí VB</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n<tr>\n<td>NN ‚Üí VBZ</td>\n<td>2</td>\n<td>2/3 ‚âÉ 0.67</td>\n</tr>\n<tr>\n<td>NN ‚Üí DT</td>\n<td>1</td>\n<td>1/3 ‚âÉ 0.33</td>\n</tr>\n<tr>\n<td>NNS ‚Üí VBP</td>\n<td>2</td>\n<td>3/3 = 1.00</td>\n</tr>\n<tr>\n<td>MD ‚Üí VB</td>\n<td>2</td>\n<td>2/3 ‚âÉ 0.67</td>\n</tr>\n<tr>\n<td>MD ‚Üí PRP</td>\n<td>1</td>\n<td>1/3 ‚âÉ 0.33</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"3-probabilita-di-emissione\">3. Probabilit√† di emissione</h4>\n<p><strong>DT</strong> (5 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>the</td>\n<td>4</td>\n<td>4/5 = 0.80</td>\n</tr>\n<tr>\n<td>some</td>\n<td>1</td>\n<td>1/5 = 0.20</td>\n</tr>\n</tbody>\n</table>\n<p><strong>PRP</strong> (2 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>we</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n<tr>\n<td>you</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n</tbody>\n</table>\n<p><strong>NN</strong> (4 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>dog</td>\n<td>1</td>\n<td>1/3 ‚âà 0.333</td>\n</tr>\n<tr>\n<td>can</td>\n<td>1</td>\n<td>1/3 ‚âà 0.333</td>\n</tr>\n<tr>\n<td>book</td>\n<td>1</td>\n<td>1/3 ‚âà 0.333</td>\n</tr>\n</tbody>\n</table>\n<p><strong>NNS</strong> (3 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>dogs</td>\n<td>2</td>\n<td>2/3 ‚âÉ 0.67</td>\n</tr>\n<tr>\n<td>cats</td>\n<td>1</td>\n<td>1/3 ‚âÉ 0.33</td>\n</tr>\n</tbody>\n</table>\n<p><strong>MD</strong> (3 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>can</td>\n<td>3</td>\n<td>3/3 = 1.00</td>\n</tr>\n</tbody>\n</table>\n<p><strong>VBZ</strong> (2 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>barks</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n<tr>\n<td>falls</td>\n<td>1</td>\n<td>1/2 = 0.50</td>\n</tr>\n</tbody>\n</table>\n<p><strong>VBP</strong> (2 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bark</td>\n<td>2</td>\n<td>2/3 ‚âà 0.667</td>\n</tr>\n<tr>\n<td>sleep</td>\n<td>1</td>\n<td>1/3 ‚âà 0.333</td>\n</tr>\n</tbody>\n</table>\n<p><strong>VB</strong> (4 occorrenze)</p>\n<table>\n<thead>\n<tr>\n<th>Parola</th>\n<th>Conteggio</th>\n<th>Probabilit√†</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>win</td>\n<td>1</td>\n<td>1/4 = 0.25</td>\n</tr>\n<tr>\n<td>book</td>\n<td>1</td>\n<td>1/4 = 0.25</td>\n</tr>\n<tr>\n<td>run</td>\n<td>2</td>\n<td>2/4 = 0.50</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"4-rappresentazione-tikz-del-modello-hmm\">4. Rappresentazione TikZ del modello HMM</h4>\n<p><img src=\"/images/tikz/3bfdc9c4c841833e4ad94f4100c0c1d9.svg\" style=\"display: block; width: 100%; height: auto; max-height: 600px;\" class=\"tikz-svg\" /></p>\n<h4 id=\"conclusione\">Conclusione</h4>\n<p>Questo √® un semplice esempio pratico che mostra come costruire un HMM da un corpus annotato, calcolare tutte le probabilit√†, e disegnare il grafo corrispondente. Nella realt√† si lavora su tagset e vocabolari molto pi√π grandi, ma il concetto √® lo stesso.</p>\n<h2 id=\"pos-decoding\">PoS Decoding</h2>\n<p>Nel contesto dei modelli <strong>HMM</strong>, il <strong>decoding</strong> √® il processo per determinare la sequenza pi√π probabile di stati nascosti (in questo caso, i PoS tag) dati una sequenza osservata di parole.</p>\n<p><br></p>\n<blockquote>\n<p><strong>Decoding</strong>: Dato in input un HMM $\\lambda = (A, B)$ e una sequenza di osservazioni $O = o_1, o_2, \\dots, o_T$, il compito √® trovare la sequenza di stati $Q = q_1 q_2 q_3 \\dots q_T$ pi√π probabile.</p>\n</blockquote>\n<p>Nel caso del <strong>PoS tagging</strong>, le <strong>osservazioni</strong> corrispondono alle parole, mentre gli <strong>stati</strong> rappresentano i corrispondenti PoS tag. L&rsquo;obiettivo √® quindi assegnare ad ogni parola il PoS tag pi√π plausibile secondo il modello HMM.</p>\n<h3 id=\"algoritmo-di-viterbi\">Algoritmo di Viterbi</h3>\n<p>Il <strong>decoding</strong> viene eseguito tramite l&rsquo;<strong>algoritmo di Viterbi</strong>, che trova il percorso di stati pi√π probabile (la sequenza di tag PoS pi√π plausibile) che ha generato la sequenza osservata.</p>\n<p>L&rsquo;algoritmo lavora in tre fasi:</p>\n<ul>\n<li>\n<p><strong>Inizializzazione</strong>: calcola la probabilit√† iniziale per ciascuno stato, moltiplicando la probabilit√† iniziale $\\pi_s$ per la probabilit√† di emissione della prima osservazione.</p>\n</li>\n<li>\n<p><strong>Ricorsione</strong>: per ogni parola nella sequenza (dalla seconda in poi), si aggiorna la matrice delle probabilit√† di percorso considerando il massimo tra tutti i possibili stati precedenti.</p>\n</li>\n<li>\n<p><strong>Terminazione</strong>: si seleziona il percorso con la probabilit√† totale pi√π alta.</p>\n</li>\n</ul>\n<blockquote>\n<p>Output: <code>bestpath</code>, la sequenza pi√π probabile di stati (PoS tag), e <code>bestpathprob</code>, la sua probabilit√†.</p>\n</blockquote>\n$$\n\\begin{aligned}\n\\textbf{VITERBI}(O = o_1, o_2, \\dots, o_T; \\lambda = (A, B)) &\\Rightarrow \\text{best-path}, \\text{path-prob} \\\\\n\\\\\n\\textbf{Inizializzazione:} \\quad &\\text{crea una matrice } \\textit{viterbi}[N, T]\\\\\n\\quad &\\text{per ogni stato } s = 1 \\dots N \\\\\n&\\quad \\textit{viterbi}[s, 1] \\leftarrow \\pi_s \\cdot b_s(o_1) \\\\\n&\\quad \\textit{backpointer}[s, 1] \\leftarrow 0 \\\\\n\\\\\n\\textbf{Ricorsione:} \\quad &\\text{per ogni } t = 2 \\dots T \\\\\n&\\quad \\text{per ogni stato } s = 1 \\dots N \\\\\n&\\quad \\quad \\textit{viterbi}[s, t] \\leftarrow \\max_{s'} \\left( \\textit{viterbi}[s', t-1] \\cdot a_{s', s} \\cdot b_s(o_t) \\right) \\\\\n&\\quad \\quad \\textit{backpointer}[s, t] \\leftarrow \\mathop{\\arg\\max}\\limits_{s'} \\left( \\textit{viterbi}[s', t-1] \\cdot a_{s', s} \\cdot b_s(o_t) \\right) \\\\\n\\\\\n\\textbf{Terminazione:} \\quad &\\text{bestpathprob} \\leftarrow \\max_{s=1}^N \\left( \\textit{viterbi}[s, T] \\right) \\\\\n&\\text{bestpathpointer} \\leftarrow \\mathop{\\arg\\max}\\limits_{s=1}^{N} \\left( \\textit{viterbi}[s, T] \\right) \\\\\n&\\text{Ricostruzione del percorso usando } \\textit{backpointer} \\\\\n\\end{aligned}\n$$\n<p><strong>Spiegazione Intuitiva</strong></p>\n<p>L&rsquo;algoritmo di Viterbi si basa su un principio semplice ma potente: invece di considerare <strong>tutti</strong> i possibili percorsi attraverso la rete di stati (cosa computazionalmente proibitiva), calcola <strong>ricorsivamente</strong> il percorso pi√π probabile che porta a ciascuno stato in ogni istante di tempo. Cos√¨ facendo, sfrutta il principio di <strong>ottimalit√†</strong> della programmazione dinamica.</p>\n<p>Ecco l&rsquo;idea chiave:</p>\n<ul>\n<li>Se vogliamo sapere qual √® la sequenza di stati pi√π probabile che ha generato una sequenza di osservazioni, possiamo costruirla passo dopo passo, <strong>tenendo traccia solo dei percorsi migliori</strong> verso ciascuno stato.</li>\n<li>In ogni momento, per uno stato corrente $s$, si calcola la <strong>probabilit√† massima di arrivare l√¨</strong> da uno qualsiasi degli stati precedenti $s'$, <strong>moltiplicando</strong>:</li>\n<li>la probabilit√† del miglior percorso fino a $s'$ al tempo $t-1$</li>\n<li>la probabilit√† di transizione da $s'$ a $s$ ($a_{s', s}$)</li>\n<li>la probabilit√† di emissione dell&rsquo;osservazione corrente da $s$ ($b_s(o_t)$)</li>\n</ul>\n<p>Questo approccio si basa su un&rsquo;importante assunzione del modello di Markov (HMM):</p>\n<ul>\n<li>La <strong>probabilit√† di uno stato</strong> dipende <strong>solo</strong> dallo stato precedente (Markoviano)</li>\n<li>L&rsquo;<strong>osservazione</strong> dipende <strong>solo</strong> dallo stato attuale</li>\n</ul>\n<p><strong>Perch√© funziona?</strong><br />\nPerch√© grazie alla struttura a stati e alle probabilit√† condizionate dell‚ÄôHMM, possiamo decomporre un problema complesso (trovare il percorso globale ottimo) in tanti sottoproblemi pi√π semplici (trovare il miglior percorso fino a un certo stato in un certo istante), e riutilizzare le soluzioni ai sottoproblemi precedenti. Questo √® esattamente ci√≤ che fa la programmazione dinamica.</p>\n<p>Infine, una volta costruita la matrice <code>viterbi</code>, usiamo <code>backpointer</code> per ricostruire <strong>all‚Äôindietro</strong> la sequenza ottimale degli stati, partendo dallo stato finale con la massima probabilit√†.</p>\n<p>In sintesi:</p>\n<ul>\n<li>Non esplora tutti i percorsi possibili.</li>\n<li>Sfrutta solo i percorsi migliori a ogni passo.</li>\n<li>√à efficiente (tempo lineare nella lunghezza della sequenza).</li>\n<li>√à esatto (garantisce il percorso pi√π probabile).</li>\n</ul>\n<h3 id=\"applicazione-dellalgoritmo-di-viterbi-per-la-sequenza-we-can-run\">Applicazione dell&rsquo;Algoritmo di Viterbi per la sequenza &ldquo;we can run&rdquo;</h3>\n<p>Questo documento illustra passo dopo passo l&rsquo;applicazione dell&rsquo;algoritmo di Viterbi per trovare la sequenza di tag POS (Part-Of-Speech) pi√π probabile per la frase &ldquo;we can run&rdquo;. </p>\n<p><strong>Parametri di Input</strong>\n- <strong>Sequenza di osservazioni</strong>:<br />\n  $$O = (o_1, o_2, o_3) = (\\text{we},\\, \\text{can},\\, \\text{run})$$<br />\n  Dove $T = 3$ √® la lunghezza della sequenza.</p>\n<ul>\n<li>\n<p><strong>Insieme degli stati (tag POS)</strong>:<br />\n  $$Q = \\{\\text{DT}, \\text{PRP}, \\text{NN}, \\text{NNS}, \\text{MD}, \\text{VBZ}, \\text{VBP}, \\text{VB}\\}$$<br />\n  Alcuni stati (VBZ, VBP, VB) hanno probabilit√† iniziale $\\pi_s = 0$.</p>\n</li>\n<li>\n<p><strong>Parametri</strong>:</p>\n</li>\n<li>$\\pi_s$: Probabilit√† iniziali degli stati.</li>\n<li>$A = [a]_{i,j}$: Matrice di transizione tra stati.</li>\n<li>$B = b_i(o_t)$: Matrice di emissione (probabilit√† che uno stato $i$ emetta una parola $o_t$).</li>\n</ul>\n<p><strong>1. Inizializzazione ($t=1$)</strong></p>\n<p>Calcoliamo le probabilit√† $v[s,1]$ per tutti gli stati al primo passo temporale ($t=1$), usando la formula:<br />\n$$v[s,1] = \\pi_s \\cdot b_s(\\text{we})$$</p>\n<p><strong>Spiegazione</strong>:\n- $v[s,1]$: Probabilit√† del percorso pi√π probabile che termina nello stato $s$ al tempo $t=1$.\n- Solo gli stati con $\\pi_s > 0$ <strong>e</strong> $b_s(\\text{we}) > 0$ contribuiscono.  </p>\n<table>\n<thead>\n<tr>\n<th>Stato $s$</th>\n<th>$\\pi_s$</th>\n<th>$b_s(\\text{we})$</th>\n<th>$v[s,1]$</th>\n<th>Note</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DT</td>\n<td>$4/9 \\approx 0.444$</td>\n<td>0</td>\n<td>$0$</td>\n<td>Emissione nulla per &ldquo;we&rdquo;</td>\n</tr>\n<tr>\n<td>PRP</td>\n<td>$1/9 \\approx 0.111$</td>\n<td>$0.50$</td>\n<td>$\\frac{1}{18} \\approx 0.0556$</td>\n<td>Unico stato con probabilit√† non nulla</td>\n</tr>\n<tr>\n<td>NN</td>\n<td>$1/9$</td>\n<td>0</td>\n<td>$0$</td>\n<td>Emissione nulla</td>\n</tr>\n<tr>\n<td>NNS</td>\n<td>$2/9$</td>\n<td>0</td>\n<td>$0$</td>\n<td>Emissione nulla</td>\n</tr>\n<tr>\n<td>MD</td>\n<td>$1/9$</td>\n<td>0</td>\n<td>$0$</td>\n<td>Emissione nulla</td>\n</tr>\n<tr>\n<td>VBZ</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>Probabilit√† iniziale nulla</td>\n</tr>\n<tr>\n<td>VBP</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>Probabilit√† iniziale nulla</td>\n</tr>\n<tr>\n<td>VB</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>Probabilit√† iniziale nulla</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Chiarimenti</strong>:\n- Lo stato PRP √® l&rsquo;unico attivo a $t=1$ perch√© ha sia $\\pi_s > 0$ che $b_s(\\text{we}) > 0$.\n- I valori di $\\pi_s$ per VBZ, VBP, VB sono zero (non presenti nel training data iniziale).</p>\n<h3 id=\"2-fase-ricorsiva\">2. Fase Ricorsiva</h3>\n<h4 id=\"passo-math_inline_125-osservazione-can\">Passo $t=2$ (osservazione: &ldquo;can&rdquo;)</h4>\n<p><strong>Emissioni rilevanti</strong>:<br />\n- $b_{\\text{NN}}(\\text{can}) = 0.25$<br />\n- $b_{\\text{MD}}(\\text{can}) = 1.00$  </p>\n<p>Calcoliamo $v[s,2]$ solo per NN e MD (unici stati con emissione non nulla):</p>\n<ol>\n<li><strong>Per lo stato NN</strong>:<br />\n   $$v[\\text{NN},2] = \\max_{s'} \\left( v[s',1] \\cdot a_{s',\\text{NN}} \\cdot 0.25 \\right)$$  </li>\n<li>$s'$ pu√≤ essere solo PRP (unico stato con $v[s',1] > 0$).  </li>\n<li>$a_{\\text{PRP},\\text{NN}} = 0$ (transizione PRP‚ÜíNN non consentita).  </li>\n<li>\n<p>Risultato: $v[\\text{NN},2] = 0.0556 \\cdot 0 \\cdot 0.25 = 0$.</p>\n</li>\n<li>\n<p><strong>Per lo stato MD</strong>:<br />\n   $$v[\\text{MD},2] = \\max_{s'} \\left( v[s',1] \\cdot a_{s',\\text{MD}} \\cdot 1.00 \\right)$$  </p>\n</li>\n<li>$a_{\\text{PRP},\\text{MD}} = 0.5$ (transizione PRP‚ÜíMD consentita).  </li>\n<li>Risultato: $v[\\text{MD},2] = 0.0556 \\cdot 0.5 \\cdot 1 = 0.0278$.  </li>\n<li>Backpointer: $bp[\\text{MD},2] = \\text{PRP}$ (stato precedente ottimale).</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>Stato $s$</th>\n<th>$v[s,2]$</th>\n<th>$bp[s, 2]$</th>\n<th>Note</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>MD</td>\n<td>$\\frac{1}{36} \\approx 0.0278$</td>\n<td>PRP</td>\n<td>Unico stato attivo a $t=2$</td>\n</tr>\n<tr>\n<td>NN</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>Probabilit√† nulla</td>\n</tr>\n<tr>\n<td>Altri</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>Emissione nulla</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"passo-math_inline_143-osservazione-run\">Passo $t=3$ (osservazione: &ldquo;run&rdquo;)</h4>\n<p><strong>Emissioni rilevanti</strong>:<br />\n- $b_{\\text{VB}}(\\text{run}) = 0.50$ (solo VB emette &ldquo;run&rdquo;).  </p>\n<p>Calcoliamo $v[\\text{VB},3]$:<br />\n$$v[\\text{VB},3] = \\max_{s'} \\left( v[s',2] \\cdot a_{s',\\text{VB}} \\cdot 0.50 \\right)$$  </p>\n<ul>\n<li>$s'$ pu√≤ essere solo MD (unico stato con $v[s',2] > 0$).  </li>\n<li>$a_{\\text{MD},\\text{VB}} = \\frac{2}{3}$ (transizione MD‚ÜíVB consentita).  </li>\n<li>Risultato:<br />\n  $$v[\\text{VB},3] = 0.0278 \\cdot \\frac{2}{3} \\cdot 0.5 = \\frac{1}{108} \\approx 0.00926$$  </li>\n<li>Backpointer: $bp[\\text{VB},3] = \\text{MD}$.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Stato $s$</th>\n<th>$v[s,3]$</th>\n<th>$bp[s, 3]$</th>\n<th>Note</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>VB</td>\n<td>$\\frac{1}{108} \\approx 0.00926$</td>\n<td>MD</td>\n<td>Unico stato attivo a $t=3$</td>\n</tr>\n<tr>\n<td>Altri</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>Emissione nulla</td>\n</tr>\n</tbody>\n</table>\n<p>Alla fine, abbiamo la tabella di valori ottimali:</p>\n<table>\n<thead>\n<tr>\n<th>Stato</th>\n<th>$o_1$=&rdquo;we&rdquo; (t=1)</th>\n<th>$o_2$=&rdquo;can&rdquo; (t=2)</th>\n<th>$o_3$=&rdquo;run&rdquo; (t=3)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DT</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>PRP</td>\n<td>$\\frac{1}{18} \\approx 0.0556$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>NN</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>NNS</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>MD</td>\n<td>$0$</td>\n<td>$\\frac{1}{36} \\approx 0.0278$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>VBZ</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>VBP</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$0$</td>\n</tr>\n<tr>\n<td>VB</td>\n<td>$0$</td>\n<td>$0$</td>\n<td>$\\frac{1}{108} \\approx 0.00926$</td>\n</tr>\n</tbody>\n</table>\n<p>e la tabella di backpointers:</p>\n<table>\n<thead>\n<tr>\n<th>Stato</th>\n<th>$o_1$=&rdquo;we&rdquo; (t=1)</th>\n<th>$o_2$=&rdquo;can&rdquo; (t=2)</th>\n<th>$o_3$=&rdquo;run&rdquo; (t=3)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>DT</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>PRP</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>NN</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>NNS</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>MD</td>\n<td>$0$</td>\n<td><strong>PRP</strong></td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>VBZ</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>VBP</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td>‚Äî</td>\n</tr>\n<tr>\n<td>VB</td>\n<td>$0$</td>\n<td>‚Äî</td>\n<td><strong>MD</strong></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"3-terminazione-e-ricostruzione-del-percorso\">3. Terminazione e Ricostruzione del Percorso</h4>\n<ol>\n<li><strong>Terminazione</strong>:  </li>\n<li>Troviamo lo stato finale ottimale:<br />\n     $$\\text{bestpathprob} = \\max_{s} v[s,T] = \\max_{s} v[s,3] = v[\\text{VB},3] \\approx 0.00926$$  </li>\n<li>\n<p>Stato finale: $s^* = \\text{VB}$.</p>\n</li>\n<li>\n<p><strong>Ricostruzione all&rsquo;indietro</strong> (backtracking):  </p>\n</li>\n<li>$\\hat{s}_3 = \\text{VB}$  </li>\n<li>$\\hat{s}_2 = bp[\\text{VB},3] = \\text{MD}$  </li>\n<li>$\\hat{s}_1 = bp[\\text{MD},2] = \\text{PRP}$  </li>\n</ol>\n<p><strong>Sequenza ottimale</strong>:<br />\n$$(\\text{PRP},\\, \\text{MD},\\, \\text{VB}) \\quad \\text{con probabilit√† } \\approx 0.926\\%$$  </p>\n<p><strong>Interpretazione linguistica</strong>:<br />\n- <strong>PRP</strong>: Pronome personale (&ldquo;we&rdquo;).<br />\n- <strong>MD</strong>: Verbo modale (&ldquo;can&rdquo;).<br />\n- <strong>VB</strong>: Verbo base (&ldquo;run&rdquo;).</p>\n<h2 id=\"conclusione-hmm-e-viterbi-nel-pos-tagging\">Conclusione: HMM e Viterbi nel PoS Tagging</h2>\n<h3 id=\"punti-chiave\">üîç Punti Chiave</h3>\n<ol>\n<li><strong>Modellazione Contestuale</strong>: Gli HMM catturano le dipendenze sequenziali tra i tag attraverso le probabilit√† di transizione  </li>\n<li><strong>Efficienza Computazionale</strong>: L&rsquo;algoritmo di Viterbi riduce la complessit√† da esponenziale a lineare grazie alla programmazione dinamica  </li>\n<li><strong>Addestramento Data-Driven</strong>: Le probabilit√† sono stimate direttamente da corpora annotati, garantendo adattabilit√† a diversi domini linguistici  </li>\n</ol>\n<h3 id=\"limiti-pratici\">üõë Limiti Pratici</h3>\n<ul>\n<li><strong>Sparsit√† dei Dati</strong>: Transizioni/emissioni non osservate nei dati di training ricevono probabilit√† zero (problema dello smoothing)  </li>\n<li><strong>Contesto Limitato</strong>: L&rsquo;assunzione markoviana di primo ordine ignora dipendenze a lungo raggio  </li>\n<li><strong>Ambiguity Resolution</strong>: Difficolt√† con parole polisemiche che richiederebbero contesto semantico  </li>\n</ul>\n<h4 id=\"soluzioni-ibride-moderne\">üí° Soluzioni Ibride Moderne</h4>\n<ol>\n<li><strong>Integrazione con Reti Neurali</strong>  </li>\n<li>Usare HMM per la struttura sequenziale + Embedding neurali per rappresentazioni contestuali  </li>\n<li>\n<p>Esempio: <strong>BiLSTM-CRF</strong> combinano la potenza delle reti ricorrenti con modelli grafici  </p>\n</li>\n<li>\n<p><strong>Transformer-Based Taggers</strong>  </p>\n</li>\n<li>Modelli come BERT sfruttano l&rsquo;attenzione globale per catturare dipendenze complesse  </li>\n<li>\n<p>Accuracy &gt;98% sul Penn Treebank contro il 95-97% degli HMM classici  </p>\n</li>\n<li>\n<p><strong>Active Learning</strong>  </p>\n</li>\n<li>Ridurre la dipendenza da grandi corpora annotati attraverso annotazioni mirate  </li>\n<li>Particolarmente utile per lingue low-resource o domini specialistici  </li>\n</ol>\n<h4 id=\"riferimenti\">üìö Riferimenti</h4>\n<ul>\n<li><a href=\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\">Penn Treebank</a></li>\n<li><a href=\"https://web.stanford.edu/~jurafsky/slp3/\">Jurafsky and Martin - Speech and Language Processing</a></li>\n</ul>"
}