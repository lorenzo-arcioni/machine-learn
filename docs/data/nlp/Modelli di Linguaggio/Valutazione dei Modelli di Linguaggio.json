{
  "title": "Valutazione dei Modelli di Linguaggio",
  "content": "<style>pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.codehilite .hll { background-color: #ffffcc }\n.codehilite { background: #f8f8f8; }\n.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */\n.codehilite .err { border: 1px solid #F00 } /* Error */\n.codehilite .k { color: #008000; font-weight: bold } /* Keyword */\n.codehilite .o { color: #666 } /* Operator */\n.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n.codehilite .cp { color: #9C6500 } /* Comment.Preproc */\n.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n.codehilite .gd { color: #A00000 } /* Generic.Deleted */\n.codehilite .ge { font-style: italic } /* Generic.Emph */\n.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n.codehilite .gr { color: #E40000 } /* Generic.Error */\n.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n.codehilite .gi { color: #008400 } /* Generic.Inserted */\n.codehilite .go { color: #717171 } /* Generic.Output */\n.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n.codehilite .gs { font-weight: bold } /* Generic.Strong */\n.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n.codehilite .gt { color: #04D } /* Generic.Traceback */\n.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n.codehilite .kp { color: #008000 } /* Keyword.Pseudo */\n.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n.codehilite .kt { color: #B00040 } /* Keyword.Type */\n.codehilite .m { color: #666 } /* Literal.Number */\n.codehilite .s { color: #BA2121 } /* Literal.String */\n.codehilite .na { color: #687822 } /* Name.Attribute */\n.codehilite .nb { color: #008000 } /* Name.Builtin */\n.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */\n.codehilite .no { color: #800 } /* Name.Constant */\n.codehilite .nd { color: #A2F } /* Name.Decorator */\n.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */\n.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n.codehilite .nf { color: #00F } /* Name.Function */\n.codehilite .nl { color: #767600 } /* Name.Label */\n.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */\n.codehilite .nv { color: #19177C } /* Name.Variable */\n.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n.codehilite .w { color: #BBB } /* Text.Whitespace */\n.codehilite .mb { color: #666 } /* Literal.Number.Bin */\n.codehilite .mf { color: #666 } /* Literal.Number.Float */\n.codehilite .mh { color: #666 } /* Literal.Number.Hex */\n.codehilite .mi { color: #666 } /* Literal.Number.Integer */\n.codehilite .mo { color: #666 } /* Literal.Number.Oct */\n.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */\n.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */\n.codehilite .sc { color: #BA2121 } /* Literal.String.Char */\n.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */\n.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */\n.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */\n.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n.codehilite .sx { color: #008000 } /* Literal.String.Other */\n.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */\n.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */\n.codehilite .ss { color: #19177C } /* Literal.String.Symbol */\n.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */\n.codehilite .fm { color: #00F } /* Name.Function.Magic */\n.codehilite .vc { color: #19177C } /* Name.Variable.Class */\n.codehilite .vg { color: #19177C } /* Name.Variable.Global */\n.codehilite .vi { color: #19177C } /* Name.Variable.Instance */\n.codehilite .vm { color: #19177C } /* Name.Variable.Magic */\n.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */\n\n/* Styling per blocchi di codice */\n.codehilite {\n    background: transparent !important;\n    border-radius: 8px;\n    overflow: hidden;\n}\n.codehilite pre {\n    background: transparent !important;\n    margin: 0 !important;\n    padding: 20px !important;\n    font-family: 'Monaco', 'Menlo', 'Consolas', monospace !important;\n    font-size: 14px !important;\n    line-height: 1.5 !important;\n    white-space: pre !important;\n    overflow-x: auto !important;\n    color: inherit !important;\n}\n.codehilite code {\n    background: transparent !important;\n    padding: 0 !important;\n    font-family: inherit !important;\n}\n\n\n.code-wrapper { \n    position: relative; \n}\n.copy-button {\n    position: absolute; \n    top: 12px; \n    right: 12px; \n    padding: 6px 12px; \n    font-size: 12px;\n    cursor: pointer; \n    border: none; \n    border-radius: 4px; \n    background: rgba(255,255,255,0.9);\n    color: #374151; \n    transition: all 0.2s ease;\n    font-weight: 500;\n}\n.copy-button:hover { \n    background: rgba(255,255,255,1);\n    transform: translateY(-1px);\n}\n\n\ndetails.code-container {\n    border: 1px solid #e5e7eb; \n    border-radius: 12px; \n    background: #f9fafb;\n    margin: 16px 0;\n    transition: all 0.3s ease;\n}\ndetails.code-container summary {\n    padding: 12px 16px;\n    font-size: 14px; \n    color: #6b7280; \n    cursor: pointer; \n    outline: none; \n    user-select: none;\n    font-weight: 500;\n}\ndetails.code-container[open] summary::after { \n    content: \" (Hide Code)\"; \n    color: #9ca3af; \n}\ndetails.code-container:not([open]) summary::after { \n    content: \" (Show Code)\"; \n    color: #d1d5db; \n}\ndetails.code-container .code-wrapper {\n    padding: 0;\n    margin: 0;\n}\n</style>\n<p>La valutazione di un modello di linguaggio consiste nella misurazione della qualità del modello attraverso la probabilità che il modello assegna ai dati di test. È un passaggio fondamentale che consente di determinare se un modello di linguaggio funziona bene o meno.</p>\n<h2 id=\"criteri-di-valutazione\">Criteri di Valutazione</h2>\n<ul>\n<li><strong>Domande fondamentali</strong>:  </li>\n<li>Come determinare se un modello è efficace?  </li>\n<li>\n<p>Come confrontare due modelli per stabilire quale sia migliore?  </p>\n</li>\n<li>\n<p><strong>Comportamento ideale di un modello</strong>:<br />\n  Un buon modello deve:<br />\n  • <strong>Favorire frasi fluenti</strong> (grammaticali o frequentemente osservate)<br />\n  • <strong>Sfavorire frasi scorrette</strong> (agrammaticali o rare)  </p>\n</li>\n<li>\n<p><strong>Intuizione chiave</strong>:  </p>\n<blockquote>\n<p>Dati due modelli probabilistici, <strong>il modello migliore è quello che si adatta meglio ai dati di test</strong>, assegnando loro probabilità più elevate.  </p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"misurazione-quantitativa\">Misurazione Quantitativa</h2>\n<p>La qualità si misura attraverso <strong>la probabilità che il modello assegna ai dati di test</strong>:<br />\n$$ P_{\\text{test}} = \\prod_{i=1}^N P(w_i | w_{1:i-1}) $$<br />\n<strong>Regola di confronto</strong>:<br />\n- Modello A è migliore di Modello B se:<br />\n  $$ P_{\\text{test}}(A) > P_{\\text{test}}(B) $$  </p>\n<h2 id=\"suddivisione-standard-dei-dati\">Suddivisione Standard dei Dati</h2>\n<p><strong>Struttura raccomandata</strong>:  </p>\n<table>\n<thead>\n<tr>\n<th>Set di Dati</th>\n<th>Scopo</th>\n<th>Dimensione Tipica</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Training</strong></td>\n<td>Apprendimento parametri (es. conteggi n-gram)</td>\n<td>80%</td>\n</tr>\n<tr>\n<td><strong>Development</strong></td>\n<td>Tuning iperparametri (es. ordine n-gram)</td>\n<td>10%</td>\n</tr>\n<tr>\n<td><strong>Test</strong></td>\n<td>Valutazione finale</td>\n<td>10%</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Condizioni essenziali</strong>:<br />\n- Training, development e test set devono essere <strong>disgiunti</strong>.<br />\n- Il test set deve contenere dati mai visti durante l’addestramento.  </p>\n<h2 id=\"valutazione-qualitativa-tramite-generazione\">Valutazione Qualitativa tramite Generazione</h2>\n<p><strong>Protocollo</strong>:<br />\n1. Generare frasi campione da modelli con ordini n-gram diversi.<br />\n2. Valutare empiricamente la qualità delle frasi generate.  </p>\n<p><strong>Esempio di output</strong>:</p>\n<table>\n<thead>\n<tr>\n<th>Ordine n-gram</th>\n<th>Frase Generata</th>\n<th>Valutazione Qualitativa</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Unigram</td>\n<td>&ldquo;the of to and a&rdquo;</td>\n<td>❌ Incoerente</td>\n</tr>\n<tr>\n<td>Bigram</td>\n<td>&ldquo;the cat jumped on&rdquo;</td>\n<td>⚠️ Parzialmente corretta</td>\n</tr>\n<tr>\n<td>Trigram</td>\n<td>&ldquo;the cat sat on the mat&rdquo;</td>\n<td>✅ Fluida</td>\n</tr>\n<tr>\n<td>Quadrigram</td>\n<td>&ldquo;the cat sat on the red carpet&rdquo;</td>\n<td>✅ Ricca di contesto</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"teoria-vs-pratica\">Teoria vs Pratica</h2>\n<ul>\n<li>\n<p><strong>Modelli complessi</strong> (es. n-gram di ordine elevato):</p>\n</li>\n<li>\n<p>Migliore adattamento ai dati di training  </p>\n</li>\n<li>\n<p>Rischio di <strong>overfitting</strong> (prestazioni scadenti su test set)<br />\n  $$ P_{\\text{quadrigram}}(w_i) \\approx 0 \\quad \\text{per sequenze nuove} $$  </p>\n</li>\n<li>\n<p><strong>Modelli semplici</strong> (es. unigrammi):  </p>\n</li>\n<li>Generalizzazione migliore  </li>\n<li>Incapacità di catturare dipendenze a lungo raggio<br />\n  $$ P_{\\text{unigram}}(w_i) = \\text{frequenza della parola} $$  </li>\n</ul>\n<h2 id=\"vocabolario-chiuso-vs-aperto\">Vocabolario Chiuso vs. Aperto</h2>\n<h3 id=\"definizioni-fondamentali\">Definizioni Fondamentali</h3>\n<ul>\n<li>\n<p><strong>Closed Vocabulary</strong>:<br />\n  Assunzione che <strong>tutte le parole nel test set siano presenti nel vocabolario</strong> (nessuna parola sconosciuta).<br />\n  $$ \\forall w \\in \\text{Test Set}, \\quad w \\in \\text{Vocabolario} $$  </p>\n</li>\n<li>\n<p><strong>Open Vocabulary</strong>:<br />\n  Gestione delle <strong>parole OOV (Out-Of-Vocabulary)</strong> tramite il token speciale <code>&lt;UNK&gt;</code>.<br />\n  $$\n  \\text{OOV} \\rightarrow \\text{<UNK>}\n  $$\n  Per gestire al meglio le parole OOV, si utilizza quindi il <strong>meccanismo di sostituzione</strong>.</p>\n</li>\n</ul>\n<h3 id=\"processo-di-addestramento-per-open-vocabulary-3-step\">Processo di Addestramento per Open Vocabulary (3 Step)</h3>\n<p>Consideriamo un set di test:</p>\n<p><em>Escort claims Berlusconi&rsquo;s bunga bunga parties full of young girls. An\nescort who claims she was paid €10,000 (£8,500) to spend two nights\nwith the Italian Prime Minister Silvio Berlusconi has revealed how his\nparties were full of young girls.</em></p>\n<h4 id=\"1-scelta-del-vocabolario\"><strong>1. Scelta del Vocabolario</strong></h4>\n<p>Consideriamo un vocabolario di train:</p>\n<p>$\\text{Vocabolario}$ = {Escort, escort, claims, Berlusconi’s, parties, full, of, young,\ngirls, an, who, she, was, paid, to, spend, two, nights, with, the, Italian,\nPrime, Minister, Berlusconi, has, revealed, how, his, were}</p>\n<ul>\n<li><strong>Strumenti</strong>: Liste di frequenza lessicale o cutoff statistico  </li>\n<li><strong>Esempio pratico</strong>:<br />\n  Dal caso studio, parole selezionate includono forme flesse (&ldquo;Escort/escort&rdquo;) e entità (&ldquo;Berlusconi&rdquo;), ma escludono numeri e valute.<br />\n<em>Dimensione vocabolario</em>: 29 parole nel caso fornito.</li>\n</ul>\n<h4 id=\"2-conversione-oov-nel-training-set\"><strong>2. Conversione OOV nel Training Set</strong></h4>\n<ul>\n<li><strong>Meccanismo di sostituzione</strong>:<br />\n  Per ogni parola $w$ nel training set:<br />\n  $$ \n  w_{\\text{convertita}} = \\begin{cases} \n  w & \\text{se } w \\in \\text{Vocabolario} \\\\\n  \\text{<UNK>} & \\text{altrimenti}\n  \\end{cases}\n  $$  </li>\n<li><strong>Risultato</strong>:<br />\n<em>Escort claims Berlusconi&rsquo;s $\\text{<UNK>}$ $\\text{<UNK>}$ parties full of young girls. An\nescort who claims she was paid $\\text{<UNK>}$ $\\text{<UNK>}$ to spend two nights with\nthe Italian Prime Minister $\\text{<UNK>}$ Berlusconi has revealed how his parties\nwere full of young girls.</em></li>\n</ul>\n<h4 id=\"3-stima-delle-probabilita\"><strong>3. Stima delle Probabilità</strong></h4>\n<ul>\n<li><strong>Trattamento di <UNK></strong>:<br />\n  Il token speciale viene considerato una parola nel modello:<br />\n  $$\n  P(\\text{<UNK>}) = \\frac{C(\\text{<UNK>})}{C(\\text{tutte le parole})}\n  $$  </li>\n</ul>\n<p><strong>Calcolo probabilità bigramma</strong>:<br />\n$$\nP(\\text{parties} | \\text{<UNK>}) = \\frac{C(\\text{<UNK> parties})}{C(\\text{<UNK>})} = \\frac{1}{5}\n$$</p>\n<h3 id=\"impatto-sulle-prestazioni\">Impatto sulle Prestazioni</h3>\n<ul>\n<li><strong>Vantaggio</strong>: Previene errori &ldquo;zero probability&rdquo; per parole nuove  </li>\n<li><strong>Svantaggio</strong>: Perde informazioni lessicali specifiche  </li>\n<li><strong>Trade-off</strong>:<br />\n  $$\n  \\text{Informatività} \\propto \\frac{1}{\\text{Dimensione Vocabolario}}\n  $$</li>\n</ul>\n<h2 id=\"valutazione-intrinseca-e-estrinseca-nei-modelli-di-linguaggio\">Valutazione Intrinseca e Estrinseca nei Modelli di Linguaggio</h2>\n<p>La valutazione dei modelli di linguaggio può essere classificata in due categorie principali: <strong>valutazione intrinseca (in vitro)</strong> ed <strong>estrinseca (in vivo o end-to-end)</strong>.  </p>\n<h3 id=\"valutazione-estrinseca-in-vivo\">Valutazione Estrinseca (In Vivo)</h3>\n<p>Questa metodologia prevede l&rsquo;integrazione del modello in un&rsquo;applicazione reale e la misurazione della sua qualità attraverso il funzionamento del sistema finale. Un esempio comune è l&rsquo;inserimento di un modello di linguaggio in un sistema di riconoscimento vocale e la valutazione della qualità delle trascrizioni generate.  </p>\n<p><strong>Vantaggi</strong>:\n- Fornisce una misura diretta dell&rsquo;impatto del modello nell&rsquo;uso pratico.\n- Permette di valutare il contributo del modello in un contesto applicativo.  </p>\n<p><strong>Svantaggi</strong>:\n- Può essere costosa e richiedere molte risorse computazionali.\n- Non sempre è possibile da realizzare per ogni modello.  </p>\n<h3 id=\"valutazione-intrinseca-in-vitro\">Valutazione Intrinseca (In Vitro)</h3>\n<p>Questa modalità utilizza metriche specifiche per valutare il modello senza integrarlo in un&rsquo;applicazione reale. Un esempio comune è la <strong>perplessità</strong> (perplexity), che misura quanto il modello è incerto nel prevedere la prossima parola di una sequenza.  </p>\n<p><strong>Vantaggi</strong>:\n- Più economica e semplice da eseguire.\n- Permette di confrontare rapidamente diversi modelli.  </p>\n<p><strong>Svantaggi</strong>:\n- Non garantisce necessariamente miglioramenti nelle applicazioni reali.\n- Anche se spesso è correlata con la qualità dell&rsquo;uso pratico, non è una misura definitiva dell&rsquo;efficacia del modello in un contesto reale.  </p>\n<p>In sintesi, la valutazione intrinseca è utile per analisi preliminari e sviluppo rapido, mentre la valutazione estrinseca è fondamentale per misurare l&rsquo;effettivo impatto del modello nel mondo reale. Idealmente, entrambe dovrebbero essere utilizzate per una valutazione completa dei modelli di linguaggio.  </p>\n<h3 id=\"perplessita-perplexity\">Perplessità (Perplexity)</h3>\n<p>La <strong>Perplexity</strong> (PP) è una metrica fondamentale per valutare i modelli linguistici, misura quanto un modello è &ldquo;perplesso&rdquo; nel predire una sequenza di parole. Valori più bassi indicano modelli più accurati.</p>\n<h4 id=\"definizione-base\">Definizione Base</h4>\n<p>Per una sequenza di <code>N</code> parole $w_1, w_2, ..., w_N = W$ la perplexity (PP) viene definita come:</p>\n$$\nPP(W) = \\mathbb P(W)^{- \\frac{1}{N}}= \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{\\mathbb P(w_i | w_1...w_{i-1})}}\n$$\n<h4 id=\"casi-specifici\">Casi Specifici</h4>\n<ul>\n<li><strong>Bigramma</strong> (semplificazione):\n  $$\n  PP(W) = \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{\\mathbb P(w_i | w_{i-1})}}\n  $$</li>\n<li><strong>Corpus</strong> con <code>m</code> frasi e <code>N</code> parole totali:\n  $$\n  PP(C) = \\sqrt[N]{\\frac{1}{\\mathbb P(s_1, ..., s_m)}}\n  $$\n  Se le frasi sono indipendenti:\n  $$\n  \\mathbb P(s_1, ..., s_m) = \\prod_{i=1}^{m} \\mathbb P(s_i)\n  $$</li>\n</ul>\n<h4 id=\"interpretazione\">Interpretazione</h4>\n<ul>\n<li><strong>PP ↓ → Modello ↑</strong>: Minore è la perplexity, migliore è il modello.</li>\n<li><strong>Esempio Reale</strong> (Wall Street Journal):\n  | N-gramma  | Unigramma | Bigramma | Trigramma |\n  |-----------|-----------|----------|-----------|\n  | Perplexity| 962       | 170      | 109       |</li>\n</ul>\n<p>Quindi, più informazione il modello ci da sulla sequenza di parole, più bassa è la perplexity, migliore il modello. Intuitivamente, se un modello assegna un&rsquo;alta probabilità al set di test, significa che non è sorpreso di osservarlo (non ne è &lsquo;perplesso&rsquo;), indicando una buona comprensione del funzionamento del linguaggio.</p>\n<h4 id=\"fonti\">Fonti</h4>\n<ul>\n<li><a href=\"https://pubs.aip.org/asa/jasa/article/62/S1/S63/642598/Perplexity-a-measure-of-the-difficulty-of-speech\">Articolo Originale</a></li>\n<li><a href=\"https://towardsdatascience.com/perplexity-in-language-models-87a196019a94\">Approfondimento</a></li>\n</ul>"
}